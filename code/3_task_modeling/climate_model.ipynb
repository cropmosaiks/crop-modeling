{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d64e464-31b8-4c88-bbf5-877a8fa59fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pyhere import here\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow\n",
    "\n",
    "import concurrent.futures\n",
    "from itertools import product, combinations\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    GridSearchCV,\n",
    "    cross_val_predict,\n",
    ")\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr, t\n",
    "\n",
    "from task_modeling_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d71534-ae81-421a-86a9-3f460bdab54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_dataframe(df, groupby_columns, target_column, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Group a pandas DataFrame and calculate mean, standard deviation, standard error,\n",
    "    and confidence interval for a single column.\n",
    "\n",
    "    :param df: The input pandas DataFrame\n",
    "    :param groupby_columns: A list of columns to group by\n",
    "    :param target_column: The column to calculate the statistics for\n",
    "    :param confidence_level: The desired confidence level for the interval (default: 0.95)\n",
    "    :return: A summarized pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Group the DataFrame\n",
    "    grouped_df = df.groupby(groupby_columns)[target_column]\n",
    "\n",
    "    # Calculate mean, standard deviation, and standard error\n",
    "    mean = grouped_df.mean()\n",
    "    std = grouped_df.std()\n",
    "    sem = grouped_df.sem()\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    ci_lower, ci_upper = t.interval(\n",
    "        confidence=confidence_level,  # Confidence level\n",
    "        df=grouped_df.count() - 1,  # Degrees of freedom\n",
    "        loc=mean,  # Mean\n",
    "        scale=sem,  # Standard error\n",
    "    )\n",
    "\n",
    "    # Create the summarized DataFrame\n",
    "    summary_df = pd.DataFrame(\n",
    "        {\n",
    "            \"summary_var\": target_column,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"sem\": sem,\n",
    "            \"ci_lower\": ci_lower,\n",
    "            \"ci_upper\": ci_upper,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return summary_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2216f1bb-8f61-417f-bbfc-6bba313014c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['pre'],\n",
       " ['tmp'],\n",
       " ['ndvi'],\n",
       " ['pre', 'tmp'],\n",
       " ['pre', 'ndvi'],\n",
       " ['tmp', 'ndvi'],\n",
       " ['pre', 'tmp', 'ndvi']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = [\"pre\", \"tmp\", \"ndvi\"]\n",
    "clim = list(combinations(variables, 2))\n",
    "clim = clim + [[variables[i]] for i in range(len(variables))] + [variables]\n",
    "clim = [list(elem) for elem in clim]\n",
    "clim.sort(key=len)\n",
    "clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18c8966-3893-4443-909f-583a883d3a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 5600/5600 [49:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results as: climate_model_n-seeds-100_2023-04-05.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Generate 100 random seeds\n",
    "num_seeds = 100\n",
    "random_seeds = [random.randint(0, 1_000_000) for _ in range(num_seeds)]\n",
    "\n",
    "output = []\n",
    "\n",
    "# Generate parameter combinations, including seeds\n",
    "param_combinations = list(\n",
    "    product(clim, [2009, 2016], [True, False], [True, False], random_seeds)\n",
    ")\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    tasks = [\n",
    "        executor.submit(run_climate_model, params) for params in param_combinations\n",
    "    ]\n",
    "    output = [\n",
    "        task.result()\n",
    "        for task in tqdm(concurrent.futures.as_completed(tasks), total=len(tasks))\n",
    "        if task.result() is not None\n",
    "    ]\n",
    "\n",
    "results = pd.DataFrame(output)\n",
    "\n",
    "mask = results.anomaly == True\n",
    "cols = [\n",
    "    \"demean_cv_R2\",\n",
    "    \"demean_cv_r\",\n",
    "    \"demean_cv_r2\",\n",
    "    \"demean_test_R2\",\n",
    "    \"demean_test_r\",\n",
    "    \"demean_test_r2\",\n",
    "]\n",
    "results.loc[mask, cols] = np.nan\n",
    "\n",
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "file_name = f\"climate_model_n-seeds-{num_seeds}_{today}.csv\"\n",
    "print(f\"Saving results as: {file_name}\\n\\n\")\n",
    "results.to_csv(here(\"data\", \"results\", file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0fbd54-ccf3-42b7-80fd-ce4fb94c5a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>random_state</th>\n",
       "      <th>year_start</th>\n",
       "      <th>hot_encode</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>total_n</th>\n",
       "      <th>train_n</th>\n",
       "      <th>test_n</th>\n",
       "      <th>best_reg_param</th>\n",
       "      <th>mean_of_val_R2</th>\n",
       "      <th>...</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_R2</th>\n",
       "      <th>test_r</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>demean_cv_R2</th>\n",
       "      <th>demean_cv_r</th>\n",
       "      <th>demean_cv_r2</th>\n",
       "      <th>demean_test_R2</th>\n",
       "      <th>demean_test_r</th>\n",
       "      <th>demean_test_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pre</td>\n",
       "      <td>670487</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>936</td>\n",
       "      <td>748</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.01, 0.001]</td>\n",
       "      <td>[0.32605299437170937, 0.5915969474212787]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.689724</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.712270</td>\n",
       "      <td>0.507328</td>\n",
       "      <td>-0.081250</td>\n",
       "      <td>0.137464</td>\n",
       "      <td>0.018896</td>\n",
       "      <td>0.061015</td>\n",
       "      <td>0.267610</td>\n",
       "      <td>0.071615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pre</td>\n",
       "      <td>116739</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>936</td>\n",
       "      <td>748</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.01, 0.001]</td>\n",
       "      <td>[0.3230651368660741, 0.568903471601985]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663613</td>\n",
       "      <td>0.635893</td>\n",
       "      <td>0.797723</td>\n",
       "      <td>0.636362</td>\n",
       "      <td>-0.060034</td>\n",
       "      <td>0.152047</td>\n",
       "      <td>0.023118</td>\n",
       "      <td>-0.012841</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.040310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pre</td>\n",
       "      <td>256787</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>936</td>\n",
       "      <td>748</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.01, 0.001]</td>\n",
       "      <td>[0.316214295918939, 0.5519145308962885]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665604</td>\n",
       "      <td>0.596661</td>\n",
       "      <td>0.776197</td>\n",
       "      <td>0.602482</td>\n",
       "      <td>-0.116015</td>\n",
       "      <td>0.103074</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>0.015910</td>\n",
       "      <td>0.216306</td>\n",
       "      <td>0.046788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pre</td>\n",
       "      <td>709570</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>936</td>\n",
       "      <td>748</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.01, 0.001]</td>\n",
       "      <td>[0.34071000856908346, 0.5596416069557559]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657814</td>\n",
       "      <td>0.656065</td>\n",
       "      <td>0.812039</td>\n",
       "      <td>0.659408</td>\n",
       "      <td>-0.049615</td>\n",
       "      <td>0.162859</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>-0.073261</td>\n",
       "      <td>0.179481</td>\n",
       "      <td>0.032213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre</td>\n",
       "      <td>146316</td>\n",
       "      <td>2009</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>936</td>\n",
       "      <td>748</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.01, 0.001]</td>\n",
       "      <td>[0.2718998176875954, 0.5290086272652292]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663041</td>\n",
       "      <td>0.619920</td>\n",
       "      <td>0.788094</td>\n",
       "      <td>0.621092</td>\n",
       "      <td>-0.127079</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.166849</td>\n",
       "      <td>0.408471</td>\n",
       "      <td>0.166849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>pre_tmp_ndvi</td>\n",
       "      <td>382554</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>432</td>\n",
       "      <td>345</td>\n",
       "      <td>87</td>\n",
       "      <td>[0.01, 0.001, 0.001]</td>\n",
       "      <td>[0.5584364012987756, 0.6960813856230079, 0.709...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772898</td>\n",
       "      <td>0.705396</td>\n",
       "      <td>0.856181</td>\n",
       "      <td>0.733046</td>\n",
       "      <td>0.205520</td>\n",
       "      <td>0.540986</td>\n",
       "      <td>0.292666</td>\n",
       "      <td>0.129545</td>\n",
       "      <td>0.491652</td>\n",
       "      <td>0.241722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>pre_tmp_ndvi</td>\n",
       "      <td>170555</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>432</td>\n",
       "      <td>345</td>\n",
       "      <td>87</td>\n",
       "      <td>[0.01, 0.01, 0.1]</td>\n",
       "      <td>[0.5622836343049482, 0.6904651626797575, 0.694...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756820</td>\n",
       "      <td>0.733523</td>\n",
       "      <td>0.858231</td>\n",
       "      <td>0.736560</td>\n",
       "      <td>0.299404</td>\n",
       "      <td>0.572170</td>\n",
       "      <td>0.327378</td>\n",
       "      <td>0.672193</td>\n",
       "      <td>0.848483</td>\n",
       "      <td>0.719923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>pre_tmp_ndvi</td>\n",
       "      <td>388162</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>432</td>\n",
       "      <td>345</td>\n",
       "      <td>87</td>\n",
       "      <td>[0.01, 0.01, 0.1]</td>\n",
       "      <td>[0.5600658729566149, 0.705632659623092, 0.7070...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767253</td>\n",
       "      <td>0.683676</td>\n",
       "      <td>0.827225</td>\n",
       "      <td>0.684301</td>\n",
       "      <td>0.316808</td>\n",
       "      <td>0.592926</td>\n",
       "      <td>0.351561</td>\n",
       "      <td>0.270710</td>\n",
       "      <td>0.597104</td>\n",
       "      <td>0.356533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>pre_tmp_ndvi</td>\n",
       "      <td>372528</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>432</td>\n",
       "      <td>345</td>\n",
       "      <td>87</td>\n",
       "      <td>[1e-08, 0.01, 0.1]</td>\n",
       "      <td>[0.584814283369868, 0.6968039956240404, 0.7031...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754589</td>\n",
       "      <td>0.734711</td>\n",
       "      <td>0.860786</td>\n",
       "      <td>0.740952</td>\n",
       "      <td>0.304971</td>\n",
       "      <td>0.579791</td>\n",
       "      <td>0.336157</td>\n",
       "      <td>0.211838</td>\n",
       "      <td>0.546692</td>\n",
       "      <td>0.298872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>pre_tmp_ndvi</td>\n",
       "      <td>219684</td>\n",
       "      <td>2016</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>432</td>\n",
       "      <td>345</td>\n",
       "      <td>87</td>\n",
       "      <td>[0.01, 0.01, 0.1]</td>\n",
       "      <td>[0.5455474261320873, 0.6790048834693356, 0.688...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746217</td>\n",
       "      <td>0.790160</td>\n",
       "      <td>0.889324</td>\n",
       "      <td>0.790898</td>\n",
       "      <td>0.346447</td>\n",
       "      <td>0.610144</td>\n",
       "      <td>0.372276</td>\n",
       "      <td>-0.037187</td>\n",
       "      <td>0.401793</td>\n",
       "      <td>0.161437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         variables  random_state  year_start  hot_encode  anomaly  total_n  \\\n",
       "0              pre        670487        2009        True    False      936   \n",
       "1              pre        116739        2009        True    False      936   \n",
       "2              pre        256787        2009        True    False      936   \n",
       "3              pre        709570        2009        True    False      936   \n",
       "4              pre        146316        2009        True    False      936   \n",
       "...            ...           ...         ...         ...      ...      ...   \n",
       "4195  pre_tmp_ndvi        382554        2016       False    False      432   \n",
       "4196  pre_tmp_ndvi        170555        2016       False    False      432   \n",
       "4197  pre_tmp_ndvi        388162        2016       False    False      432   \n",
       "4198  pre_tmp_ndvi        372528        2016       False    False      432   \n",
       "4199  pre_tmp_ndvi        219684        2016       False    False      432   \n",
       "\n",
       "      train_n  test_n        best_reg_param  \\\n",
       "0         748     188         [0.01, 0.001]   \n",
       "1         748     188         [0.01, 0.001]   \n",
       "2         748     188         [0.01, 0.001]   \n",
       "3         748     188         [0.01, 0.001]   \n",
       "4         748     188         [0.01, 0.001]   \n",
       "...       ...     ...                   ...   \n",
       "4195      345      87  [0.01, 0.001, 0.001]   \n",
       "4196      345      87     [0.01, 0.01, 0.1]   \n",
       "4197      345      87     [0.01, 0.01, 0.1]   \n",
       "4198      345      87    [1e-08, 0.01, 0.1]   \n",
       "4199      345      87     [0.01, 0.01, 0.1]   \n",
       "\n",
       "                                         mean_of_val_R2  ...  train_r2  \\\n",
       "0             [0.32605299437170937, 0.5915969474212787]  ...  0.689724   \n",
       "1               [0.3230651368660741, 0.568903471601985]  ...  0.663613   \n",
       "2               [0.316214295918939, 0.5519145308962885]  ...  0.665604   \n",
       "3             [0.34071000856908346, 0.5596416069557559]  ...  0.657814   \n",
       "4              [0.2718998176875954, 0.5290086272652292]  ...  0.663041   \n",
       "...                                                 ...  ...       ...   \n",
       "4195  [0.5584364012987756, 0.6960813856230079, 0.709...  ...  0.772898   \n",
       "4196  [0.5622836343049482, 0.6904651626797575, 0.694...  ...  0.756820   \n",
       "4197  [0.5600658729566149, 0.705632659623092, 0.7070...  ...  0.767253   \n",
       "4198  [0.584814283369868, 0.6968039956240404, 0.7031...  ...  0.754589   \n",
       "4199  [0.5455474261320873, 0.6790048834693356, 0.688...  ...  0.746217   \n",
       "\n",
       "       test_R2    test_r   test_r2  demean_cv_R2  demean_cv_r  demean_cv_r2  \\\n",
       "0     0.505226  0.712270  0.507328     -0.081250     0.137464      0.018896   \n",
       "1     0.635893  0.797723  0.636362     -0.060034     0.152047      0.023118   \n",
       "2     0.596661  0.776197  0.602482     -0.116015     0.103074      0.010624   \n",
       "3     0.656065  0.812039  0.659408     -0.049615     0.162859      0.026523   \n",
       "4     0.619920  0.788094  0.621092     -0.127079     0.061464      0.003778   \n",
       "...        ...       ...       ...           ...          ...           ...   \n",
       "4195  0.705396  0.856181  0.733046      0.205520     0.540986      0.292666   \n",
       "4196  0.733523  0.858231  0.736560      0.299404     0.572170      0.327378   \n",
       "4197  0.683676  0.827225  0.684301      0.316808     0.592926      0.351561   \n",
       "4198  0.734711  0.860786  0.740952      0.304971     0.579791      0.336157   \n",
       "4199  0.790160  0.889324  0.790898      0.346447     0.610144      0.372276   \n",
       "\n",
       "      demean_test_R2  demean_test_r  demean_test_r2  \n",
       "0           0.061015       0.267610        0.071615  \n",
       "1          -0.012841       0.200774        0.040310  \n",
       "2           0.015910       0.216306        0.046788  \n",
       "3          -0.073261       0.179481        0.032213  \n",
       "4           0.166849       0.408471        0.166849  \n",
       "...              ...            ...             ...  \n",
       "4195        0.129545       0.491652        0.241722  \n",
       "4196        0.672193       0.848483        0.719923  \n",
       "4197        0.270710       0.597104        0.356533  \n",
       "4198        0.211838       0.546692        0.298872  \n",
       "4199       -0.037187       0.401793        0.161437  \n",
       "\n",
       "[4200 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1d2b32-e3a1-48c4-90b7-10266cd7392f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results.groupby(\n",
    "#     [\"variables\", \"year_start\", \"hot_encode\", \"anomaly\"], as_index=False\n",
    "# ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "733736a5-2b9e-4d91-821c-ab7f5962ca14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>year_start</th>\n",
       "      <th>hot_encode</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>summary_var</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ndvi</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>demean_cv_R2</td>\n",
       "      <td>-0.187697</td>\n",
       "      <td>0.161662</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>-0.219774</td>\n",
       "      <td>-0.155620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pre</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>demean_cv_R2</td>\n",
       "      <td>-0.512005</td>\n",
       "      <td>0.077951</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>-0.527472</td>\n",
       "      <td>-0.496537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pre_ndvi</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>demean_cv_R2</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>0.107621</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.034606</td>\n",
       "      <td>0.077314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pre_tmp</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>demean_cv_R2</td>\n",
       "      <td>0.045963</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.030764</td>\n",
       "      <td>0.061162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre_tmp_ndvi</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>demean_cv_R2</td>\n",
       "      <td>0.152658</td>\n",
       "      <td>0.088301</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.135137</td>\n",
       "      <td>0.170179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tmp</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>demean_cv_R2</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.057490</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.025414</td>\n",
       "      <td>0.048229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tmp_ndvi</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>demean_cv_R2</td>\n",
       "      <td>0.194853</td>\n",
       "      <td>0.080505</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.178879</td>\n",
       "      <td>0.210827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      variables  year_start  hot_encode  anomaly   summary_var      mean  \\\n",
       "0          ndvi        2016        True    False  demean_cv_R2 -0.187697   \n",
       "1           pre        2016        True    False  demean_cv_R2 -0.512005   \n",
       "2      pre_ndvi        2016        True    False  demean_cv_R2  0.055960   \n",
       "3       pre_tmp        2016        True    False  demean_cv_R2  0.045963   \n",
       "4  pre_tmp_ndvi        2016        True    False  demean_cv_R2  0.152658   \n",
       "5           tmp        2016        True    False  demean_cv_R2  0.036821   \n",
       "6      tmp_ndvi        2016        True    False  demean_cv_R2  0.194853   \n",
       "\n",
       "        std       sem  ci_lower  ci_upper  \n",
       "0  0.161662  0.016166 -0.219774 -0.155620  \n",
       "1  0.077951  0.007795 -0.527472 -0.496537  \n",
       "2  0.107621  0.010762  0.034606  0.077314  \n",
       "3  0.076598  0.007660  0.030764  0.061162  \n",
       "4  0.088301  0.008830  0.135137  0.170179  \n",
       "5  0.057490  0.005749  0.025414  0.048229  \n",
       "6  0.080505  0.008050  0.178879  0.210827  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = results.copy()\n",
    "a = a[a.year_start == 2016]\n",
    "a = a[a.hot_encode]\n",
    "\n",
    "b = summarize_dataframe(\n",
    "    df=a,\n",
    "    groupby_columns=[\"variables\", \"year_start\", \"hot_encode\", \"anomaly\"],\n",
    "    target_column=\"demean_cv_R2\",\n",
    ")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea262f8-654d-4b5c-83a9-f06d57cd6e89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 39s, sys: 6.73 s, total: 4min 46s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### TESTING\n",
    "variable_groups = [\"pre\", \"tmp\", \"ndvi\"]\n",
    "index_cols = [\"year\", \"district\", \"yield_mt\"]\n",
    "year_start = 2016\n",
    "hot_encode = True\n",
    "anomaly = False\n",
    "n_splits = 5\n",
    "seed = 42\n",
    "\n",
    "#########################################     READ DATA    #########################################\n",
    "data = pd.read_csv(here(\"data\", \"climate\", \"climate_summary.csv\"))\n",
    "data = data.dropna()\n",
    "\n",
    "keep_cols = []\n",
    "\n",
    "for var in variable_groups:\n",
    "    tmp = data.columns[data.columns.to_series().str.contains(var)].tolist()\n",
    "    keep_cols.append(tmp)\n",
    "\n",
    "keep_cols = [*index_cols, *[col for cols in keep_cols for col in cols]]\n",
    "\n",
    "data = data.loc[:, keep_cols]\n",
    "\n",
    "data = data[data.year >= year_start]\n",
    "\n",
    "crop_yield = data.copy().loc[:, tuple(index_cols)].reset_index(drop=True)\n",
    "crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "\n",
    "########################################    STANDARDIZE FEATURES    #########################################\n",
    "data = data.set_index(index_cols)\n",
    "data_scaled = StandardScaler().fit_transform(data.values)\n",
    "data = pd.DataFrame(data_scaled, index=data.index).reset_index()\n",
    "data.columns = data.columns.astype(str)\n",
    "\n",
    "#########################################     CALCULATE ANOMALY   #########################################\n",
    "if anomaly:\n",
    "    data[\"yield_mt\"] = np.log10(data.yield_mt.to_numpy() + 1)\n",
    "    data.set_index([\"year\", \"district\"], inplace=True)\n",
    "    var_cols = data.columns\n",
    "    data = data[var_cols] - data.groupby([\"district\"], as_index=True)[\n",
    "        var_cols\n",
    "    ].transform(\"mean\")\n",
    "    data.reset_index(drop=False, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#########################################    HOT ENCODE    #########################################\n",
    "if hot_encode:\n",
    "    index_cols.remove(\"district\")\n",
    "    data = pd.get_dummies(data, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "x_all = data.drop(index_cols, axis=1)\n",
    "y_all = np.log10(data.yield_mt.to_numpy() + 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, test_size=0.2, random_state=seed\n",
    ")\n",
    "kfold = KFold(n_splits=n_splits)\n",
    "# folds = []\n",
    "# for i, (train_index, test_index) in enumerate(kfold.split(x_train)):\n",
    "#     folds.append({\"fold\": i + 1, \"\": list(test_index)})\n",
    "\n",
    "#########################################     K-FOLD CV    #########################################\n",
    "### SETUP\n",
    "tic = time.time()\n",
    "alphas = {\"alpha\": np.logspace(-8, 8, base=10, num=17)}\n",
    "\n",
    "i = 0\n",
    "start = [i]\n",
    "end = [x_train.shape[1]]\n",
    "\n",
    "for var in variable_groups:\n",
    "    i += 12\n",
    "    start.append(i)\n",
    "    end.append(i)\n",
    "start.sort()\n",
    "end.sort()\n",
    "\n",
    "if not hot_encode:\n",
    "    start = start[0:-1]\n",
    "    end = end[0:-1]\n",
    "\n",
    "### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER(S)\n",
    "best_lambdas, best_scores, best_model = kfold_rr_multi_lambda_tuning(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    grid=alphas.get(\"alpha\"),\n",
    "    n_splits=n_splits,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    static_lam=1,\n",
    "    verbose=0,\n",
    "    show_linalg_warning=False,\n",
    "    fit_model_after_tuning=True,\n",
    "    seed=seed,\n",
    ")\n",
    "### PREDICT WITH BEST HYPERPARAMETER(S)\n",
    "val_predictions = cross_val_predict(best_model, X=x_train, y=y_train, cv=kfold)\n",
    "train_predictions = best_model.predict(x_train)\n",
    "test_predictions = best_model.predict(x_test)\n",
    "\n",
    "#########################################     DE-MEAN TRAIN R2    #########################################\n",
    "# train_split = (\n",
    "#     pd.DataFrame(folds).explode(\"\").drop(\"\", axis=1).set_index(x_train.index)\n",
    "# )\n",
    "# train_split[\"split\"] = np.repeat(\"train\", len(x_train))\n",
    "\n",
    "train_split = pd.DataFrame(\n",
    "    np.repeat(\"train\", len(x_train)), columns=[\"split\"], index=x_train.index\n",
    ")\n",
    "train_split = train_split.join(\n",
    "    crop_yield.copy()[crop_yield.index.isin(x_train.index)]\n",
    ")\n",
    "train_split[\"cv_prediction\"] = np.maximum(val_predictions, 0)\n",
    "train_split = demean_by_group(train_split, predicted=\"cv_prediction\", group=[\"district\"])\n",
    "train_split[\"demean_test_prediction\"] = np.repeat(np.nan, len(x_train))\n",
    "\n",
    "#########################################     DE-MEAN TEST R2    #########################################\n",
    "test_split = pd.DataFrame({\"split\": np.repeat(\"test\", len(x_test))}, index=x_test.index)\n",
    "# test_split[\"fold\"] = 6\n",
    "test_split = test_split.join(crop_yield.copy()[crop_yield.index.isin(x_test.index)])\n",
    "test_split[\"test_prediction\"] = np.maximum(best_model.predict(x_test), 0)\n",
    "test_split[\"cv_prediction\"] = np.repeat(np.nan, len(x_test))\n",
    "test_split[\"demean_cv_prediction\"] = np.repeat(np.nan, len(x_test))\n",
    "test_split = demean_by_group(test_split, predicted=\"test_prediction\", group=[\"district\"])\n",
    "\n",
    "d = {\n",
    "    \"variables\": [variable_groups],\n",
    "    \"year_start\": year_start,\n",
    "    \"hot_encode\": hot_encode,\n",
    "    \"anomaly\": anomaly,\n",
    "    \"total_n\": len(x_all),\n",
    "    \"train_n\": len(x_train),\n",
    "    \"test_n\": len(x_test),\n",
    "    \"best_reg_param\": [best_lambdas],\n",
    "    \"mean_of_val_R2\": [best_scores],\n",
    "    \"val_R2\": r2_score(y_train, val_predictions),\n",
    "    \"val_r\": pearsonr(val_predictions, y_train)[0],\n",
    "    \"val_r2\": pearsonr(val_predictions, y_train)[0] ** 2,\n",
    "    \"train_R2\": r2_score(y_train, train_predictions),\n",
    "    \"train_r\": pearsonr(train_predictions, y_train)[0],\n",
    "    \"train_r2\": pearsonr(train_predictions, y_train)[0] ** 2,\n",
    "    \"test_R2\": r2_score(y_test, test_predictions),\n",
    "    \"test_r\": pearsonr(test_predictions, y_test)[0],\n",
    "    \"test_r2\": pearsonr(test_predictions, y_test)[0] ** 2,\n",
    "    \"demean_cv_R2\": r2_score(\n",
    "        train_split.demean_log_yield, train_split.demean_cv_prediction\n",
    "    ),\n",
    "    \"demean_cv_r\": pearsonr(\n",
    "        train_split.demean_log_yield, train_split.demean_cv_prediction\n",
    "    )[0],\n",
    "    \"demean_cv_r2\": pearsonr(\n",
    "        train_split.demean_log_yield, train_split.demean_cv_prediction\n",
    "    )[0]\n",
    "    ** 2,\n",
    "    \"demean_test_R2\": r2_score(\n",
    "        test_split.demean_log_yield, test_split.demean_test_prediction\n",
    "    ),\n",
    "    \"demean_test_r\": pearsonr(\n",
    "        test_split.demean_log_yield, test_split.demean_test_prediction\n",
    "    )[0],\n",
    "    \"demean_test_r2\": pearsonr(\n",
    "        test_split.demean_log_yield, test_split.demean_test_prediction\n",
    "    )[0]\n",
    "    ** 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc70a05-1663-49a7-b36b-365327f4bd7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>district</th>\n",
       "      <th>yield_mt</th>\n",
       "      <th>log_yield</th>\n",
       "      <th>cv_prediction</th>\n",
       "      <th>demean_log_yield</th>\n",
       "      <th>demean_cv_prediction</th>\n",
       "      <th>demean_test_prediction</th>\n",
       "      <th>test_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>train</td>\n",
       "      <td>2017</td>\n",
       "      <td>Mazabuka</td>\n",
       "      <td>2.823767</td>\n",
       "      <td>0.582491</td>\n",
       "      <td>0.427763</td>\n",
       "      <td>0.190994</td>\n",
       "      <td>0.043694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>train</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ndola</td>\n",
       "      <td>2.588668</td>\n",
       "      <td>0.554933</td>\n",
       "      <td>0.503889</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>-0.058730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kafue</td>\n",
       "      <td>2.844356</td>\n",
       "      <td>0.584824</td>\n",
       "      <td>0.508687</td>\n",
       "      <td>0.125010</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>train</td>\n",
       "      <td>2017</td>\n",
       "      <td>Masaiti</td>\n",
       "      <td>2.045396</td>\n",
       "      <td>0.483644</td>\n",
       "      <td>0.559393</td>\n",
       "      <td>-0.039523</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>train</td>\n",
       "      <td>2020</td>\n",
       "      <td>Kalulushi</td>\n",
       "      <td>3.472055</td>\n",
       "      <td>0.650507</td>\n",
       "      <td>0.609615</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kalomo</td>\n",
       "      <td>1.537028</td>\n",
       "      <td>0.404325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>test</td>\n",
       "      <td>2017</td>\n",
       "      <td>Mpulungu</td>\n",
       "      <td>2.719739</td>\n",
       "      <td>0.570512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kawambwa</td>\n",
       "      <td>3.011642</td>\n",
       "      <td>0.603322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.607808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>Chipata</td>\n",
       "      <td>1.915801</td>\n",
       "      <td>0.464758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>Kaoma</td>\n",
       "      <td>1.932044</td>\n",
       "      <td>0.467170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.406449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     split  year   district  yield_mt  log_yield  cv_prediction  \\\n",
       "132  train  2017   Mazabuka  2.823767   0.582491       0.427763   \n",
       "231  train  2019      Ndola  2.588668   0.554933       0.503889   \n",
       "31   train  2016      Kafue  2.844356   0.584824       0.508687   \n",
       "84   train  2017    Masaiti  2.045396   0.483644       0.559393   \n",
       "296  train  2020  Kalulushi  3.472055   0.650507       0.609615   \n",
       "..     ...   ...        ...       ...        ...            ...   \n",
       "57    test  2016     Kalomo  1.537028   0.404325            NaN   \n",
       "124   test  2017   Mpulungu  2.719739   0.570512            NaN   \n",
       "24    test  2016   Kawambwa  3.011642   0.603322            NaN   \n",
       "17    test  2016    Chipata  1.915801   0.464758            NaN   \n",
       "66    test  2016      Kaoma  1.932044   0.467170            NaN   \n",
       "\n",
       "     demean_log_yield  demean_cv_prediction  demean_test_prediction  \\\n",
       "132          0.190994              0.043694                     NaN   \n",
       "231         -0.007168             -0.058730                     NaN   \n",
       "31           0.125010              0.028804                     NaN   \n",
       "84          -0.039523              0.037150                     NaN   \n",
       "296          0.048078              0.012385                     NaN   \n",
       "..                ...                   ...                     ...   \n",
       "57           0.000000                   NaN                0.000000   \n",
       "124          0.000000                   NaN                0.000000   \n",
       "24           0.004752                   NaN                0.001051   \n",
       "17           0.000000                   NaN                0.000000   \n",
       "66           0.037779                   NaN                0.009334   \n",
       "\n",
       "     test_prediction  \n",
       "132              NaN  \n",
       "231              NaN  \n",
       "31               NaN  \n",
       "84               NaN  \n",
       "296              NaN  \n",
       "..               ...  \n",
       "57          0.365072  \n",
       "124         0.553158  \n",
       "24          0.607808  \n",
       "17          0.485300  \n",
       "66          0.406449  \n",
       "\n",
       "[432 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_split, test_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894ab36-7c85-4f7d-bcac-808e9b48ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
