{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aaf7810-5612-46c5-8369-1e95387fe44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q pyhere p_tqdm glum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d64e464-31b8-4c88-bbf5-877a8fa59fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from pyhere import here\n",
    "from datetime import date\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import pickle\n",
    "\n",
    "import pyarrow\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import p_tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneGroupOut, cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr,  pearsonr\n",
    "\n",
    "from prediction_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012168f4-4cf6-4ab5-83f1-73731c8f2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_df = pd.read_csv(here('data', 'climate', 'climate_summary.csv'))\n",
    "climate_df = climate_df.dropna()\n",
    "drop_cols = ['year', 'district', 'yield_mt']\n",
    "ndvi_cols = climate_df.columns[climate_df.columns.to_series().str.contains('ndvi')]\n",
    "keep_cols = [*ndvi_cols, *drop_cols]\n",
    "# climate_df = climate_df.loc[:, keep_cols]\n",
    "climate_df = climate_df[climate_df.year >= 2016]\n",
    "# climate_df = climate_df[climate_df.year != 2011]\n",
    "\n",
    "hot_encode = True\n",
    "# hot_encode = False\n",
    "\n",
    "crop_yield = climate_df.copy().loc[:, tuple(drop_cols)].reset_index(drop = True)\n",
    "crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "\n",
    "########################################    STANDARDIZE FEATURES    #########################################    \n",
    "climate_df = climate_df.set_index(drop_cols) \n",
    "climate_df_scaled = StandardScaler().fit_transform(climate_df.values)\n",
    "climate_df = pd.DataFrame(climate_df_scaled, index=climate_df.index).reset_index()\n",
    "climate_df.columns = climate_df.columns.astype(str)\n",
    "\n",
    "#########################################    HOT ENCODE    ######################################### \n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    climate_df = pd.get_dummies(climate_df, columns = [\"district\"], drop_first = False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "x_all = climate_df.drop(drop_cols, axis = 1) \n",
    "y_all = np.log10(climate_df.yield_mt.to_numpy() + 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0961e12b-344d-47bb-b4b5-202ec8689201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "a = [1 for j in range(x_train.shape[1])] \n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9b990d5d-f696-449f-9c18-5bb2b419ecba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "a = np.repeat(1, x_train.shape[1]).tolist()\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7922d-fe55-4fb4-bf07-efce7de0d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_rr_multi_lambda_tuning(\n",
    "    X, \n",
    "    y,\n",
    "    grid=np.logspace(-8, 8, base = 10, num = 17), \n",
    "    n_splits=5,\n",
    "    start=0, \n",
    "    end=12, \n",
    "    static_lam=1,\n",
    "    verbose=True,\n",
    "    show_linalg_warning=False,\n",
    "    fit_model_after_tuning=True\n",
    "):\n",
    "    if show_linalg_warning:\n",
    "        pass\n",
    "    else:\n",
    "        warnings.filterwarnings(action=\"ignore\", category=LinAlgWarning, module=\"glum\")\n",
    "    \n",
    "    assert (len(start) == len(end)), \"Start and end indexes must have same length\"\n",
    "  \n",
    "    kfold = KFold(n_splits=n_splits)\n",
    "    alpha = {'alpha': [1]}\n",
    "    \n",
    "    if hasattr(start, '__iter__'):\n",
    "        pass\n",
    "    else:\n",
    "        start = [start]; end = [end]\n",
    "        \n",
    "    penalties = [static_lam for j in range(X.shape[1])] \n",
    "    lambdas = []; best_scores = []\n",
    "    \n",
    "    for i in range(len(start)):\n",
    "        \n",
    "        scores = []\n",
    "        \n",
    "        for pen in grid:\n",
    "            \n",
    "            if verbose:\n",
    "                print(pen, end=\" \")\n",
    "                \n",
    "            penalties[start[i]:end[i]] = [pen for j in range(end[i]-start[i])]\n",
    "            \n",
    "            ridge = glm(family=\"normal\", P2=penalties, l1_ratio=0, random_state=42)   \n",
    "            search = GridSearchCV(ridge, alpha, scoring = 'r2', cv = kfold).fit(X, y)\n",
    "            \n",
    "            scores.append(search.best_score_)\n",
    "            \n",
    "        best_lambda = grid[np.argmax(scores)]\n",
    "        penalties[start[i]:end[i]] = [best_lambda for j in range(end[i]-start[i])]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'''\\n\\tBest \\u03BB {i+1}: {best_lambda}\\n\\tVal R2 {i+1}: {scores[np.argmax(scores)]:0.4f}''') \n",
    "        \n",
    "        lambdas.append(best_lambda)\n",
    "        best_scores.append(scores[np.argmax(scores)])\n",
    "        \n",
    "    if fit_model_after_tuning:\n",
    "        \n",
    "        for k in range(len(start)):\n",
    "            penalties[start[k]:end[k]] = [lambdas[k] for j in range(end[k]-start[k])]\n",
    "            \n",
    "        ridge = glm(family=\"normal\", P2=penalties, l1_ratio=0, random_state=42) \n",
    "        model = GridSearchCV(ridge, alpha, scoring = 'r2', cv = kfold).fit(X, y).best_estimator_\n",
    "        \n",
    "    else:\n",
    "        model = np.nan\n",
    "        \n",
    "    return(lambdas, best_scores, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a5d463a1-75eb-43fa-a54c-6f2608e4aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 位 1: 100.0\n",
      "Val R2: 0.8156  \n",
      "\n",
      "Best 位 2: 1.0\n",
      "Val R2: 0.8168  \n",
      "\n",
      "Best 位 3: 0.01\n",
      "\n",
      "Best 位's': [100.0, 1.0, 0.01]\n",
      "Final Val R2: 0.8168  \n",
      "Test R2: 0.8391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_kwargs = {\n",
    "    \"X\": x_train,\n",
    "    \"y\": y_train,\n",
    "    \"locations\": x_train.index,\n",
    "    \"split_col\": x_train.reset_index().index,\n",
    "    \"lambdas\": np.logspace(-8, 8, base = 10, num = 17), \n",
    "    \"return_preds\": True,\n",
    "    \"return_model\": False,\n",
    "    \"svd_solve\": False,\n",
    "    \"allow_linalg_warning_instances\": True,\n",
    "    \"fit_model_after_tuning\": False,\n",
    "    \"intercept\": True,\n",
    "    \"num_folds\": 5,\n",
    "    \"random_state\": 0,\n",
    "}\n",
    "static_lam_idxs_1 = list(range(x_train.shape[1]-(72+24), x_train.shape[1]))\n",
    "static_lam_idxs_2 = [list(range(0, x_train.shape[1]-(72+24))), list(range(x_train.shape[1]-72, x_train.shape[1]))]\n",
    "static_lam_idxs_3 = [list(range(0, x_train.shape[1]-(72+24))), list(range(x_train.shape[1]-(72+24) , x_train.shape[1]-72))]\n",
    "static_lam_idxs   = [list(range(x_train.shape[1]-(72+24), x_train.shape[1]-72)), list(range(x_train.shape[1]-72, x_train.shape[1]))]\n",
    "\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    static_lam_val=0.01,\n",
    "    static_lam_idxs=static_lam_idxs_1,\n",
    "    **solver_kwargs\n",
    ")\n",
    "best_alpha_1_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_1 = solver_kwargs.get(\"lambdas\")[best_alpha_1_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "print(\n",
    "f\"\"\"Best \\u03BB 1: {best_alpha_1}\n",
    "Val R2: {r2_score(truth, preds):0.4f}  \\n\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    static_lam_val=[best_alpha_1, 0.01],\n",
    "    static_lam_idxs=static_lam_idxs_2,\n",
    "    **solver_kwargs\n",
    ")\n",
    "best_alpha_2_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_2 = solver_kwargs.get(\"lambdas\")[best_alpha_2_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "print(\n",
    "f\"\"\"Best \\u03BB 2: {best_alpha_2}\n",
    "Val R2: {r2_score(truth, preds):0.4f}  \\n\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    static_lam_val=[best_alpha_1, best_alpha_2],\n",
    "    static_lam_idxs=static_lam_idxs_3,\n",
    "    **solver_kwargs\n",
    ")\n",
    "best_alpha_3_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_3 = solver_kwargs.get(\"lambdas\")[best_alpha_3_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "print(f\"Best \\u03BB 3: {best_alpha_3}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "model, intercept_term = custom_ridge(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    lam=best_alpha_1, \n",
    "    intercept=True,\n",
    "    static_lam_val=[best_alpha_2, best_alpha_3], \n",
    "    static_lam_idxs=static_lam_idxs\n",
    ")\n",
    "pred_test = np.asarray(x_test).dot(model) + intercept_term \n",
    "pred_test = np.maximum(pred_test, 0)\n",
    "\n",
    "print(\n",
    "f\"\"\"Best \\u03BB's': {[best_alpha_1, best_alpha_2, best_alpha_3]}\n",
    "Final Val R2: {r2_score(truth, preds):0.4f}  \n",
    "Test R2: {r2_score(y_test, pred_test):0.4f}\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20baa923-0075-433e-aa90-c06c4c0f49e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc9114-158c-4080-8813-da018d5f2d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b683dfb7-3e4e-4d39-be22-25bf65ef3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_kwargs = {\n",
    "    \"X\": x_train,\n",
    "    \"y\": y_train,\n",
    "    \"locations\": x_train.index,\n",
    "    \"split_col\": x_train.reset_index().index,\n",
    "    \"lambdas\": np.logspace(-8, 8, base = 10, num = 17), \n",
    "    \"return_preds\": True,\n",
    "    \"return_model\": False,\n",
    "    \"svd_solve\": False,\n",
    "    \"allow_linalg_warning_instances\": True,\n",
    "    \"fit_model_after_tuning\": False,\n",
    "    \"intercept\": True,\n",
    "    \"num_folds\": 5,\n",
    "    \"random_state\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062502e9-86b6-4b88-90ee-9940f2177219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 108)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]-(72+24), x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "625f0a2c-a1e8-430b-b1f2-54db13dfadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "Best 位 1: 100.0\n",
      "Val R2: 0.8122642529351547  :0.4f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static_lam_idxs_1 = list(range(x_train.shape[1]-(72+24), x_train.shape[1]))\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    static_lam_val=1e-10,\n",
    "    static_lam_idxs=static_lam_idxs_1,\n",
    "    **solver_kwargs\n",
    ")\n",
    "\n",
    "best_alpha_1_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_1 = solver_kwargs.get(\"lambdas\")[best_alpha_1_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "print(\n",
    "f\"\"\"Best \\u03BB 1: {best_alpha_1}\n",
    "Val R2: {r2_score(truth, preds)}  :0.4f\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad8d16f4-2346-4076-a06e-057779dabf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 12), (36, 108))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 0, x_train.shape[1]-(72+24) ), ( x_train.shape[1]-72, x_train.shape[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f82eb6dd-545e-402b-af98-a66f615a5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=1000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=10000000.0: \n",
      "we will allow this model upon model selection\n",
      "linalg warning on lambda=100000000.0: \n",
      "we will allow this model upon model selection\n",
      "Best 位 2: 1.0\n",
      "Val R2: 0.8156877968683461  :0.4f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static_lam_idxs_2 = [list(range(0, x_train.shape[1]-(72+24))), list(range(x_train.shape[1]-72, x_train.shape[1]))]\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    static_lam_val=[best_alpha_1, 1e-10],\n",
    "    static_lam_idxs=static_lam_idxs_2,\n",
    "    **solver_kwargs\n",
    ")\n",
    "best_alpha_2_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_2 = solver_kwargs.get(\"lambdas\")[best_alpha_2_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "print(\n",
    "f\"\"\"Best \\u03BB 2: {best_alpha_2}\n",
    "Val R2: {r2_score(truth, preds)}  :0.4f\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "641b07f2-8a6b-459d-86ca-c00710e07cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 12), (12, 36))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 0, x_train.shape[1]-(72+24) ), ( x_train.shape[1]-(72+24) , x_train.shape[1]-72 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac10f522-7dc0-438b-bee2-96772225cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 位 3: 0.01\n",
      "Val R2: 0.8167894610473784  :0.4f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static_lam_idxs_3 = [list(range(0, x_train.shape[1]-(72+24))), list(range(x_train.shape[1]-(72+24) , x_train.shape[1]-72))]\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    static_lam_val=[best_alpha_1, best_alpha_2],\n",
    "    static_lam_idxs=static_lam_idxs_3,\n",
    "    **solver_kwargs\n",
    ")\n",
    "best_alpha_3_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_3 = solver_kwargs.get(\"lambdas\")[best_alpha_3_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "print(\n",
    "f\"\"\"Best \\u03BB 3: {best_alpha_3}\n",
    "Val R2: {r2_score(truth, preds)}  :0.4f\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aead4391-78ce-4da5-828f-0d75c0a844cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 36), (36, 108))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( x_train.shape[1]-(72+24) , x_train.shape[1]-72 ), ( x_train.shape[1]-72 , x_train.shape[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76236795-9a1c-4cff-9ff2-b22e0b39fa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 位's': [100.0, 1.0, 0.01]\n",
      "Val R2: 0.8167894610473784  :0.4f\n",
      "Test R2: 0.8391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static_lam_idxs = [list(range(x_train.shape[1]-(72+24), x_train.shape[1]-72)), list(range(x_train.shape[1]-72, x_train.shape[1]))]\n",
    "model, intercept_term = custom_ridge(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    lam=best_alpha_1, \n",
    "    intercept=True,\n",
    "    static_lam_val=[best_alpha_2, best_alpha_3], \n",
    "    static_lam_idxs=static_lam_idxs\n",
    ")\n",
    "pred_test = np.asarray(x_test).dot(model) + intercept_term \n",
    "pred_test = np.maximum(pred_test, 0)\n",
    "\n",
    "print(\n",
    "f\"\"\"Best \\u03BB's': {[best_alpha_1, best_alpha_2, best_alpha_3]}\n",
    "Val R2: {r2_score(truth, preds)}  :0.4f\n",
    "Test R2: {r2_score(y_test, pred_test):0.4f}\\n\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84776a9f-c93d-411b-b27b-1680fef0a948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfb965-8d16-4ce2-aa84-2f8ef39bfb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043cade-b0e1-4d0e-b8d9-f12f3861d10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0b15d-b67d-4d08-96ec-8d1c292e3112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069f3d8e-a6d3-4296-8961-79fc459022c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "import task_modeling_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e9b03d-0841-45f2-a229-6c306b9f6d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-08, 1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01,\n",
       "       1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07,\n",
       "       1.e+08])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "alphas.get('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f84358d-827a-44f1-bf46-62269f37a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1 1.0 10.0 100.0 1000.0 10000.0 100000.0 1000000.0 10000000.0 100000000.0 \n",
      "\tBest 位 1: 0.01\n",
      "\tVal R2 1: 0.7937\n",
      "1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1 1.0 10.0 100.0 1000.0 10000.0 100000.0 1000000.0 10000000.0 100000000.0 \n",
      "\tBest 位 2: 0.0001\n",
      "\tVal R2 2: 0.7944\n",
      "Total time: 2.33 minutes\n",
      "Final Val R2: 0.8058\n",
      "Final Test R2: 0.8304\n"
     ]
    }
   ],
   "source": [
    "best_lam, res, model = kfold_rr_multi_lambda_tuning(\n",
    "    x_train, y_train, \n",
    "    grid=np.logspace(-8, 8, base = 10, num = 17), \n",
    "    start=[0, 36],\n",
    "    end=[36, 108], \n",
    "    static_lam=1e-16,\n",
    "    verbose=True,\n",
    "    show_linalg_warning=False,\n",
    "    fit_model_after_tuning=True\n",
    ")\n",
    "val_predictions = cross_val_predict(model, X = x_train, y = y_train, cv = kfold) \n",
    "print(f\"\"\"Final Val R2: {r2_score(y_train, val_predictions):0.4f}\n",
    "Final Test R2: {r2_score(y_test, model.predict(x_test)):0.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6557c59-e6bc-4ed6-8817-48fbfc9e5497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1 1.0 10.0 100.0 1000.0 10000.0 100000.0 1000000.0 10000000.0 100000000.0 \n",
      "\tBest 位 1: 0.1\n",
      "\tVal R2 1: 0.7899\n",
      "1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1 1.0 10.0 100.0 1000.0 10000.0 100000.0 1000000.0 10000000.0 100000000.0 \n",
      "\tBest 位 2: 0.01\n",
      "\tVal R2 2: 0.7987\n",
      "1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1 1.0 10.0 100.0 1000.0 10000.0 100000.0 1000000.0 10000000.0 100000000.0 \n",
      "\tBest 位 3: 0.01\n",
      "\tVal R2 3: 0.7994\n",
      "1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1 1.0 10.0 100.0 1000.0 10000.0 100000.0 1000000.0 10000000.0 100000000.0 \n",
      "\tBest 位 4: 0.0001\n",
      "\tVal R2 4: 0.8016\n",
      "Final Val R2: 0.8127\n",
      "Final Test R2: 0.8381\n"
     ]
    }
   ],
   "source": [
    "best_lam, res, model = kfold_rr_multi_lambda_tuning(\n",
    "    x_train, y_train, grid=np.logspace(-8, 8, base = 10, num = 17), \n",
    "    start=[0, 12, 24, 36], end=[12, 24, 36, 108], static_lam=1e-16\n",
    ")\n",
    "val_predictions = cross_val_predict(model, X = x_train, y = y_train, cv = kfold) \n",
    "print(f\"\"\"Final Val R2: {r2_score(y_train, val_predictions):0.4f}\n",
    "Final Test R2: {r2_score(y_test, model.predict(x_test)):0.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e95643-369d-462c-86dd-9cc8ec301176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4964c2-64e9-40c9-b3d8-54a3bfdfb26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 594 ms, sys: 2.6 s, total: 3.2 s\n",
      "Wall time: 794 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lambdas=np.logspace(-8, 8, base = 10, num = 17)\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    locations=x_train.index,\n",
    "    split_col=x_train.reset_index().index,\n",
    "    lambdas=lambdas,\n",
    "    static_lam_val=1e-20,\n",
    "    static_lam_idxs=list(range(0,x_train.shape[1]-72)),\n",
    "    intercept=True,\n",
    "    num_folds=5,\n",
    "    random_state=0,\n",
    "    return_preds=True,\n",
    "    return_model=False,\n",
    "    svd_solve=False,\n",
    "    allow_linalg_warning_instances=True,\n",
    "    fit_model_after_tuning=False,\n",
    ")\n",
    "best_alpha_1_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_1 = lambdas[best_alpha_1_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "# print(\n",
    "# f\"\"\"Best alpha 1: {best_alpha_1}\n",
    "# Val R2: {r2_score(truth, preds):0.4f}\\n\"\"\"\n",
    "# )\n",
    "\n",
    "kfold_results = kfold_solve_custom_split_col(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    locations=x_train.index,\n",
    "    split_col=x_train.reset_index().index,\n",
    "    lambdas=lambdas,\n",
    "    static_lam_val=best_alpha_1,\n",
    "    static_lam_idxs=list(range(x_train.shape[1]-72, x_train.shape[1])),\n",
    "    intercept=True,\n",
    "    num_folds=5,\n",
    "    random_state=0,\n",
    "    return_preds=True,\n",
    "    return_model=False,\n",
    "    svd_solve=False,\n",
    "    allow_linalg_warning_instances=True,\n",
    "    fit_model_after_tuning=False,\n",
    ")\n",
    "best_alpha_2_idx = interpret_kfold_results(kfold_results, \"r2_score\")[0][0][0]\n",
    "best_alpha_2 = lambdas[best_alpha_2_idx]\n",
    "preds = np.maximum(get_pred_truth_locs(kfold_results)[0].flatten(), 0)\n",
    "truth = get_pred_truth_locs(kfold_results)[1].flatten()\n",
    "\n",
    "\n",
    "model, intercept_term = custom_ridge(\n",
    "    X=x_train,\n",
    "    y=y_train,\n",
    "    lam=best_alpha_1, \n",
    "    intercept=True,\n",
    "    static_lam_val=best_alpha_2,\n",
    "    static_lam_idxs=list(range(x_train.shape[1]-72, x_train.shape[1])))\n",
    "pred_test = np.asarray(x_test).dot(model) + intercept_term \n",
    "pred_test = np.maximum(pred_test, 0)\n",
    "\n",
    "# print(\n",
    "# f\"\"\"Best alpha 2: {best_alpha_2}\n",
    "# Fianl Val R2: {r2_score(truth, preds):0.4f}\n",
    "# Final test R2: {r2_score(y_test, pred_test):0.4f}\\n\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffc9fc-32ea-47c7-93fc-0d0aea13d688",
   "metadata": {},
   "source": [
    "# NDVI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50874f01-370e-40eb-84c1-4f98234d2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val  R2: 0.7802 \n",
      "Test R2: 0.8085 \n",
      "\n",
      "Demean Val  R2: 0.0921 \n",
      "Demean Test R2: 0.4394\n"
     ]
    }
   ],
   "source": [
    "climate_df = pd.read_csv(here('data', 'climate', 'climate_summary.csv'))\n",
    "climate_df = climate_df.dropna()\n",
    "drop_cols = ['year', 'district', 'yield_mt']\n",
    "ndvi_cols = climate_df.columns[climate_df.columns.to_series().str.contains('ndvi')]\n",
    "keep_cols = [*ndvi_cols, *drop_cols]\n",
    "climate_df = climate_df.loc[:, keep_cols]\n",
    "climate_df = climate_df[climate_df.year >= 2016]\n",
    "\n",
    "hot_encode = True\n",
    "# hot_encode = False\n",
    "\n",
    "crop_yield = climate_df.copy().loc[:, tuple(drop_cols)].reset_index(drop = True)\n",
    "crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "\n",
    "#########################################    HOT ENCODE    ######################################### \n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    climate_df = pd.get_dummies(climate_df, columns = [\"district\"], drop_first = False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#########################################    STANDARDIZE FEATURES    #########################################    \n",
    "climate_df = climate_df.set_index(drop_cols) \n",
    "climate_df_scaled = StandardScaler().fit_transform(climate_df.values)\n",
    "climate_df = pd.DataFrame(climate_df_scaled, index=climate_df.index).reset_index()\n",
    "climate_df.columns = climate_df.columns.astype(str)\n",
    "\n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "x_all = climate_df.drop(drop_cols, axis = 1) \n",
    "y_all = np.log10(climate_df.yield_mt.to_numpy() + 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################################     K-FOLD CV   ###########################################\n",
    "### SETUP\n",
    "alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "kfold = KFold()\n",
    "ridge = Ridge(random_state=0)    \n",
    "### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "ridge_reg = GridSearchCV(ridge, alphas, scoring = 'r2', cv = kfold)\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "best_model = ridge_reg.best_estimator_\n",
    "### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "val_predictions = cross_val_predict(best_model, X = x_train, y = y_train, cv = kfold)   \n",
    "train_predictions = best_model.predict(x_train)\n",
    "test_predictions  = best_model.predict(x_test)\n",
    "\n",
    "#########################################     DE-MEAN R2    #########################################    \n",
    "crop_yield[\"prediction\"] = np.maximum(best_model.predict(x_all), 0)\n",
    "\n",
    "train_split = pd.DataFrame(np.repeat('train', len(x_train)), columns = ['split'], index = x_train.index)\n",
    "train_split = train_split.join(crop_yield.copy()[crop_yield.index.isin(x_train.index)])\n",
    "train_split['cv_prediction'] = np.maximum(val_predictions, 0)\n",
    "train_split[\"demean_cv_yield\"] = train_split[\"log_yield\"]-train_split.groupby('district')['log_yield'].transform('mean')\n",
    "train_split[\"demean_cv_prediction\"] = train_split[\"cv_prediction\"]-train_split.groupby('district')['cv_prediction'].transform('mean')\n",
    "\n",
    "test_split = pd.DataFrame(np.repeat('test', len(x_test)), columns = ['split'], index = x_test.index)\n",
    "test_split = test_split.join(crop_yield.copy()[crop_yield.index.isin(x_test.index)])\n",
    "test_split['cv_prediction'] = np.repeat(np.nan, len(x_test))\n",
    "test_split[\"demean_cv_yield\"] = np.repeat(np.nan, len(x_test))\n",
    "test_split[\"demean_cv_prediction\"] = np.repeat(np.nan, len(x_test))\n",
    "\n",
    "predictions = pd.concat([train_split, test_split])\n",
    "\n",
    "test_split[\"demean_test_yield\"] = test_split[\"log_yield\"]-test_split.groupby('district')['log_yield'].transform('mean')\n",
    "test_split[\"demean_test_prediction\"] = test_split[\"prediction\"]-test_split.groupby('district')['prediction'].transform('mean')\n",
    "\n",
    "print(f'Val  R2: {r2_score(y_train, val_predictions):0.4f}',\n",
    "      f'\\nTest R2: {r2_score(y_test, test_predictions):0.4f}',\n",
    "     f'\\n\\nDemean Val  R2: {r2_score(train_split.demean_cv_yield, train_split.demean_cv_prediction):0.4f}',\n",
    "     f'\\nDemean Test R2: {r2_score(test_split.demean_test_yield, test_split.demean_test_prediction):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3eef3-18bb-4b2b-8da8-02bc0230bda2",
   "metadata": {},
   "source": [
    "# Precipitation, Temperature, and NDVI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1840a92e-3eca-4039-a5d4-6a8367316314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val  R2: 0.8044 \n",
      "Test R2: 0.8297 \n",
      "\n",
      "Demean Val  R2: 0.1723 \n",
      "Demean Test R2: 0.5297\n"
     ]
    }
   ],
   "source": [
    "climate_df = pd.read_csv(here('data', 'climate', 'climate_summary.csv'))\n",
    "climate_df = climate_df.dropna()\n",
    "drop_cols = ['year', 'district', 'yield_mt']\n",
    "climate_df = climate_df[climate_df.year >= 2016]\n",
    "\n",
    "hot_encode = True\n",
    "# hot_encode = False\n",
    "\n",
    "crop_yield = climate_df.copy().loc[:, tuple(drop_cols)].reset_index(drop = True)\n",
    "crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "\n",
    "#########################################    HOT ENCODE    ######################################### \n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    climate_df = pd.get_dummies(climate_df, columns = [\"district\"], drop_first = False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#########################################    STANDARDIZE FEATURES    #########################################    \n",
    "climate_df = climate_df.set_index(drop_cols) \n",
    "climate_df_scaled = StandardScaler().fit_transform(climate_df.values)\n",
    "climate_df = pd.DataFrame(climate_df_scaled, index=climate_df.index).reset_index()\n",
    "climate_df.columns = climate_df.columns.astype(str)\n",
    "\n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "x_all = climate_df.drop(drop_cols, axis = 1) \n",
    "y_all = np.log10(climate_df.yield_mt.to_numpy() + 1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################################     K-FOLD CV   ###########################################\n",
    "### SETUP\n",
    "alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "kfold = KFold()\n",
    "ridge = Ridge(random_state=0)      \n",
    "### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "ridge_reg = GridSearchCV(ridge, alphas, scoring = 'r2', cv = kfold)\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "best_model = ridge_reg.best_estimator_\n",
    "### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "val_predictions = cross_val_predict(best_model, X = x_train, y = y_train, cv = kfold)   \n",
    "train_predictions = best_model.predict(x_train)\n",
    "test_predictions  = best_model.predict(x_test)\n",
    "\n",
    "#########################################     DE-MEAN R2    #########################################    \n",
    "crop_yield[\"prediction\"] = np.maximum(best_model.predict(x_all), 0)\n",
    "\n",
    "train_split = pd.DataFrame(np.repeat('train', len(x_train)), columns = ['split'], index = x_train.index)\n",
    "train_split = train_split.join(crop_yield.copy()[crop_yield.index.isin(x_train.index)])\n",
    "train_split['cv_prediction'] = np.maximum(val_predictions, 0)\n",
    "train_split[\"demean_cv_yield\"] = train_split[\"log_yield\"]-train_split.groupby('district')['log_yield'].transform('mean')\n",
    "train_split[\"demean_cv_prediction\"] = train_split[\"cv_prediction\"]-train_split.groupby('district')['cv_prediction'].transform('mean')\n",
    "\n",
    "test_split = pd.DataFrame(np.repeat('test', len(x_test)), columns = ['split'], index = x_test.index)\n",
    "test_split = test_split.join(crop_yield.copy()[crop_yield.index.isin(x_test.index)])\n",
    "test_split['cv_prediction'] = np.repeat(np.nan, len(x_test))\n",
    "test_split[\"demean_cv_yield\"] = np.repeat(np.nan, len(x_test))\n",
    "test_split[\"demean_cv_prediction\"] = np.repeat(np.nan, len(x_test))\n",
    "\n",
    "predictions = pd.concat([train_split, test_split])\n",
    "\n",
    "test_split[\"demean_test_yield\"] = test_split[\"log_yield\"]-test_split.groupby('district')['log_yield'].transform('mean')\n",
    "test_split[\"demean_test_prediction\"] = test_split[\"prediction\"]-test_split.groupby('district')['prediction'].transform('mean')\n",
    "\n",
    "print(f'Val  R2: {r2_score(y_train, val_predictions):0.4f}',\n",
    "      f'\\nTest R2: {r2_score(y_test, test_predictions):0.4f}',\n",
    "     f'\\n\\nDemean Val  R2: {r2_score(train_split.demean_cv_yield, train_split.demean_cv_prediction):0.4f}',\n",
    "     f'\\nDemean Test R2: {r2_score(test_split.demean_test_yield, test_split.demean_test_prediction):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b577bc71-d766-42fe-adad-93286a5a19ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792567922097444"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3dfe35-025c-4b06-8b2b-23b4f223f11b",
   "metadata": {},
   "source": [
    "# NDVI Anomaly Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f20bb178-7708-45e3-aa68-124c88541b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val  R2: 0.4449\n",
      "Test R2: 0.4293\n"
     ]
    }
   ],
   "source": [
    "climate_df = pd.read_csv(here('data', 'climate', 'climate_summary.csv'))\n",
    "climate_df = climate_df.dropna()\n",
    "drop_cols = ['year', 'district', 'yield_mt']\n",
    "ndvi_cols = climate_df.columns[climate_df.columns.to_series().str.contains('ndvi')]\n",
    "keep_cols = [*ndvi_cols, *drop_cols]\n",
    "climate_df = climate_df.loc[:, keep_cols]\n",
    "climate_df = climate_df[climate_df.year >= 2016]\n",
    "\n",
    "crop_yield = climate_df.copy().loc[:, tuple(drop_cols)].reset_index(drop = True)\n",
    "crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "\n",
    "#########################################    STANDARDIZE FEATURES    #########################################    \n",
    "climate_df = climate_df.set_index(drop_cols) \n",
    "climate_df_scaled = StandardScaler().fit_transform(climate_df.values)\n",
    "climate_df = pd.DataFrame(climate_df_scaled, index=climate_df.index).reset_index()\n",
    "climate_df.columns = climate_df.columns.astype(str)\n",
    "\n",
    "#########################################     CALCULATE ANOMALY   #########################################\n",
    "climate_df['yield_mt'] = np.log10(climate_df.yield_mt.to_numpy() + 1)\n",
    "climate_df.set_index(['year', 'district'], inplace=True)\n",
    "var_cols = climate_df.columns\n",
    "climate_df = climate_df[var_cols] - climate_df.groupby(['district'], as_index=True)[var_cols].transform('mean')\n",
    "climate_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "x_all = climate_df.drop(drop_cols, axis = 1) \n",
    "y_all = climate_df.yield_mt\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################################     K-FOLD CV   ###########################################\n",
    "### SETUP\n",
    "alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "kfold = KFold()\n",
    "ridge = Ridge(random_state=0)      \n",
    "### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "ridge_reg = GridSearchCV(ridge, alphas, scoring = 'r2', cv = kfold)\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "best_model = ridge_reg.best_estimator_\n",
    "### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "val_predictions   = cross_val_predict(best_model, X = x_train, y = y_train, cv = kfold)   \n",
    "train_predictions = best_model.predict(x_train)\n",
    "test_predictions  = best_model.predict(x_test)\n",
    "\n",
    "#########################################     DE-MEAN R2    #########################################    \n",
    "crop_yield[\"prediction\"] = best_model.predict(x_all)\n",
    "\n",
    "train_split = pd.DataFrame(np.repeat('train', len(x_train)), columns = ['split'], index = x_train.index)\n",
    "train_split = train_split.join(crop_yield.copy()[crop_yield.index.isin(x_train.index)])\n",
    "train_split['cv_prediction'] = val_predictions\n",
    "\n",
    "test_split = pd.DataFrame(np.repeat('test', len(x_test)), columns = ['split'], index = x_test.index)\n",
    "test_split = test_split.join(crop_yield.copy()[crop_yield.index.isin(x_test.index)])\n",
    "test_split['cv_prediction'] = np.repeat(np.nan, len(x_test))\n",
    "\n",
    "predictions = pd.concat([train_split, test_split])\n",
    "\n",
    "print(f'Val  R2: {r2_score(y_train, val_predictions):0.4f}\\nTest R2: {r2_score(y_test, test_predictions):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c574bb5-882f-4588-ae97-44af906398a6",
   "metadata": {},
   "source": [
    "# Precipitation, Temperature, and NDVI  Anomaly model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "102e934f-c6e8-4222-9956-a621dda75298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val  R2: 0.5284\n",
      "Test R2: 0.5145\n"
     ]
    }
   ],
   "source": [
    "climate_df = pd.read_csv(here('data', 'climate', 'climate_summary.csv'))\n",
    "climate_df = climate_df.dropna()\n",
    "drop_cols = ['year', 'district', 'yield_mt']\n",
    "climate_df = climate_df[climate_df.year >= 2016]\n",
    "\n",
    "crop_yield = climate_df.copy().loc[:, tuple(drop_cols)].reset_index(drop = True)\n",
    "crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "\n",
    "#########################################    STANDARDIZE FEATURES    #########################################    \n",
    "climate_df = climate_df.set_index(drop_cols) \n",
    "climate_df_scaled = StandardScaler().fit_transform(climate_df.values)\n",
    "climate_df = pd.DataFrame(climate_df_scaled, index=climate_df.index).reset_index()\n",
    "climate_df.columns = climate_df.columns.astype(str)\n",
    "\n",
    "#########################################     CALCULATE ANOMALY   #########################################\n",
    "climate_df['yield_mt'] = np.log10(climate_df.yield_mt.to_numpy() + 1)\n",
    "climate_df.set_index(['year', 'district'], inplace=True)\n",
    "var_cols = climate_df.columns\n",
    "climate_df = climate_df[var_cols] - climate_df.groupby(['district'], as_index=True)[var_cols].transform('mean')\n",
    "climate_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "x_all = climate_df.drop(drop_cols, axis = 1) \n",
    "y_all = climate_df.yield_mt\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################################     K-FOLD CV   ###########################################\n",
    "### SETUP\n",
    "alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "kfold = KFold()\n",
    "ridge = Ridge(random_state=0)      \n",
    "### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "ridge_reg = GridSearchCV(ridge, alphas, scoring = 'r2', cv = kfold)\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "best_model = ridge_reg.best_estimator_\n",
    "### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "val_predictions   = cross_val_predict(best_model, X = x_train, y = y_train, cv = kfold)   \n",
    "train_predictions = best_model.predict(x_train)\n",
    "test_predictions  = best_model.predict(x_test)\n",
    "\n",
    "#########################################     DE-MEAN R2    #########################################    \n",
    "crop_yield[\"prediction\"] = best_model.predict(x_all)\n",
    "\n",
    "train_split = pd.DataFrame(np.repeat('train', len(x_train)), columns = ['split'], index = x_train.index)\n",
    "train_split = train_split.join(crop_yield.copy()[crop_yield.index.isin(x_train.index)])\n",
    "train_split['cv_prediction'] = val_predictions\n",
    "\n",
    "test_split = pd.DataFrame(np.repeat('test', len(x_test)), columns = ['split'], index = x_test.index)\n",
    "test_split = test_split.join(crop_yield.copy()[crop_yield.index.isin(x_test.index)])\n",
    "test_split['cv_prediction'] = np.repeat(np.nan, len(x_test))\n",
    "\n",
    "predictions = pd.concat([train_split, test_split])\n",
    "\n",
    "print(f'Val  R2: {r2_score(y_train, val_predictions):0.4f}\\nTest R2: {r2_score(y_test, test_predictions):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb25ab-e9b1-4bfc-b2e9-a3f4c106a446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
