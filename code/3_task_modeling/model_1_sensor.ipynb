{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa45eeff-1bf9-40bf-a5ff-9b412d0a787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import warnings\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from pyhere import here\n",
    "from datetime import date\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import pickle\n",
    "\n",
    "import pyarrow\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import p_tqdm\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneGroupOut, cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr,  pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f32198-986c-413d-9e1a-47faf0e55b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(string):\n",
    "    return string.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "point_pattern = re.compile(\"20k-points\")\n",
    "wa_pattern = re.compile(\"cm-False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353ccafc-8838-44ad-9e39-8ed4595cd09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = here(\"data\")\n",
    "directory = here(\"data\", \"random_features\", \"summary\")\n",
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "files = os.listdir(directory)\n",
    "files = [f for f in files if f not in ('.gitkeep', '.ipynb_checkpoints')]\n",
    "files = [f for f in files if not (bool(point_pattern.search(f)) & bool(wa_pattern.search(f)))]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6877398-a7af-4d30-8be5-f2f5b92c8a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramlist = list(itertools.product(files, [True, False]))\n",
    "len(paramlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ae5aca-1f61-4214-a348-11ca6f4b5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params):\n",
    "#########################################     SET PARAMS    #########################################\n",
    "    file         = params[0]\n",
    "    hot_encode   = params[1]\n",
    "    f            = file.split(sep=\"_\")\n",
    "    satellite    = f[0]\n",
    "    bands        = f[1].replace(\"bands-\", \"\")\n",
    "    country_code = f[2]\n",
    "    points       = f[3].replace(\"k-points\", \"\")\n",
    "    num_features = f[4].replace(\"-features\", \"\")\n",
    "    yrs          = f[5].replace(\"yr-\", \"\").split(sep=\"-\")\n",
    "    mns          = f[6].replace(\"mn-\", \"\").split(sep=\"-\")\n",
    "    limit_months = str2bool(f[7].replace(\"lm-\", \"\"))\n",
    "    crop_mask    = str2bool(f[8].replace(\"cm-\", \"\"))\n",
    "    weighted_avg = str2bool(f[9].replace(\"wa-\", \"\"))\n",
    "    years        = range(int(yrs[0]), int(yrs[1])+1)\n",
    "    month_range  = list(range(int(mns[0]), int(mns[1])+1))\n",
    "    alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "    \n",
    "#########################################     READ DATA    #########################################\n",
    "    fn = f\"{directory}/{file}\"\n",
    "    features = pd.read_feather(fn)\n",
    "     \n",
    "    drop_cols = ['district', 'year', 'yield_mt', \"crop_perc\"]\n",
    "            \n",
    "    if weighted_avg:\n",
    "        drop_cols.remove(\"crop_perc\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    crop_yield = features.copy().loc[:, tuple(drop_cols)]\n",
    "    \n",
    "    if hot_encode:\n",
    "        drop_cols.remove(\"district\")\n",
    "        features = pd.get_dummies(features, columns=[\"district\"], drop_first=False)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "    x_all = features.drop(drop_cols, axis = 1) \n",
    "    y_all = np.log10(features.yield_mt.to_numpy() + 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################################     K-FOLD CV    ###########################################\n",
    "    kfold = KFold()\n",
    "    ridge = Ridge()\n",
    "    ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "    kfold_ridge_reg = GridSearchCV(ridge, alphas, scoring = 'r2', cv = kfold)\n",
    "    kfold_ridge_reg.fit(x_train, y_train)\n",
    "    kfold_best_model = kfold_ridge_reg.best_estimator_\n",
    "    ### VALIDATION PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "    kfold_val_predictions = cross_val_predict(kfold_best_model, X = x_train, y = y_train, cv = kfold)   \n",
    "    ### TRAIN AND TEST PREDICT\n",
    "    y_pred_train_k = kfold_best_model.predict(x_train)\n",
    "    y_pred_test_k  = kfold_best_model.predict(x_test)\n",
    "\n",
    "#########################################     LOGO SPLIT   ###########################################\n",
    "    x_train_g = features[features.year < max(features.year)].drop(drop_cols, axis=1)\n",
    "    y_train_g = features[features.year < max(features.year)].yield_mt\n",
    "    g_train_g = features[features.year < max(features.year)].year.ravel()\n",
    "\n",
    "    x_test_g = features[features.year == max(features.year)].drop(drop_cols, axis=1)\n",
    "    y_test_g = features[features.year == max(features.year)].yield_mt\n",
    "    g_test_g = features[features.year == max(features.year)].year\n",
    "\n",
    "#########################################     LOGO CV    ###########################################\n",
    "    logo = LeaveOneGroupOut()\n",
    "    ridge = Ridge()\n",
    "    ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "    logo_ridge_reg = GridSearchCV(ridge, alphas, scoring='r2', cv=logo)\n",
    "    logo_ridge_reg.fit(x_train_g, y_train_g, groups=g_train_g)\n",
    "    logo_best_model = logo_ridge_reg.best_estimator_\n",
    "    ### VALIDATION PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "    logo_val_predictions = cross_val_predict(logo_best_model, X=x_train_g, y=y_train_g, groups=g_train_g, cv=logo)   \n",
    "    ### TRAIN AND TEST PREDICT\n",
    "    logo_train_pred = logo_best_model.predict(x_train_g)\n",
    "    logo_test_pred  = logo_best_model.predict(x_test_g)\n",
    "    \n",
    "#########################################     DE-MEAN R2    #########################################    \n",
    "    crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "    crop_yield[\"district_yield_mean\"] = crop_yield.groupby('district')['log_yield'].transform('mean')\n",
    "    crop_yield[\"demean_yield\"] = crop_yield[\"log_yield\"] - crop_yield[\"district_yield_mean\"]\n",
    "    \n",
    "    crop_yield[\"k-fold_prediction\"] = np.maximum(kfold_best_model.predict(x_all), 0)\n",
    "    crop_yield[\"k-fold_district_prediction_mean\"] = crop_yield.groupby('district')['k-fold_prediction'].transform('mean')\n",
    "    crop_yield[\"k-fold_demean_prediction\"] = crop_yield[\"k-fold_prediction\"] - crop_yield[\"k-fold_district_prediction_mean\"]\n",
    "    \n",
    "    crop_yield[\"logo_prediction\"] = np.maximum(logo_best_model.predict(x_all), 0)\n",
    "    crop_yield[\"logo_district_prediction_mean\"] = crop_yield.groupby('district')['logo_prediction'].transform('mean')\n",
    "    crop_yield[\"logo_demean_prediction\"] = crop_yield[\"logo_prediction\"] - crop_yield[\"logo_district_prediction_mean\"]\n",
    "    \n",
    "#########################################     SAVE MODELS   #########################################  \n",
    "    model_fn_suffix = file.replace('_summary.feather', '')\n",
    "    k_model_fn  = f'k-fold-cv_rr-model_{model_fn_suffix}_he-{hot_encode}.pkl'\n",
    "    logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}_he-{hot_encode}.pkl'\n",
    "    \n",
    "    with open(here('models', k_model_fn),'wb') as f:\n",
    "        pickle.dump(kfold_best_model, f)\n",
    "        \n",
    "    with open(here('models', logo_model_fn),'wb') as f:\n",
    "        pickle.dump(logo_best_model, f)\n",
    "        \n",
    "#########################################     SAVE RESULTS    #########################################\n",
    "    d = {\n",
    "        'country': country_code,\n",
    "        'satellite': satellite,\n",
    "        'bands': bands,\n",
    "        'num_features': num_features,\n",
    "        'points': points, \n",
    "        'month_range': f'{min(month_range)}-{max(month_range)}',\n",
    "        \n",
    "        'limit_months': limit_months,\n",
    "        'crop_mask': crop_mask,\n",
    "        'weighted_avg': weighted_avg,\n",
    "        'hot_encode': hot_encode,\n",
    "        \n",
    "        'kfold_total_n': len(x_all),\n",
    "        'kfold_train_n': len(x_train),\n",
    "        'kfold_test_n': len(x_test),\n",
    "        \n",
    "        'kfold_best_reg_param': list(kfold_ridge_reg.best_params_.values())[0],\n",
    "        'kfold_mean_of_val_R2s': kfold_ridge_reg.best_score_,\n",
    "        'kfold_val_R2': r2_score(y_train, kfold_val_predictions),\n",
    "        'kfold_val_r' : pearsonr(kfold_val_predictions, y_train)[0],\n",
    "        'kfold_val_r2' : pearsonr(kfold_val_predictions, y_train)[0] ** 2,\n",
    "        \n",
    "        'kfold_train_R2': r2_score(y_train, y_pred_train_k),\n",
    "        'kfold_train_r': pearsonr(y_pred_train_k, y_train)[0],\n",
    "        'kfold_train_r2': pearsonr(y_pred_train_k, y_train)[0] ** 2,\n",
    "        \n",
    "        'kfold_test_R2': r2_score(y_test, y_pred_test_k),\n",
    "        'kfold_test_r': pearsonr(y_pred_test_k, y_test)[0],\n",
    "        'kfold_test_r2': pearsonr(y_pred_test_k, y_test)[0] ** 2,\n",
    "        \n",
    "        'logo_total_n': len(x_all),\n",
    "        'logo_train_n': len(x_train),\n",
    "        'logo_test_n': len(x_test),    \n",
    "        \n",
    "        'logo_best_reg_param': list(logo_ridge_reg.best_params_.values())[0],      \n",
    "        'logo_mean_of_val_R2s' : logo_ridge_reg.best_score_,\n",
    "        'logo_val_R2' : r2_score(y_train_g, logo_val_predictions),\n",
    "        'logo_val_r' : pearsonr(logo_val_predictions, y_train_g)[0],\n",
    "        'logo_val_r2' : pearsonr(logo_val_predictions, y_train_g)[0] ** 2,\n",
    "        \n",
    "        'logo_train_R2': r2_score(y_train_g, logo_train_pred),\n",
    "        'logo_train_r': pearsonr(logo_train_pred, y_train_g)[0],\n",
    "        'logo_train_r2': pearsonr(logo_train_pred, y_train_g)[0] ** 2,\n",
    "        \n",
    "        'logo_test_R2': r2_score(y_test_g, logo_test_pred),\n",
    "        'logo_test_r': pearsonr(logo_test_pred, y_test_g)[0],\n",
    "        'logo_test_r2': pearsonr(logo_test_pred, y_test_g)[0] ** 2,\n",
    "        \n",
    "        'kfold_demean_R2': r2_score(crop_yield[\"demean_yield\"], crop_yield[\"k-fold_demean_prediction\"]),\n",
    "        'kfold_demean_r':  pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"k-fold_demean_prediction\"])[0],\n",
    "        'kfold_demean_r2': pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"k-fold_demean_prediction\"])[0] ** 2,\n",
    "        \n",
    "        'logo_demean_R2': r2_score(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"]),\n",
    "        'logo_demean_r':  pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"])[0],\n",
    "        'logo_demean_r2': pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"])[0] ** 2,\n",
    "        \n",
    "    }\n",
    "    return pd.DataFrame(data=d, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30720303-2152-4ac9-9ba6-c1b14f64275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1174ba75a05c40d78dfee674326b4b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results as: results_2022-11-12.csv\n",
      "\n",
      "\n",
      "CPU times: user 1.66 s, sys: 780 ms, total: 2.44 s\n",
      "Wall time: 52min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time    \n",
    "##### With progress bar\n",
    "workers = os.cpu_count()\n",
    "if __name__ == \"__main__\":\n",
    "    output = []\n",
    "    for result in p_tqdm.p_umap(model, paramlist, num_cpus=workers):\n",
    "        output.append(result)\n",
    "    results = pd.concat(output).reset_index(drop=True)\n",
    "    today = date.today().strftime(\"%Y-%m-%d\")\n",
    "    file_name = f'results_{today}.csv'\n",
    "    print(f\"Saving results as: {file_name}\\n\\n\")           \n",
    "    results.to_csv(here(\"data\",\"results\", file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0210868e-8156-40bb-afa0-b8dd8ee7ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time    \n",
    "##### No progress bar\n",
    "# if __name__ == \"__main__\":\n",
    "#     with multiprocessing.Pool(processes=os.cpu_count()) as pool:\n",
    "#         output = []\n",
    "#         for result in pool.imap_unordered(model, paramlist, chunksize=2):\n",
    "#             output.append(result)\n",
    "#     results = pd.concat(output).reset_index(drop=True)\n",
    "#     file_name = f'results_{today}.csv'\n",
    "#     print(f\"Saving results as: {file_name}\\n\\n\")           \n",
    "#     results.to_csv(here(\"data\",\"results\", file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39006d56-39c2-46c1-87c3-365d1074f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
