{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa45eeff-1bf9-40bf-a5ff-9b412d0a787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import warnings\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from pyhere import here\n",
    "from datetime import date\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import pickle\n",
    "\n",
    "import pyarrow\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import p_tqdm\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneGroupOut, cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr,  pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f32198-986c-413d-9e1a-47faf0e55b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(string):\n",
    "    return string.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "point_pattern = re.compile(\"20k-points\")\n",
    "wa_pattern = re.compile(\"cm-False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353ccafc-8838-44ad-9e39-8ed4595cd09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = here(\"data\")\n",
    "directory = here(\"data\", \"random_features\", \"summary\")\n",
    "files = os.listdir(directory)\n",
    "files = [f for f in files if f not in ('.gitkeep', '.ipynb_checkpoints')]\n",
    "files = [f for f in files if not (bool(point_pattern.search(f)) & bool(wa_pattern.search(f)))]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6877398-a7af-4d30-8be5-f2f5b92c8a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramlist = list(itertools.product(files, [True, False]))\n",
    "len(paramlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ae5aca-1f61-4214-a348-11ca6f4b5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params):\n",
    "#########################################     SET PARAMS    #########################################\n",
    "    file         = params[0]\n",
    "    hot_encode   = params[1]\n",
    "    f            = file.split(sep=\"_\")\n",
    "    satellite    = f[0]\n",
    "    bands        = f[1].replace(\"bands-\", \"\")\n",
    "    country_code = f[2]\n",
    "    points       = f[3].replace(\"k-points\", \"\")\n",
    "    num_features = f[4].replace(\"-features\", \"\")\n",
    "    yrs          = f[5].replace(\"yr-\", \"\").split(sep=\"-\")\n",
    "    mns          = f[6].replace(\"mn-\", \"\").split(sep=\"-\")\n",
    "    limit_months = str2bool(f[7].replace(\"lm-\", \"\"))\n",
    "    crop_mask    = str2bool(f[8].replace(\"cm-\", \"\"))\n",
    "    weighted_avg = str2bool(f[9].replace(\"wa-\", \"\"))\n",
    "    years        = range(int(yrs[0]), int(yrs[1])+1)\n",
    "    month_range  = list(range(int(mns[0]), int(mns[1])+1))\n",
    "    \n",
    "    alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "    kfold  = KFold()\n",
    "    logo   = LeaveOneGroupOut()\n",
    "    ridge  = Ridge()    \n",
    "    \n",
    "#########################################     READ DATA    #########################################\n",
    "    fn = f\"{directory}/{file}\"\n",
    "    features = pd.read_feather(fn)\n",
    "     \n",
    "    drop_cols = ['district', 'year', 'yield_mt', \"crop_perc\"]\n",
    "            \n",
    "    if weighted_avg:\n",
    "        drop_cols.remove(\"crop_perc\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    crop_yield = features.copy().loc[:, tuple(drop_cols)]\n",
    "    \n",
    "#########################################     HOT ENCODE    ###########################################\n",
    "    if hot_encode:\n",
    "        drop_cols.remove(\"district\")\n",
    "        features = pd.get_dummies(features, columns=[\"district\"], drop_first=False)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    features['yield_mt'] = np.log10(features.yield_mt.to_numpy() + 1)\n",
    "    \n",
    "#########################################     K-FOLD SPLIT    #########################################\n",
    "    x_all = features.drop(drop_cols, axis = 1) \n",
    "    y_all = features.yield_mt\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "#########################################     K-FOLD CV    ###########################################\n",
    "\n",
    "    ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "    kfold_ridge_reg = GridSearchCV(ridge, alphas, scoring = 'r2', cv = kfold)\n",
    "    kfold_ridge_reg.fit(x_train, y_train)\n",
    "    kfold_best_model = kfold_ridge_reg.best_estimator_\n",
    "    ### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "    kfold_val_predictions = cross_val_predict(kfold_best_model, X = x_train, y = y_train, cv = kfold)   \n",
    "    y_pred_train_k = kfold_best_model.predict(x_train)\n",
    "    y_pred_test_k  = kfold_best_model.predict(x_test)\n",
    "\n",
    "# #########################################     LOGO SPLIT   ###########################################\n",
    "#     x_train_g = features[features.year < max(features.year)].drop(drop_cols, axis=1)\n",
    "#     y_train_g = features[features.year < max(features.year)].yield_mt\n",
    "#     g_train_g = features[features.year < max(features.year)].year.ravel()\n",
    "\n",
    "#     x_test_g = features[features.year == max(features.year)].drop(drop_cols, axis=1)\n",
    "#     y_test_g = features[features.year == max(features.year)].yield_mt\n",
    "#     g_test_g = features[features.year == max(features.year)].year\n",
    "\n",
    "# #########################################     LOGO CV    ###########################################\n",
    "#     ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "#     logo_ridge_reg = GridSearchCV(ridge, alphas, scoring='r2', cv=logo)\n",
    "#     logo_ridge_reg.fit(x_train_g, y_train_g, groups=g_train_g)\n",
    "#     logo_best_model = logo_ridge_reg.best_estimator_\n",
    "#     ### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "#     logo_val_predictions = cross_val_predict(logo_best_model, X=x_train_g, y=y_train_g, groups=g_train_g, cv=logo)   \n",
    "#     logo_train_pred = logo_best_model.predict(x_train_g)\n",
    "#     logo_test_pred  = logo_best_model.predict(x_test_g)\n",
    "\n",
    "#########################################     LOGO ITERATOR   ###########################################\n",
    "    logo_val_results = []\n",
    "    logo_train_results = []\n",
    "    logo_test_results = []\n",
    "\n",
    "    for year in features.year.unique():\n",
    "#########################################     LOGO SPLIT   ###########################################\n",
    "        x_train_g = features[features.year != year].drop(drop_cols, axis=1)\n",
    "        y_train_g = features[features.year != year].yield_mt.ravel()\n",
    "        g_train_g = features[features.year != year].year.ravel()\n",
    "        d_train_g = crop_yield[crop_yield.year != year].district.ravel()\n",
    "\n",
    "        x_test_g = features[features.year == year].drop(drop_cols, axis=1)\n",
    "        y_test_g = features[features.year == year].yield_mt.ravel()\n",
    "        g_test_g = features[features.year == year].year.ravel()\n",
    "        d_test_g = crop_yield[crop_yield.year == year].district.ravel()\n",
    "\n",
    "#########################################     LOGO CV   ###########################################\n",
    "        ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "        logo_ridge_reg = GridSearchCV(ridge, alphas, scoring='r2', cv=logo)\n",
    "        logo_ridge_reg.fit(x_train_g, y_train_g, groups=g_train_g)\n",
    "        logo_best_model = logo_ridge_reg.best_estimator_\n",
    "        ### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "        logo_val_predictions = cross_val_predict(logo_best_model, X=x_train_g, y=y_train_g, groups=g_train_g, cv=logo) \n",
    "        logo_train_pred = logo_best_model.predict(x_train_g)\n",
    "        logo_test_pred  = logo_best_model.predict(x_test_g)\n",
    "\n",
    "#########################################     LOGO RESULTS   ###########################################\n",
    "        val_results = {'year': g_train_g, 'district': d_train_g, 'split': 'val', \n",
    "                       'observed': y_train_g, 'predicted': logo_val_predictions}\n",
    "\n",
    "        train_results = {'year': g_train_g, 'district': d_train_g,'split': 'train', \n",
    "                         'observed': y_train_g, 'predicted': logo_train_pred}\n",
    "\n",
    "        test_results = {'year': g_test_g, 'district': d_test_g, 'split': 'test', \n",
    "                        'observed': y_test_g, 'predicted': logo_test_pred}\n",
    "        \n",
    "        logo_val_results.append(val_results)\n",
    "        logo_train_results.append(train_results)\n",
    "        logo_test_results.append(test_results)\n",
    "\n",
    "#########################################     EXPLODE RESULTS   ###########################################\n",
    "    explode_cols = ['year', 'district', 'observed', 'predicted']\n",
    "    val_df   = pd.DataFrame(logo_val_results  ).explode(explode_cols) \n",
    "    train_df = pd.DataFrame(logo_train_results).explode(explode_cols) \n",
    "    test_df  = pd.DataFrame(logo_test_results ).explode(explode_cols)\n",
    "    \n",
    "    group_cols = ['year', 'district', 'split']\n",
    "    val_summary   =   val_df.groupby(group_cols, as_index=False).mean()\n",
    "    train_summary = train_df.groupby(group_cols, as_index=False).mean()\n",
    "\n",
    "#########################################     DE-MEAN R2    #########################################    \n",
    "    crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "    crop_yield[\"district_yield_mean\"] = crop_yield.groupby('district')['log_yield'].transform('mean')\n",
    "    crop_yield[\"demean_yield\"] = crop_yield[\"log_yield\"] - crop_yield[\"district_yield_mean\"]\n",
    "    \n",
    "    crop_yield[\"kfold_prediction\"] = np.maximum(kfold_best_model.predict(x_all), 0)\n",
    "    crop_yield[\"kfold_district_prediction_mean\"] = crop_yield.groupby('district')['kfold_prediction'].transform('mean')\n",
    "    crop_yield[\"kfold_demean_prediction\"] = crop_yield[\"kfold_prediction\"] - crop_yield[\"kfold_district_prediction_mean\"]\n",
    "    \n",
    "    join_cols = ['year', 'district']\n",
    "    crop_yield = crop_yield.set_index(join_cols).join(test_df.set_index(join_cols)).reset_index()\n",
    "    crop_yield[\"logo_district_prediction_mean\"] = crop_yield.groupby('district')['predicted'].transform('mean')\n",
    "    crop_yield[\"logo_demean_prediction\"] = crop_yield[\"predicted\"] - crop_yield[\"logo_district_prediction_mean\"]\n",
    "    \n",
    "    # crop_yield[\"logo_prediction\"] = np.maximum(logo_best_model.predict(x_all), 0)\n",
    "    # crop_yield[\"logo_district_prediction_mean\"] = crop_yield.groupby('district')['logo_prediction'].transform('mean')\n",
    "    # crop_yield[\"logo_demean_prediction\"] = crop_yield[\"logo_prediction\"] - crop_yield[\"logo_district_prediction_mean\"]\n",
    "    \n",
    "#########################################     SAVE MODELS   #########################################  \n",
    "    model_fn_suffix = file.replace('_summary.feather', '')\n",
    "    k_model_fn  = f'kfold-cv_rr-model_{model_fn_suffix}_he-{hot_encode}.pkl'\n",
    "    logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}_he-{hot_encode}.pkl'\n",
    "    \n",
    "    with open(here('models', k_model_fn),'wb') as f:\n",
    "        pickle.dump(kfold_best_model, f)\n",
    "        \n",
    "    with open(here('models', logo_model_fn),'wb') as f:\n",
    "        pickle.dump(logo_best_model, f)\n",
    "        \n",
    "#########################################     SAVE RESULTS    #########################################\n",
    "    d = {\n",
    "        'country'     : country_code,\n",
    "        'satellite'   : satellite,\n",
    "        'bands'       : bands,\n",
    "        'num_features': num_features,\n",
    "        'points'      : points, \n",
    "        'month_range' : f'{min(month_range)}-{max(month_range)}',\n",
    "        \n",
    "        'limit_months': limit_months,\n",
    "        'crop_mask'   : crop_mask,\n",
    "        'weighted_avg': weighted_avg,\n",
    "        'hot_encode'  : hot_encode,\n",
    "        \n",
    "        'kfold_total_n': len(x_all),\n",
    "        'kfold_train_n': len(x_train),\n",
    "        'kfold_test_n' : len(x_test),\n",
    "        \n",
    "        'kfold_best_reg_param': list(kfold_ridge_reg.best_params_.values())[0],\n",
    "        'kfold_mean_of_val_R2': kfold_ridge_reg.best_score_,\n",
    "        'kfold_val_R2': r2_score(y_train, kfold_val_predictions),\n",
    "        'kfold_val_r' : pearsonr(kfold_val_predictions, y_train)[0],\n",
    "        'kfold_val_r2': pearsonr(kfold_val_predictions, y_train)[0] ** 2,\n",
    "        \n",
    "        'kfold_train_R2': r2_score(y_train, y_pred_train_k),\n",
    "        'kfold_train_r' : pearsonr(y_pred_train_k, y_train)[0],\n",
    "        'kfold_train_r2': pearsonr(y_pred_train_k, y_train)[0] ** 2,\n",
    "        \n",
    "        'kfold_test_R2': r2_score(y_test, y_pred_test_k),\n",
    "        'kfold_test_r' : pearsonr(y_pred_test_k, y_test)[0],\n",
    "        'kfold_test_r2': pearsonr(y_pred_test_k, y_test)[0] ** 2,\n",
    "        \n",
    "        'logo_total_n': len(features),\n",
    "        'logo_train_n': len(train_df),\n",
    "        'logo_test_n' : len(test_df),    \n",
    "        \n",
    "        'logo_best_reg_param': list(logo_ridge_reg.best_params_.values())[0],      \n",
    "        'logo_summary_val_R2': r2_score(val_summary.observed, val_summary.predicted),\n",
    "        'logo_summary_val_r' : pearsonr(val_summary.observed, val_summary.predicted)[0],\n",
    "        \n",
    "        'logo_val_R2' : r2_score(val_df.observed, val_df.predicted),\n",
    "        'logo_val_r'  : pearsonr(val_df.predicted, val_df.observed)[0],\n",
    "        'logo_val_r2' : pearsonr(val_df.predicted, val_df.observed)[0] ** 2,\n",
    "        \n",
    "        'logo_summary_train_R2': r2_score(train_summary.observed, train_summary.predicted),\n",
    "        'logo_summary_train_r' : pearsonr(train_summary.observed, train_summary.predicted)[0],\n",
    "        \n",
    "        'logo_train_R2': r2_score(train_df.observed, train_df.predicted),\n",
    "        'logo_train_r' : pearsonr(train_df.predicted, train_df.observed)[0],\n",
    "        'logo_train_r2': pearsonr(train_df.predicted, train_df.observed)[0] ** 2,\n",
    "        \n",
    "        'logo_test_R2': r2_score(test_df.observed, test_df.predicted),\n",
    "        'logo_test_r' : pearsonr(test_df.predicted, test_df.observed)[0],\n",
    "        'logo_test_r2': pearsonr(test_df.predicted, test_df.observed)[0] ** 2,\n",
    "        \n",
    "        'kfold_demean_R2': r2_score(crop_yield[\"demean_yield\"], crop_yield[\"kfold_demean_prediction\"]),\n",
    "        'kfold_demean_r':  pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"kfold_demean_prediction\"])[0],\n",
    "        'kfold_demean_r2': pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"kfold_demean_prediction\"])[0] ** 2,\n",
    "        \n",
    "        'logo_demean_R2': r2_score(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"]),\n",
    "        'logo_demean_r':  pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"])[0],\n",
    "        'logo_demean_r2': pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"])[0] ** 2,\n",
    "        \n",
    "    }\n",
    "    print('done')\n",
    "    return pd.DataFrame(data=d, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30720303-2152-4ac9-9ba6-c1b14f64275a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1c520c8c4e4d22a006f8b6ae6c8ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results as: results_2022-11-23.csv\n",
      "\n",
      "\n",
      "CPU times: user 1.71 s, sys: 937 ms, total: 2.65 s\n",
      "Wall time: 2h 50min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time    \n",
    "##### With progress bar\n",
    "workers = os.cpu_count()\n",
    "if __name__ == \"__main__\":\n",
    "    output = []\n",
    "    for result in p_tqdm.p_umap(model, paramlist, num_cpus=workers):\n",
    "        output.append(result)\n",
    "    results = pd.concat(output).reset_index(drop=True)\n",
    "    today = date.today().strftime(\"%Y-%m-%d\")\n",
    "    file_name = f'results_{today}.csv'\n",
    "    print(f\"Saving results as: {file_name}\\n\\n\")           \n",
    "    results.to_csv(here(\"data\",\"results\", file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39006d56-39c2-46c1-87c3-365d1074f20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>satellite</th>\n",
       "      <th>bands</th>\n",
       "      <th>num_features</th>\n",
       "      <th>points</th>\n",
       "      <th>month_range</th>\n",
       "      <th>limit_months</th>\n",
       "      <th>crop_mask</th>\n",
       "      <th>weighted_avg</th>\n",
       "      <th>hot_encode</th>\n",
       "      <th>...</th>\n",
       "      <th>logo_train_r2</th>\n",
       "      <th>logo_test_R2</th>\n",
       "      <th>logo_test_r</th>\n",
       "      <th>logo_test_r2</th>\n",
       "      <th>kfold_demean_R2</th>\n",
       "      <th>kfold_demean_r</th>\n",
       "      <th>kfold_demean_r2</th>\n",
       "      <th>logo_demean_R2</th>\n",
       "      <th>logo_demean_r</th>\n",
       "      <th>logo_demean_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>4-9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440318</td>\n",
       "      <td>-0.361305</td>\n",
       "      <td>0.235193</td>\n",
       "      <td>0.055316</td>\n",
       "      <td>0.449785</td>\n",
       "      <td>0.696348</td>\n",
       "      <td>0.484900</td>\n",
       "      <td>-2.384992</td>\n",
       "      <td>-0.099402</td>\n",
       "      <td>0.009881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>4-9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687445</td>\n",
       "      <td>0.404243</td>\n",
       "      <td>0.650719</td>\n",
       "      <td>0.423435</td>\n",
       "      <td>0.364483</td>\n",
       "      <td>0.617485</td>\n",
       "      <td>0.381288</td>\n",
       "      <td>-0.647625</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>0.009653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>4-9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468789</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>0.449377</td>\n",
       "      <td>0.201940</td>\n",
       "      <td>0.368260</td>\n",
       "      <td>0.645440</td>\n",
       "      <td>0.416593</td>\n",
       "      <td>-1.009621</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>0.003225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>4-9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829760</td>\n",
       "      <td>0.389867</td>\n",
       "      <td>0.654661</td>\n",
       "      <td>0.428581</td>\n",
       "      <td>0.477287</td>\n",
       "      <td>0.691128</td>\n",
       "      <td>0.477657</td>\n",
       "      <td>-1.215675</td>\n",
       "      <td>0.057958</td>\n",
       "      <td>0.003359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>4-9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230123</td>\n",
       "      <td>0.040867</td>\n",
       "      <td>0.232004</td>\n",
       "      <td>0.053826</td>\n",
       "      <td>0.185483</td>\n",
       "      <td>0.562430</td>\n",
       "      <td>0.316328</td>\n",
       "      <td>-0.220105</td>\n",
       "      <td>0.122598</td>\n",
       "      <td>0.015030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>4-9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.678487</td>\n",
       "      <td>0.187797</td>\n",
       "      <td>0.532123</td>\n",
       "      <td>0.283155</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.660669</td>\n",
       "      <td>0.436483</td>\n",
       "      <td>-0.867956</td>\n",
       "      <td>-0.020912</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>1-12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435721</td>\n",
       "      <td>0.273096</td>\n",
       "      <td>0.524260</td>\n",
       "      <td>0.274848</td>\n",
       "      <td>0.347582</td>\n",
       "      <td>0.591030</td>\n",
       "      <td>0.349316</td>\n",
       "      <td>-0.259267</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>1-12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417061</td>\n",
       "      <td>0.256944</td>\n",
       "      <td>0.509197</td>\n",
       "      <td>0.259281</td>\n",
       "      <td>0.313864</td>\n",
       "      <td>0.567517</td>\n",
       "      <td>0.322075</td>\n",
       "      <td>-0.262830</td>\n",
       "      <td>-0.044156</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>1-12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425456</td>\n",
       "      <td>0.264026</td>\n",
       "      <td>0.515752</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.308500</td>\n",
       "      <td>0.562415</td>\n",
       "      <td>0.316311</td>\n",
       "      <td>-0.257251</td>\n",
       "      <td>-0.037664</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>1024</td>\n",
       "      <td>20</td>\n",
       "      <td>1-12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432827</td>\n",
       "      <td>0.274840</td>\n",
       "      <td>0.525740</td>\n",
       "      <td>0.276402</td>\n",
       "      <td>0.351998</td>\n",
       "      <td>0.594868</td>\n",
       "      <td>0.353869</td>\n",
       "      <td>-0.249608</td>\n",
       "      <td>-0.016666</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   country       satellite                    bands num_features points  \\\n",
       "0      ZMB  sentinel-2-l2a                    2-3-4         1000      4   \n",
       "1      ZMB  sentinel-2-l2a                  2-3-4-8         1000     15   \n",
       "2      ZMB  sentinel-2-l2a                  2-3-4-8         1000     15   \n",
       "3      ZMB  sentinel-2-l2a                  2-3-4-8         1000     15   \n",
       "4      ZMB  sentinel-2-l2a                    2-3-4         1000     15   \n",
       "..     ...             ...                      ...          ...    ...   \n",
       "83     ZMB   landsat-c2-l2  r-g-b-nir-swir16-swir22         1024     20   \n",
       "84     ZMB   landsat-c2-l2  r-g-b-nir-swir16-swir22         1024     20   \n",
       "85     ZMB   landsat-c2-l2  r-g-b-nir-swir16-swir22         1024     20   \n",
       "86     ZMB   landsat-c2-l2  r-g-b-nir-swir16-swir22         1024     20   \n",
       "87     ZMB   landsat-c2-l2  r-g-b-nir-swir16-swir22         1024     20   \n",
       "\n",
       "   month_range  limit_months  crop_mask  weighted_avg  hot_encode  ...  \\\n",
       "0          4-9          True      False         False       False  ...   \n",
       "1          4-9          True      False         False       False  ...   \n",
       "2          4-9          True       True          True       False  ...   \n",
       "3          4-9          True      False         False        True  ...   \n",
       "4          4-9          True      False          True       False  ...   \n",
       "..         ...           ...        ...           ...         ...  ...   \n",
       "83         4-9          True       True         False        True  ...   \n",
       "84        1-12         False       True          True        True  ...   \n",
       "85        1-12         False       True         False       False  ...   \n",
       "86        1-12         False       True          True       False  ...   \n",
       "87        1-12         False       True         False        True  ...   \n",
       "\n",
       "    logo_train_r2  logo_test_R2  logo_test_r  logo_test_r2  kfold_demean_R2  \\\n",
       "0        0.440318     -0.361305     0.235193      0.055316         0.449785   \n",
       "1        0.687445      0.404243     0.650719      0.423435         0.364483   \n",
       "2        0.468789      0.099644     0.449377      0.201940         0.368260   \n",
       "3        0.829760      0.389867     0.654661      0.428581         0.477287   \n",
       "4        0.230123      0.040867     0.232004      0.053826         0.185483   \n",
       "..            ...           ...          ...           ...              ...   \n",
       "83       0.678487      0.187797     0.532123      0.283155         0.436000   \n",
       "84       0.435721      0.273096     0.524260      0.274848         0.347582   \n",
       "85       0.417061      0.256944     0.509197      0.259281         0.313864   \n",
       "86       0.425456      0.264026     0.515752      0.266000         0.308500   \n",
       "87       0.432827      0.274840     0.525740      0.276402         0.351998   \n",
       "\n",
       "    kfold_demean_r  kfold_demean_r2  logo_demean_R2  logo_demean_r  \\\n",
       "0         0.696348         0.484900       -2.384992      -0.099402   \n",
       "1         0.617485         0.381288       -0.647625       0.098249   \n",
       "2         0.645440         0.416593       -1.009621       0.056786   \n",
       "3         0.691128         0.477657       -1.215675       0.057958   \n",
       "4         0.562430         0.316328       -0.220105       0.122598   \n",
       "..             ...              ...             ...            ...   \n",
       "83        0.660669         0.436483       -0.867956      -0.020912   \n",
       "84        0.591030         0.349316       -0.259267      -0.028118   \n",
       "85        0.567517         0.322075       -0.262830      -0.044156   \n",
       "86        0.562415         0.316311       -0.257251      -0.037664   \n",
       "87        0.594868         0.353869       -0.249608      -0.016666   \n",
       "\n",
       "    logo_demean_r2  \n",
       "0         0.009881  \n",
       "1         0.009653  \n",
       "2         0.003225  \n",
       "3         0.003359  \n",
       "4         0.015030  \n",
       "..             ...  \n",
       "83        0.000437  \n",
       "84        0.000791  \n",
       "85        0.001950  \n",
       "86        0.001419  \n",
       "87        0.000278  \n",
       "\n",
       "[88 rows x 47 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d016b23-b6ad-42f4-b2c9-d70f5f9c6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time    \n",
    "# #### No progress bar\n",
    "# multiprocessing.set_start_method('spawn')\n",
    "# workers = os.cpu_count()\n",
    "# if __name__ == \"__main__\":\n",
    "#     with multiprocessing.Pool(processes=workers) as pool:\n",
    "#         output = []\n",
    "#         for result in pool.imap_unordered(model, paramlist, chunksize=2):\n",
    "#             output.append(result)\n",
    "#     results = pd.concat(output).reset_index(drop=True)\n",
    "#     today = date.today().strftime(\"%Y-%m-%d\")\n",
    "#     file_name = f'results_{today}.csv'\n",
    "#     print(f\"Saving results as: {file_name}\\n\\n\")           \n",
    "#     results.to_csv(here(\"data\",\"results\", file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5a231b1-c5cb-49a7-83a5-54cbe18c8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #########################################     SET PARAMS    #########################################\n",
    "# file         = paramlist[0][0]\n",
    "# hot_encode   = paramlist[0][1]\n",
    "\n",
    "\n",
    "\n",
    "# f            = file.split(sep=\"_\")\n",
    "# satellite    = f[0]\n",
    "# bands        = f[1].replace(\"bands-\", \"\")\n",
    "# country_code = f[2]\n",
    "# points       = f[3].replace(\"k-points\", \"\")\n",
    "# num_features = f[4].replace(\"-features\", \"\")\n",
    "# yrs          = f[5].replace(\"yr-\", \"\").split(sep=\"-\")\n",
    "# mns          = f[6].replace(\"mn-\", \"\").split(sep=\"-\")\n",
    "# limit_months = str2bool(f[7].replace(\"lm-\", \"\"))\n",
    "# crop_mask    = str2bool(f[8].replace(\"cm-\", \"\"))\n",
    "# weighted_avg = str2bool(f[9].replace(\"wa-\", \"\"))\n",
    "# years        = range(int(yrs[0]), int(yrs[1])+1)\n",
    "# month_range  = list(range(int(mns[0]), int(mns[1])+1))\n",
    "\n",
    "# alphas = {'alpha': np.logspace(-8, 8, base = 10, num = 17)}\n",
    "# kfold  = KFold()\n",
    "# logo   = LeaveOneGroupOut()\n",
    "# ridge  = Ridge()    \n",
    "\n",
    "# #########################################     READ DATA    #########################################\n",
    "# fn = f\"{directory}/{file}\"\n",
    "# features = pd.read_feather(fn)\n",
    "\n",
    "# drop_cols = ['district', 'year', 'yield_mt', \"crop_perc\"]\n",
    "\n",
    "# if weighted_avg:\n",
    "#     drop_cols.remove(\"crop_perc\")\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# crop_yield = features.copy().loc[:, tuple(drop_cols)]\n",
    "\n",
    "# #########################################     HOT ENCODE    ###########################################\n",
    "# if hot_encode:\n",
    "#     drop_cols.remove(\"district\")\n",
    "#     features = pd.get_dummies(features, columns=[\"district\"], drop_first=False)\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# features['yield_mt'] = np.log10(features.yield_mt.to_numpy() + 1)\n",
    "\n",
    "# #########################################     K-FOLD SPLIT    #########################################\n",
    "# x_all = features.drop(drop_cols, axis = 1) \n",
    "# y_all = features.yield_mt\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=0)\n",
    "\n",
    "# #########################################     K-FOLD CV    ###########################################\n",
    "\n",
    "# ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "# kfold_ridge_reg = GridSearchCV(ridge, alphas, scoring = 'r2', cv = kfold)\n",
    "# kfold_ridge_reg.fit(x_train, y_train)\n",
    "# kfold_best_model = kfold_ridge_reg.best_estimator_\n",
    "# ### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "# kfold_val_predictions = cross_val_predict(kfold_best_model, X = x_train, y = y_train, cv = kfold)   \n",
    "# y_pred_train_k = kfold_best_model.predict(x_train)\n",
    "# y_pred_test_k  = kfold_best_model.predict(x_test)\n",
    "\n",
    "# # #########################################     LOGO SPLIT   ###########################################\n",
    "# #     x_train_g = features[features.year < max(features.year)].drop(drop_cols, axis=1)\n",
    "# #     y_train_g = features[features.year < max(features.year)].yield_mt\n",
    "# #     g_train_g = features[features.year < max(features.year)].year.ravel()\n",
    "\n",
    "# #     x_test_g = features[features.year == max(features.year)].drop(drop_cols, axis=1)\n",
    "# #     y_test_g = features[features.year == max(features.year)].yield_mt\n",
    "# #     g_test_g = features[features.year == max(features.year)].year\n",
    "\n",
    "# # #########################################     LOGO CV    ###########################################\n",
    "# #     ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "# #     logo_ridge_reg = GridSearchCV(ridge, alphas, scoring='r2', cv=logo)\n",
    "# #     logo_ridge_reg.fit(x_train_g, y_train_g, groups=g_train_g)\n",
    "# #     logo_best_model = logo_ridge_reg.best_estimator_\n",
    "# #     ### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "# #     logo_val_predictions = cross_val_predict(logo_best_model, X=x_train_g, y=y_train_g, groups=g_train_g, cv=logo)   \n",
    "# #     logo_train_pred = logo_best_model.predict(x_train_g)\n",
    "# #     logo_test_pred  = logo_best_model.predict(x_test_g)\n",
    "\n",
    "# #########################################     LOGO ITERATOR   ###########################################\n",
    "# logo_val_results = []\n",
    "# logo_train_results = []\n",
    "# logo_test_results = []\n",
    "\n",
    "# for year in features.year.unique():\n",
    "# #########################################     LOGO SPLIT   ###########################################\n",
    "#     x_train_g = features[features.year != year].drop(drop_cols, axis=1)\n",
    "#     y_train_g = features[features.year != year].yield_mt.ravel()\n",
    "#     g_train_g = features[features.year != year].year.ravel()\n",
    "#     d_train_g = crop_yield[crop_yield.year != year].district.ravel()\n",
    "\n",
    "#     x_test_g = features[features.year == year].drop(drop_cols, axis=1)\n",
    "#     y_test_g = features[features.year == year].yield_mt.ravel()\n",
    "#     g_test_g = features[features.year == year].year.ravel()\n",
    "#     d_test_g = crop_yield[crop_yield.year == year].district.ravel()\n",
    "\n",
    "# #########################################     LOGO CV   ###########################################\n",
    "#     ### GRID SEARCH - FINDING BEST REGULARIZATION PARAMETER\n",
    "#     logo_ridge_reg = GridSearchCV(ridge, alphas, scoring='r2', cv=logo)\n",
    "#     logo_ridge_reg.fit(x_train_g, y_train_g, groups=g_train_g)\n",
    "#     logo_best_model = logo_ridge_reg.best_estimator_\n",
    "#     ### PREDICT - PREDICTING WITH BEST HYPERPARAMETER\n",
    "#     logo_val_predictions = cross_val_predict(logo_best_model, X=x_train_g, y=y_train_g, groups=g_train_g, cv=logo) \n",
    "#     logo_train_pred = logo_best_model.predict(x_train_g)\n",
    "#     logo_test_pred  = logo_best_model.predict(x_test_g)\n",
    "\n",
    "# #########################################     LOGO RESULTS   ###########################################\n",
    "#     val_results = {'year': g_train_g, 'district': d_train_g, 'split': 'val', \n",
    "#                    'observed': y_train_g, 'predicted': logo_val_predictions}\n",
    "\n",
    "#     train_results = {'year': g_train_g, 'district': d_train_g,'split': 'train', \n",
    "#                      'observed': y_train_g, 'predicted': logo_train_pred}\n",
    "\n",
    "#     test_results = {'year': g_test_g, 'district': d_test_g, 'split': 'test', \n",
    "#                     'observed': y_test_g, 'predicted': logo_test_pred}\n",
    "\n",
    "#     logo_val_results.append(val_results)\n",
    "#     logo_train_results.append(train_results)\n",
    "#     logo_test_results.append(test_results)\n",
    "\n",
    "# #########################################     EXPLODE RESULTS   ###########################################\n",
    "# explode_cols = ['year', 'district', 'observed', 'predicted']\n",
    "# val_df   = pd.DataFrame(logo_val_results  ).explode(explode_cols) \n",
    "# train_df = pd.DataFrame(logo_train_results).explode(explode_cols) \n",
    "# test_df  = pd.DataFrame(logo_test_results ).explode(explode_cols)\n",
    "\n",
    "# group_cols = ['year', 'district', 'split']\n",
    "# val_summary   =   val_df.groupby(group_cols, as_index=False).mean()\n",
    "# train_summary = train_df.groupby(group_cols, as_index=False).mean()\n",
    "\n",
    "# #########################################     DE-MEAN R2    #########################################    \n",
    "# crop_yield[\"log_yield\"] = np.log10(crop_yield.yield_mt.to_numpy() + 1)\n",
    "# crop_yield[\"district_yield_mean\"] = crop_yield.groupby('district')['log_yield'].transform('mean')\n",
    "# crop_yield[\"demean_yield\"] = crop_yield[\"log_yield\"] - crop_yield[\"district_yield_mean\"]\n",
    "\n",
    "# crop_yield[\"kfold_prediction\"] = np.maximum(kfold_best_model.predict(x_all), 0)\n",
    "# crop_yield[\"kfold_district_prediction_mean\"] = crop_yield.groupby('district')['kfold_prediction'].transform('mean')\n",
    "# crop_yield[\"kfold_demean_prediction\"] = crop_yield[\"kfold_prediction\"] - crop_yield[\"kfold_district_prediction_mean\"]\n",
    "\n",
    "# join_cols = ['year', 'district']\n",
    "# crop_yield = crop_yield.set_index(join_cols).join(test_df.set_index(join_cols)).reset_index()\n",
    "# crop_yield[\"logo_district_prediction_mean\"] = crop_yield.groupby('district')['predicted'].transform('mean')\n",
    "# crop_yield[\"logo_demean_prediction\"] = crop_yield[\"predicted\"] - crop_yield[\"logo_district_prediction_mean\"]\n",
    "\n",
    "# # crop_yield[\"logo_prediction\"] = np.maximum(logo_best_model.predict(x_all), 0)\n",
    "# # crop_yield[\"logo_district_prediction_mean\"] = crop_yield.groupby('district')['logo_prediction'].transform('mean')\n",
    "# # crop_yield[\"logo_demean_prediction\"] = crop_yield[\"logo_prediction\"] - crop_yield[\"logo_district_prediction_mean\"]\n",
    "\n",
    "# #########################################     SAVE MODELS   #########################################  \n",
    "# # model_fn_suffix = file.replace('_summary.feather', '')\n",
    "# # k_model_fn  = f'kfold-cv_rr-model_{model_fn_suffix}_he-{hot_encode}.pkl'\n",
    "# # logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}_he-{hot_encode}.pkl'\n",
    "\n",
    "# # with open(here('models', k_model_fn),'wb') as f:\n",
    "# #     pickle.dump(kfold_best_model, f)\n",
    "\n",
    "# # with open(here('models', logo_model_fn),'wb') as f:\n",
    "# #     pickle.dump(logo_best_model, f)\n",
    "\n",
    "# #########################################     SAVE RESULTS    #########################################\n",
    "# d = {\n",
    "#     'country'     : country_code,\n",
    "#     'satellite'   : satellite,\n",
    "#     'bands'       : bands,\n",
    "#     'num_features': num_features,\n",
    "#     'points'      : points, \n",
    "#     'month_range' : f'{min(month_range)}-{max(month_range)}',\n",
    "\n",
    "#     'limit_months': limit_months,\n",
    "#     'crop_mask'   : crop_mask,\n",
    "#     'weighted_avg': weighted_avg,\n",
    "#     'hot_encode'  : hot_encode,\n",
    "\n",
    "#     'kfold_total_n': len(x_all),\n",
    "#     'kfold_train_n': len(x_train),\n",
    "#     'kfold_test_n' : len(x_test),\n",
    "\n",
    "#     'kfold_best_reg_param': list(kfold_ridge_reg.best_params_.values())[0],\n",
    "#     'kfold_mean_of_val_R2': kfold_ridge_reg.best_score_,\n",
    "#     'kfold_val_R2': r2_score(y_train, kfold_val_predictions),\n",
    "#     'kfold_val_r' : pearsonr(kfold_val_predictions, y_train)[0],\n",
    "#     'kfold_val_r2': pearsonr(kfold_val_predictions, y_train)[0] ** 2,\n",
    "\n",
    "#     'kfold_train_R2': r2_score(y_train, y_pred_train_k),\n",
    "#     'kfold_train_r' : pearsonr(y_pred_train_k, y_train)[0],\n",
    "#     'kfold_train_r2': pearsonr(y_pred_train_k, y_train)[0] ** 2,\n",
    "\n",
    "#     'kfold_test_R2': r2_score(y_test, y_pred_test_k),\n",
    "#     'kfold_test_r' : pearsonr(y_pred_test_k, y_test)[0],\n",
    "#     'kfold_test_r2': pearsonr(y_pred_test_k, y_test)[0] ** 2,\n",
    "\n",
    "#     'logo_total_n': len(features),\n",
    "#     'logo_train_n': len(train_df),\n",
    "#     'logo_test_n' : len(test_df),    \n",
    "\n",
    "#     'logo_best_reg_param': list(logo_ridge_reg.best_params_.values())[0],      \n",
    "#     'logo_summary_val_R2': r2_score(val_summary.observed, val_summary.predicted),\n",
    "#     'logo_summary_val_r' : pearsonr(val_summary.observed, val_summary.predicted)[0],\n",
    "\n",
    "#     'logo_val_R2' : r2_score(val_df.observed, val_df.predicted),\n",
    "#     'logo_val_r'  : pearsonr(val_df.predicted, val_df.observed)[0],\n",
    "#     'logo_val_r2' : pearsonr(val_df.predicted, val_df.observed)[0] ** 2,\n",
    "\n",
    "#     'logo_summary_train_R2': r2_score(train_summary.observed, train_summary.predicted),\n",
    "#     'logo_summary_train_r' : pearsonr(train_summary.observed, train_summary.predicted)[0],\n",
    "\n",
    "#     'logo_train_R2': r2_score(train_df.observed, train_df.predicted),\n",
    "#     'logo_train_r' : pearsonr(train_df.predicted, train_df.observed)[0],\n",
    "#     'logo_train_r2': pearsonr(train_df.predicted, train_df.observed)[0] ** 2,\n",
    "\n",
    "#     'logo_test_R2': r2_score(test_df.observed, test_df.predicted),\n",
    "#     'logo_test_r' : pearsonr(test_df.predicted, test_df.observed)[0],\n",
    "#     'logo_test_r2': pearsonr(test_df.predicted, test_df.observed)[0] ** 2,\n",
    "\n",
    "#     'kfold_demean_R2': r2_score(crop_yield[\"demean_yield\"], crop_yield[\"kfold_demean_prediction\"]),\n",
    "#     'kfold_demean_r':  pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"kfold_demean_prediction\"])[0],\n",
    "#     'kfold_demean_r2': pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"kfold_demean_prediction\"])[0] ** 2,\n",
    "\n",
    "#     'logo_demean_R2': r2_score(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"]),\n",
    "#     'logo_demean_r':  pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"])[0],\n",
    "#     'logo_demean_r2': pearsonr(crop_yield[\"demean_yield\"], crop_yield[\"logo_demean_prediction\"])[0] ** 2,\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9718c0c3-3722-4af0-bf90-97ab86b841e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.DataFrame(d, index = [0])\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de70af-8a8b-44b9-9c38-bf7006f093e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
