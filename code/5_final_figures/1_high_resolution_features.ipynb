{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc81613-5df0-41b8-8922-a241b1ca875d",
   "metadata": {},
   "source": [
    "# Modeling Crop Yield\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f807a9-4078-43eb-8005-651307577218",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import warnings\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from pyhere import here\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyarrow\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import p_tqdm\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneGroupOut, cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr,  pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a10e81-3447-491b-8999-19d4df8296b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_shp = geopandas.read_file(here('data', 'geo_boundaries', 'gadm36_ZMB_2.shp'))\n",
    "country_shp = country_shp.set_index('district')\n",
    "\n",
    "crop_df = pd.read_csv(here('data', 'crop_yield', 'cfs_maize_districts_zambia_2009_2022.csv'))\n",
    "crop_df = crop_df.set_index(['district', 'year'])[['yield_mt']]\n",
    "                             \n",
    "weights_4_fn = 'ZMB_cropland_percentage_4k-points.feather'\n",
    "weights_15_fn = 'ZMB_cropland_percentage_15k-points.feather'\n",
    "weights_20_fn = 'ZMB_cropland_percentage_20k-points.feather'\n",
    "  \n",
    "weights_4 = pd.read_feather(here(\"data\", \"land_cover\", weights_4_fn))\n",
    "weights_15 = pd.read_feather(here(\"data\", \"land_cover\", weights_15_fn))\n",
    "weights_20 = pd.read_feather(here(\"data\", \"land_cover\", weights_20_fn))\n",
    "                           \n",
    "weights_4.lon, weights_4.lat = round(weights_4.lon, 5), round(weights_4.lat, 5)\n",
    "weights_15.lon, weights_15.lat = round(weights_15.lon, 5), round(weights_15.lat, 5)\n",
    "weights_20.lon, weights_20.lat = round(weights_20.lon, 5), round(weights_20.lat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d0f439-fb04-4333-a537-110e78b0b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_files(flist, **kwargs):\n",
    "    return pd.concat([pd.read_feather(f, **kwargs) for f in flist], axis=0).reset_index(drop=True)\n",
    "\n",
    "def merge_tuple(x, bases = (tuple, list)):\n",
    "    for e in x:\n",
    "        if type(e) in bases:\n",
    "            for e in merge_tuple(e, bases):\n",
    "                yield e\n",
    "        else:\n",
    "            yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1b58e9-7140-4677-9255-2545e4f94c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satellite</th>\n",
       "      <th>bands</th>\n",
       "      <th>country_code</th>\n",
       "      <th>points</th>\n",
       "      <th>num_features</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_4k-points_1000-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>landsat-8-c2-l2</td>\n",
       "      <td>1-2-3-4-5-6-7</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_15k-points_1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1024</td>\n",
       "      <td>landsat-c2-l2_bands-r-g-b-nir-swir16-swir22_ZM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landsat-8-c2-l2</td>\n",
       "      <td>1-2-3-4-5-6-7</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         satellite                    bands country_code  points num_features  \\\n",
       "0   sentinel-2-l2a                    2-3-4          ZMB       4         1000   \n",
       "1  landsat-8-c2-l2            1-2-3-4-5-6-7          ZMB      15         1000   \n",
       "2   sentinel-2-l2a                  2-3-4-8          ZMB      15         1000   \n",
       "3   sentinel-2-l2a                    2-3-4          ZMB      15         1000   \n",
       "4    landsat-c2-l2  r-g-b-nir-swir16-swir22          ZMB      20         1024   \n",
       "5  landsat-8-c2-l2            1-2-3-4-5-6-7          ZMB      20         1000   \n",
       "6   sentinel-2-l2a                    2-3-4          ZMB      20         1000   \n",
       "\n",
       "                                             pattern  \n",
       "0  sentinel-2-l2a_bands-2-3-4_ZMB_4k-points_1000-...  \n",
       "1  landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-po...  \n",
       "2  sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...  \n",
       "3  sentinel-2-l2a_bands-2-3-4_ZMB_15k-points_1000...  \n",
       "4  landsat-c2-l2_bands-r-g-b-nir-swir16-swir22_ZM...  \n",
       "5  landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...  \n",
       "6  sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_groups = pd.DataFrame()\n",
    "satellites = [\"sentinel-2-l2a\",\"landsat-8-c2-l2\",\"landsat-c2-l2\"]\n",
    "for satellite in satellites:\n",
    "    \n",
    "    directory = here(\"data\", \"random_features\", satellite)\n",
    "    files = os.listdir(directory)\n",
    "    files = [f for f in files if f not in ('.gitkeep', '.ipynb_checkpoints')]\n",
    "    files.sort()\n",
    "    \n",
    "    for file in files:\n",
    "        f = file.split(sep=\"_\")\n",
    "        d = {\n",
    "            'satellite'    : f[0],\n",
    "            'bands'        : f[1].replace(\"bands-\", \"\"),\n",
    "            'country_code' : f[2],\n",
    "            'points'       : int(f[3].replace(\"k-points\", \"\")),\n",
    "            'num_features' : f[4].replace(\"-features\", \"\"),\n",
    "            'pattern'      : f[0]+'_'+f[1]+'_'+f[2]+'_'+f[3]+'_'+f[4]+'_*'\n",
    "        }\n",
    "        df = pd.DataFrame(data=d, index=[0])\n",
    "        file_groups = pd.concat([file_groups, df])\n",
    "        \n",
    "file_groups = file_groups.sort_values(by=['points'], ascending=True)\n",
    "file_groups = file_groups.drop_duplicates().reset_index(drop=True)\n",
    "file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4707c3f-ef20-4214-a794-db5a7ea3191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satellite</th>\n",
       "      <th>bands</th>\n",
       "      <th>country_code</th>\n",
       "      <th>points</th>\n",
       "      <th>num_features</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landsat-8-c2-l2</td>\n",
       "      <td>1-2-3-4-5-6-7</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         satellite          bands country_code  points num_features  \\\n",
       "5  landsat-8-c2-l2  1-2-3-4-5-6-7          ZMB      20         1000   \n",
       "\n",
       "                                             pattern  \n",
       "5  landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_groups = file_groups[file_groups.satellite == \"landsat-8-c2-l2\"]\n",
    "file_groups = file_groups[file_groups.points == 20]\n",
    "file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34510e26-c2a5-445c-b198-993a8024b025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-points_1000-features_*',\n",
       " True,\n",
       " True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = 'limit_months crop_mask'.split()\n",
    "paramlist = list(itertools.product([False,True], repeat = len(names)))\n",
    "paramlist = list(itertools.product(file_groups.pattern.to_list(), paramlist))\n",
    "for i in range(len(paramlist)):\n",
    "    paramlist[i] = tuple(merge_tuple(paramlist[i]))\n",
    "paramlist = [t for t in paramlist if (t[1] == True) & (t[2] == True)][0]\n",
    "paramlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48216d3-dbcc-41ee-be1e-20c88b0c0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_features(params):\n",
    "    file         = params[0]\n",
    "    limit_months = params[1]\n",
    "    crop_mask    = params[2]\n",
    "    # weighted_avg = params[3]\n",
    "    f            = file.split(sep=\"_\")\n",
    "    satellite    = f[0]\n",
    "    points       = int(f[3].replace(\"k-points\", \"\"))\n",
    "    num_features = int(f[4].replace(\"-features\", \"\"))\n",
    " \n",
    "    path = str(here(\"data\", \"random_features\", satellite, file))\n",
    "    files = glob.glob(pathname=path)\n",
    "    \n",
    "    print('Opening')\n",
    "    \n",
    "    features = get_merged_files(files)\n",
    "\n",
    "    year_end = max(features.year)\n",
    "    \n",
    "    if satellite == \"landsat-c2-l2\":\n",
    "        year_start = 2008\n",
    "    elif satellite == \"landsat-8-c2-l2\":\n",
    "        year_start = 2013 \n",
    "    else:\n",
    "        year_start = 2015 \n",
    "        \n",
    "    month_range = range(4, 10) if limit_months else range(1, 13)\n",
    "\n",
    "    if (satellite == \"landsat-8-c2-l2\") & (limit_months):\n",
    "        month_start = 4\n",
    "    else:\n",
    "        month_start = 10\n",
    "\n",
    "    keep = np.where(\n",
    "        ((features.year == year_start) & (features.month >= month_start)) | (features.year > year_start), True, False)\n",
    "\n",
    "    features = features[keep]\n",
    "\n",
    "    features['year'] = np.where(\n",
    "        features['month'].isin([10, 11, 12]),\n",
    "        features['year'] + 1, \n",
    "        features['year']\n",
    "    )\n",
    "    features = features[features.year <= year_end]\n",
    "\n",
    "    features.lon, features.lat = round(features.lon, 5), round(features.lat, 5)\n",
    "\n",
    "    features = features[features.month.isin(month_range)]\n",
    "\n",
    "    features = features.set_index(['lon','lat', \"year\", 'month']).unstack()\n",
    "    features.columns = features.columns.map(lambda x: '{}_{}'.format(*x))\n",
    "\n",
    "    features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    features.reset_index(inplace = True)\n",
    "\n",
    "    if points == 4:\n",
    "        weights = weights_4.copy()\n",
    "    elif points == 15:\n",
    "        weights = weights_15.copy()\n",
    "    elif points == 20:\n",
    "        weights = weights_20.copy()\n",
    "\n",
    "    features = features.join(weights.set_index(['lon', 'lat']), on = ['lon', 'lat'])\n",
    "\n",
    "    if crop_mask:\n",
    "        features = features[features.crop_perc > 0]\n",
    "    else:\n",
    "        pass   \n",
    "\n",
    "    features = geopandas.GeoDataFrame(\n",
    "        features, \n",
    "        geometry = geopandas.points_from_xy(x = features.lon, y = features.lat), \n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "\n",
    "    features = (\n",
    "        features\n",
    "        .sjoin(country_shp, how = 'left', predicate = 'within')\n",
    "        .drop(['geometry'], axis = 1)\n",
    "        .rename(columns = {\"index_right\": \"district\"})\n",
    "        .dropna(subset=['district'])\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "\n",
    "    print('Imputing')\n",
    "    \n",
    "    num_cells = len(features) * len(month_range) * int(num_features)\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features.fillna(features.groupby(['year', 'district'], as_index=False).transform('mean'), inplace=True)\n",
    "\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features.fillna(features.groupby(['district'], as_index=False).transform('mean'), inplace=True)\n",
    "\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features = features.dropna(axis=0)\n",
    "\n",
    "    min_yr = min(features.year); max_yr = max(features.year)\n",
    "    min_mn = min(month_range);   max_mn = max(month_range)\n",
    "\n",
    "    f = f'{file[:-1]}yr-{min_yr}-{max_yr}_mn-{min_mn}-{max_mn}_lm-{limit_months}'+\\\n",
    "        f'_cm-{crop_mask}_full.feather'\n",
    "    full_file = here('data', 'random_features', 'full_files', f)\n",
    "\n",
    "    print('Saving')\n",
    "    \n",
    "    features.reset_index(drop=True).to_feather(full_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e778a47-781d-4f2b-818e-47669bf7d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening\n",
      "Imputing\n",
      "Saving\n",
      "CPU times: user 7min 54s, sys: 3min 7s, total: 11min 2s\n",
      "Wall time: 9min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "impute_features(paramlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58636bf2-ba9d-4a6e-9fd1-37cda0f46928",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode = True\n",
    "weighhted_avg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258b7e9a-c619-47b7-abd9-8fa22305de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-points_1000-features_yr-2013-2021_mn-4-9_lm-True_cm-True_full.feather'\n",
    "fn = here('data', 'random_features', 'full_files', f)\n",
    "features = pd.read_feather(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7348ed-1c77-460a-a0fd-9cdf0da50e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['year', 'lon', 'lat', 'crop_perc', 'district']\n",
    "\n",
    "if weighhted_avg:\n",
    "    features = features.set_index(drop_cols)\n",
    "    features.rename(columns={x:y for x,y in zip(features.columns,range(0,len(features.columns)))}, inplace=True)\n",
    "    features = features.reset_index()\n",
    "    features.columns = features.columns.astype(str)\n",
    "\n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    features = pd.get_dummies(features, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "features\n",
    "\n",
    "predictions = features.copy()[drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef564ee6-e657-4d4d-9850-12c519fb1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn_suffix = f.replace('_full.feather', '')+ '_wa-True_he-True'\n",
    "model_fn_suffix \n",
    "\n",
    "k_model_fn = f'k-fold-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "\n",
    "# with open(here('models', k_model_fn),'wb') as f:\n",
    "#     pickle.dump(best_kfold_model, f)\n",
    "        \n",
    "with open(here('models', k_model_fn), 'rb') as f:\n",
    "    best_kfold_model = pickle.load(f)\n",
    "    \n",
    "x_all = features.drop(drop_cols, axis = 1) \n",
    "predictions['prediction'] = best_kfold_model.predict(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ae85bc55-0973-4355-adf9-f132dcd8414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred = f'high-res-pred_k-fold-cv_{model_fn_suffix}.feather'\n",
    "fn = here('data', 'results', f_pred)\n",
    "predictions.to_feather(str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f3c7cec6-3d98-4c5f-ab82-b83bb261d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>crop_perc</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>22.07488</td>\n",
       "      <td>-14.86423</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.132330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>22.07488</td>\n",
       "      <td>-14.86423</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.158144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>22.07488</td>\n",
       "      <td>-14.86423</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.149651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>22.07488</td>\n",
       "      <td>-14.86423</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.164380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>22.07488</td>\n",
       "      <td>-14.86423</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.225569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176377</th>\n",
       "      <td>2017</td>\n",
       "      <td>33.52488</td>\n",
       "      <td>-10.32423</td>\n",
       "      <td>0.30577</td>\n",
       "      <td>0.737005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176378</th>\n",
       "      <td>2018</td>\n",
       "      <td>33.52488</td>\n",
       "      <td>-10.32423</td>\n",
       "      <td>0.30577</td>\n",
       "      <td>0.641154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176379</th>\n",
       "      <td>2019</td>\n",
       "      <td>33.52488</td>\n",
       "      <td>-10.32423</td>\n",
       "      <td>0.30577</td>\n",
       "      <td>0.595801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176380</th>\n",
       "      <td>2020</td>\n",
       "      <td>33.52488</td>\n",
       "      <td>-10.32423</td>\n",
       "      <td>0.30577</td>\n",
       "      <td>0.597986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176381</th>\n",
       "      <td>2021</td>\n",
       "      <td>33.52488</td>\n",
       "      <td>-10.32423</td>\n",
       "      <td>0.30577</td>\n",
       "      <td>0.676551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176382 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year       lon       lat  crop_perc  prediction\n",
       "0       2013  22.07488 -14.86423    0.12790    0.132330\n",
       "1       2014  22.07488 -14.86423    0.12790    0.158144\n",
       "2       2015  22.07488 -14.86423    0.12790    0.149651\n",
       "3       2016  22.07488 -14.86423    0.12790    0.164380\n",
       "4       2017  22.07488 -14.86423    0.12790    0.225569\n",
       "...      ...       ...       ...        ...         ...\n",
       "176377  2017  33.52488 -10.32423    0.30577    0.737005\n",
       "176378  2018  33.52488 -10.32423    0.30577    0.641154\n",
       "176379  2019  33.52488 -10.32423    0.30577    0.595801\n",
       "176380  2020  33.52488 -10.32423    0.30577    0.597986\n",
       "176381  2021  33.52488 -10.32423    0.30577    0.676551\n",
       "\n",
       "[176382 rows x 5 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f4ae421b-4710-4de1-87a2-6f5f1b009481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0804510383588988"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(crop_df.log_yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df423f72-097b-49da-831b-333d37c4b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e287cfe-165c-4d16-872a-28e79ee489e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf7c0a-7934-46d0-9e42-7125ee3bf7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0b0c5-d52b-4fd9-be9d-87a21dbc8e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aead853-e4e8-403b-b64a-2aba5dca282e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "07a1b8fc-e7cf-4ef5-8262-11acb5f9bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# country_shp.boundary.plot(ax = ax, edgecolor = \"black\")\n",
    "# plt.scatter(predictions.lon, predictions.lat,  c=predictions.crop_perc, s=.3, marker = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5ce4025d-d9b5-46e5-81c5-80586d4efb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_gdf = geopandas.GeoDataFrame(predictions, geometry=geopandas.points_from_xy(predictions.lon, predictions.lat))\n",
    "# predictions_gdf[predictions_gdf.year == 2013].plot(column = 'predictions', markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9b8f7290-99e9-4cce-b6ba-313c9354b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_df = crop_df.join(country_shp).reset_index()\n",
    "# crop_df['log_yield'] = np.log10(crop_df.yield_mt.to_numpy() + 1)\n",
    "# crop_df = geopandas.GeoDataFrame(crop_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b9e41d25-66bf-401b-9b9e-31e8a05d8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_df['log_yield'] = np.log10(crop_df.yield_mt.to_numpy() + 1)\n",
    "# crop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e4f69-2872-4746-8a16-f74dde3c2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_yield, max_yield = min(crop_df.log_yield), max(crop_df.log_yield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0d154ac6-1a12-4203-b88e-bc060ec44c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scatter(x, y, c, **kwargs):\n",
    "#     del kwargs[\"color\"]\n",
    "#     fig, ax = plt.subplots()\n",
    "#     country_shp.boundary.plot(ax = ax, edgecolor = \"black\")\n",
    "#     plt.scatter(x, y, c = c, **kwargs)\n",
    "    \n",
    "# def yield_plot(**kwargs):\n",
    "#     del kwargs[\"color\"]\n",
    "#     geopandas.GeoDataFrame.plot('yield_mt',**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb4d702a-fffb-48c4-b3d5-eb9e5b2e221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(\n",
    "#     crop_df,\n",
    "#     col='year',\n",
    "#     col_wrap=3,\n",
    "#     height=4, \n",
    "#     aspect=1\n",
    "# )\n",
    "# g.map(yield_plot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366812a9-b244-44b5-a264-d64f985ada15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ec63a-2e63-49e6-972d-1a9671ffc4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9814799-5987-45c0-9247-e45a86ac0a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d64b9c5d-740a-439b-be8f-f30548382477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = range(min(predictions.year), max(predictions.year)+1)\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 12),\n",
    "#                         # constrained_layout=True, \n",
    "#                         sharex=True, sharey=True, \n",
    "#                         subplot_kw=dict(aspect='equal'))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# fig.suptitle(\"Log Yield\", fontsize=18, y=0.95, x=.35)\n",
    "# fig.tight_layout()\n",
    "\n",
    "# for year, ax in zip(years, axs.ravel()):\n",
    "#     crop_df[crop_df[\"year\"] == year].plot(\n",
    "#         ax=ax, \n",
    "#         column = \"log_yield\", \n",
    "#         norm=colors.Normalize(vmin= min_yield, vmax=max_yield)\n",
    "#     )\n",
    "#     ax.set_title(year)\n",
    "#     ax.set_xlabel(\"\")\n",
    "    \n",
    "# axs = axs.ravel()\n",
    "# patch_col = axs[0].collections[0]\n",
    "# cb = fig.colorbar(patch_col, ax=axs, shrink=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "26bbab6b-b458-4ec8-96ed-fd926faa86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.FacetGrid(\n",
    "#     predictions,\n",
    "#     col='year',\n",
    "#     col_wrap=3,\n",
    "#     height=4, \n",
    "#     aspect=1\n",
    "# )\n",
    "# g.map_dataframe(scatter, 'lon', 'lat', 'predictions', s = .25)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b21cb102-dad0-4702-9cca-5a020d1f79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_shp.boundary.plot(edgecolor = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af08d91f-2b32-45ee-8866-8446c407dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ((ax1,ax2,ax3) ,(ax4,ax5,ax6),(ax7,ax8,ax9)) = plt.subplots(nrows=3, ncols=3, figsize=(15, 20))\n",
    "# ax1 = (crop_df[crop_df.year == 2013]\n",
    "#        .plot(ax = ax1, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2013 log_yields\"))\n",
    "# ax2 = (crop_df[crop_df.year == 2014]\n",
    "#        .plot(ax = ax2, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2014 log_yields\"))\n",
    "# ax3 = (crop_df[crop_df.year == 2015]\n",
    "#        .plot(ax = ax3, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2015 log_yields\"))\n",
    "# ax4 = (crop_df[crop_df.year == 2016]\n",
    "#        .plot(ax = ax4, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2016 log_yields\"))\n",
    "# ax5 = (crop_df[crop_df.year == 2017]\n",
    "#        .plot(ax = ax5, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2017 log_yields\"))\n",
    "# ax6 = (crop_df[crop_df.year == 2018]\n",
    "#        .plot(ax = ax6, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2018 log_yields\"))\n",
    "# ax7 = (crop_df[crop_df.year == 2019]\n",
    "#        .plot(ax = ax7, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2019 log_yields\"))\n",
    "# ax8 = (crop_df[crop_df.year == 2020]\n",
    "#        .plot(ax = ax8, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2020 log_yields\"))\n",
    "# ax9 = (crop_df[crop_df.year == 2021]\n",
    "#        .plot(ax = ax9, column = \"log_yield\", legend = True, norm=colors.Normalize(vmin= min_yield, vmax=max_yield))\n",
    "#        .set_title(\"2021 log_yields\"))\n",
    "\n",
    "# caption = \"A positive value is an underestimated prediction (the prediction is lower than the actual yield), a negative value is an over estimated prediction\"\n",
    "# plt.figtext(0.5, 0.01, caption, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "# fig.tight_layout()\n",
    "# handles, labels = ax1.get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper center')\n",
    "# plt.figlegend(loc = 'lower center', ncol=5, labelspacing=0.)\n",
    "\n",
    "# from matplotlib.legend import _get_legend_handles_labels\n",
    "# ...\n",
    "# fig.legend(*_get_legend_handles_and_labels(fig.axes), ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9797579-4b92-4a07-bbb4-4bd67966e64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mosaiks-env] *",
   "language": "python",
   "name": "conda-env-mosaiks-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
