{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc81613-5df0-41b8-8922-a241b1ca875d",
   "metadata": {},
   "source": [
    "# Modeling Crop Yield\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f807a9-4078-43eb-8005-651307577218",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import warnings\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from pyhere import here\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyarrow\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import p_tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneGroupOut, cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr,  pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a10e81-3447-491b-8999-19d4df8296b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_shp = geopandas.read_file(here('data', 'geo_boundaries', 'gadm36_ZMB_2.shp'))\n",
    "country_shp = country_shp.set_index('district')\n",
    "\n",
    "crop_df = pd.read_csv(here('data', 'crop_yield', 'cfs_maize_districts_zambia_2009_2022.csv'))\n",
    "crop_df = crop_df.set_index(['district', 'year'])[['yield_mt']]\n",
    "                             \n",
    "weights_4_fn = 'ZMB_cropland_percentage_4k-points.feather'\n",
    "weights_15_fn = 'ZMB_cropland_percentage_15k-points.feather'\n",
    "weights_20_fn = 'ZMB_cropland_percentage_20k-points.feather'\n",
    "  \n",
    "weights_4 = pd.read_feather(here(\"data\", \"land_cover\", weights_4_fn))\n",
    "weights_15 = pd.read_feather(here(\"data\", \"land_cover\", weights_15_fn))\n",
    "weights_20 = pd.read_feather(here(\"data\", \"land_cover\", weights_20_fn))\n",
    "                           \n",
    "weights_4.lon, weights_4.lat = round(weights_4.lon, 5), round(weights_4.lat, 5)\n",
    "weights_15.lon, weights_15.lat = round(weights_15.lon, 5), round(weights_15.lat, 5)\n",
    "weights_20.lon, weights_20.lat = round(weights_20.lon, 5), round(weights_20.lat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d0f439-fb04-4333-a537-110e78b0b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_files(flist, **kwargs):\n",
    "    return pd.concat([pd.read_feather(f, **kwargs) for f in flist], axis=0).reset_index(drop=True)\n",
    "\n",
    "def merge_tuple(x, bases = (tuple, list)):\n",
    "    for e in x:\n",
    "        if type(e) in bases:\n",
    "            for e in merge_tuple(e, bases):\n",
    "                yield e\n",
    "        else:\n",
    "            yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1b58e9-7140-4677-9255-2545e4f94c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satellite</th>\n",
       "      <th>bands</th>\n",
       "      <th>country_code</th>\n",
       "      <th>points</th>\n",
       "      <th>num_features</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_4k-points_1000-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>landsat-8-c2-l2</td>\n",
       "      <td>1-2-3-4-5-6-7</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_15k-points_1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1024</td>\n",
       "      <td>landsat-c2-l2_bands-r-g-b-nir-swir16-swir22_ZM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landsat-8-c2-l2</td>\n",
       "      <td>1-2-3-4-5-6-7</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         satellite                    bands country_code  points num_features  \\\n",
       "0   sentinel-2-l2a                    2-3-4          ZMB       4         1000   \n",
       "1  landsat-8-c2-l2            1-2-3-4-5-6-7          ZMB      15         1000   \n",
       "2   sentinel-2-l2a                  2-3-4-8          ZMB      15         1000   \n",
       "3   sentinel-2-l2a                    2-3-4          ZMB      15         1000   \n",
       "4    landsat-c2-l2  r-g-b-nir-swir16-swir22          ZMB      20         1024   \n",
       "5  landsat-8-c2-l2            1-2-3-4-5-6-7          ZMB      20         1000   \n",
       "6   sentinel-2-l2a                    2-3-4          ZMB      20         1000   \n",
       "\n",
       "                                             pattern  \n",
       "0  sentinel-2-l2a_bands-2-3-4_ZMB_4k-points_1000-...  \n",
       "1  landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-po...  \n",
       "2  sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...  \n",
       "3  sentinel-2-l2a_bands-2-3-4_ZMB_15k-points_1000...  \n",
       "4  landsat-c2-l2_bands-r-g-b-nir-swir16-swir22_ZM...  \n",
       "5  landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...  \n",
       "6  sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_groups = pd.DataFrame()\n",
    "satellites = [\"sentinel-2-l2a\",\"landsat-8-c2-l2\",\"landsat-c2-l2\"]\n",
    "for satellite in satellites:\n",
    "    \n",
    "    directory = here(\"data\", \"random_features\", satellite)\n",
    "    files = os.listdir(directory)\n",
    "    files = [f for f in files if f not in ('.gitkeep', '.ipynb_checkpoints')]\n",
    "    files.sort()\n",
    "    \n",
    "    for file in files:\n",
    "        f = file.split(sep=\"_\")\n",
    "        d = {\n",
    "            'satellite'    : f[0],\n",
    "            'bands'        : f[1].replace(\"bands-\", \"\"),\n",
    "            'country_code' : f[2],\n",
    "            'points'       : int(f[3].replace(\"k-points\", \"\")),\n",
    "            'num_features' : f[4].replace(\"-features\", \"\"),\n",
    "            'pattern'      : f[0]+'_'+f[1]+'_'+f[2]+'_'+f[3]+'_'+f[4]+'_*'\n",
    "        }\n",
    "        df = pd.DataFrame(data=d, index=[0])\n",
    "        file_groups = pd.concat([file_groups, df])\n",
    "        \n",
    "file_groups = file_groups.sort_values(by=['points'], ascending=True)\n",
    "file_groups = file_groups.drop_duplicates().reset_index(drop=True)\n",
    "file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4707c3f-ef20-4214-a794-db5a7ea3191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satellite</th>\n",
       "      <th>bands</th>\n",
       "      <th>country_code</th>\n",
       "      <th>points</th>\n",
       "      <th>num_features</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        satellite    bands country_code  points num_features  \\\n",
       "2  sentinel-2-l2a  2-3-4-8          ZMB      15         1000   \n",
       "\n",
       "                                             pattern  \n",
       "2  sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_groups = file_groups[file_groups.satellite == \"sentinel-2-l2a\"]\n",
    "file_groups = file_groups[file_groups.points == 15]\n",
    "file_groups = file_groups[file_groups.bands == '2-3-4-8']\n",
    "file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34510e26-c2a5-445c-b198-993a8024b025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_1000-features_*', False, True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = 'limit_months crop_mask'.split()\n",
    "paramlist = list(itertools.product([False,True], repeat = len(names)))\n",
    "paramlist = list(itertools.product(file_groups.pattern.to_list(), paramlist))\n",
    "for i in range(len(paramlist)):\n",
    "    paramlist[i] = tuple(merge_tuple(paramlist[i]))\n",
    "paramlist = [t for t in paramlist if (t[1] == False) & (t[2] == True)][0]\n",
    "paramlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffcc84d-5fc4-45b3-b35e-ed1b53aea6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_1000-features_*'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a025b5c-07bd-45aa-ab4a-ca97721941ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening\n"
     ]
    }
   ],
   "source": [
    "# def impute_features(params):\n",
    "file         = paramlist[0]\n",
    "limit_months = paramlist[1]\n",
    "crop_mask    = paramlist[2]\n",
    "# weighted_avg = params[3]\n",
    "f            = file.split(sep=\"_\")\n",
    "satellite    = f[0]\n",
    "points       = int(f[3].replace(\"k-points\", \"\"))\n",
    "num_features = int(f[4].replace(\"-features\", \"\"))\n",
    "\n",
    "path = str(here(\"data\", \"random_features\", satellite, file))\n",
    "files = glob.glob(pathname=path)\n",
    "\n",
    "print('Opening')\n",
    "\n",
    "features = get_merged_files(files)\n",
    "\n",
    "year_end = max(features.year)\n",
    "\n",
    "if satellite == \"landsat-c2-l2\":\n",
    "    year_start = 2008\n",
    "elif satellite == \"landsat-8-c2-l2\":\n",
    "    year_start = 2013 \n",
    "else:\n",
    "    year_start = 2015 \n",
    "\n",
    "month_range = range(4, 10) if limit_months else range(1, 13)\n",
    "\n",
    "if (satellite == \"landsat-8-c2-l2\") & (limit_months):\n",
    "    month_start = 4\n",
    "else:\n",
    "    month_start = 10\n",
    "\n",
    "keep = np.where(\n",
    "    ((features.year == year_start) & (features.month >= month_start)) | (features.year > year_start), True, False)\n",
    "\n",
    "features = features[keep]\n",
    "\n",
    "features['year'] = np.where(\n",
    "    features['month'].isin([10, 11, 12]),\n",
    "    features['year'] + 1, \n",
    "    features['year']\n",
    ")\n",
    "features = features[features.year <= year_end]\n",
    "\n",
    "features.lon, features.lat = round(features.lon, 5), round(features.lat, 5)\n",
    "\n",
    "features = features[features.month.isin(month_range)]\n",
    "\n",
    "features = features.set_index(['lon','lat', \"year\", 'month']).unstack()\n",
    "features.columns = features.columns.map(lambda x: '{}_{}'.format(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb868e8e-8ac8-42f5-bc3d-cd994b193446",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = features.copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577f88a3-ff31-417a-b0e8-12b092114881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>year</th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>...</th>\n",
       "      <th>999_3</th>\n",
       "      <th>999_4</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.98176</td>\n",
       "      <td>-14.01693</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.532144</td>\n",
       "      <td>3.849683</td>\n",
       "      <td>4.034249</td>\n",
       "      <td>4.161150</td>\n",
       "      <td>3.833862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.656577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.98287</td>\n",
       "      <td>-15.95433</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.227335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.875107</td>\n",
       "      <td>5.971619</td>\n",
       "      <td>6.791008</td>\n",
       "      <td>7.082443</td>\n",
       "      <td>6.455033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.98372</td>\n",
       "      <td>-13.92686</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.575454</td>\n",
       "      <td>5.457288</td>\n",
       "      <td>5.407687</td>\n",
       "      <td>5.276629</td>\n",
       "      <td>5.851517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.352674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.98510</td>\n",
       "      <td>-15.86427</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.169197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.884258</td>\n",
       "      <td>5.573695</td>\n",
       "      <td>5.966973</td>\n",
       "      <td>6.100280</td>\n",
       "      <td>5.397137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21.98566</td>\n",
       "      <td>-13.83679</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.001415</td>\n",
       "      <td>4.761360</td>\n",
       "      <td>4.753737</td>\n",
       "      <td>4.706692</td>\n",
       "      <td>5.137783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.313816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105371</th>\n",
       "      <td>33.54503</td>\n",
       "      <td>-10.56450</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.937199</td>\n",
       "      <td>3.020481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.550606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105378</th>\n",
       "      <td>33.54695</td>\n",
       "      <td>-10.65435</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.038828</td>\n",
       "      <td>3.151504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.970561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105385</th>\n",
       "      <td>33.58948</td>\n",
       "      <td>-10.51863</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.940908</td>\n",
       "      <td>3.235936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.876681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105392</th>\n",
       "      <td>33.59140</td>\n",
       "      <td>-10.60847</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.827517</td>\n",
       "      <td>2.792906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.642956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105399</th>\n",
       "      <td>33.63583</td>\n",
       "      <td>-10.56260</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.033279</td>\n",
       "      <td>3.232837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.628088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15058 rows × 12003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             lon       lat  year  0_1  0_2  0_3  0_4  0_5  0_6  0_7  ...  \\\n",
       "0       21.98176 -14.01693  2016  NaN  0.0  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "7       21.98287 -15.95433  2016  NaN  0.0  NaN  NaN  NaN  0.0  NaN  ...   \n",
       "14      21.98372 -13.92686  2016  NaN  0.0  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "21      21.98510 -15.86427  2016  NaN  0.0  NaN  NaN  NaN  0.0  NaN  ...   \n",
       "28      21.98566 -13.83679  2016  NaN  0.0  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "...          ...       ...   ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "105371  33.54503 -10.56450  2016  NaN  NaN  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "105378  33.54695 -10.65435  2016  NaN  NaN  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "105385  33.58948 -10.51863  2016  NaN  NaN  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "105392  33.59140 -10.60847  2016  NaN  NaN  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "105399  33.63583 -10.56260  2016  NaN  NaN  NaN  NaN  NaN  0.0  0.0  ...   \n",
       "\n",
       "        999_3  999_4  999_5     999_6     999_7     999_8     999_9    999_10  \\\n",
       "0         NaN    NaN    NaN  3.532144  3.849683  4.034249  4.161150  3.833862   \n",
       "7         NaN    NaN    NaN  5.227335       NaN  5.875107  5.971619  6.791008   \n",
       "14        NaN    NaN    NaN  4.575454  5.457288  5.407687  5.276629  5.851517   \n",
       "21        NaN    NaN    NaN  5.169197       NaN  5.884258  5.573695  5.966973   \n",
       "28        NaN    NaN    NaN  4.001415  4.761360  4.753737  4.706692  5.137783   \n",
       "...       ...    ...    ...       ...       ...       ...       ...       ...   \n",
       "105371    NaN    NaN    NaN  2.937199  3.020481       NaN  3.550606       NaN   \n",
       "105378    NaN    NaN    NaN  3.038828  3.151504       NaN  3.970561       NaN   \n",
       "105385    NaN    NaN    NaN  2.940908  3.235936       NaN  3.876681       NaN   \n",
       "105392    NaN    NaN    NaN  2.827517  2.792906       NaN  3.642956       NaN   \n",
       "105399    NaN    NaN    NaN  3.033279  3.232837       NaN  3.628088       NaN   \n",
       "\n",
       "          999_11    999_12  \n",
       "0            NaN  3.656577  \n",
       "7       7.082443  6.455033  \n",
       "14           NaN  5.352674  \n",
       "21      6.100280  5.397137  \n",
       "28           NaN  5.313816  \n",
       "...          ...       ...  \n",
       "105371       NaN       NaN  \n",
       "105378       NaN       NaN  \n",
       "105385       NaN       NaN  \n",
       "105392       NaN       NaN  \n",
       "105399       NaN       NaN  \n",
       "\n",
       "[15058 rows x 12003 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a.year == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7ce12b-bd29-4368-aa48-0c0296049acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "features.reset_index(inplace = True)\n",
    "\n",
    "if points == 4:\n",
    "    weights = weights_4.copy()\n",
    "elif points == 15:\n",
    "    weights = weights_15.copy()\n",
    "elif points == 20:\n",
    "    weights = weights_20.copy()\n",
    "\n",
    "features = features.join(weights.set_index(['lon', 'lat']), on = ['lon', 'lat'])\n",
    "\n",
    "if crop_mask:\n",
    "    features = features[features.crop_perc > 0]\n",
    "else:\n",
    "    pass   \n",
    "\n",
    "features = geopandas.GeoDataFrame(\n",
    "    features, \n",
    "    geometry = geopandas.points_from_xy(x = features.lon, y = features.lat), \n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "features = (\n",
    "    features\n",
    "    .sjoin(country_shp, how = 'left', predicate = 'within')\n",
    "    .drop(['geometry'], axis = 1)\n",
    "    .rename(columns = {\"index_right\": \"district\"})\n",
    "    .dropna(subset=['district'])\n",
    "    .reset_index(drop = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35546ddf-afad-4857-88ba-4ac8879636e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[features.year == 2016].district.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69499cf-831c-42f7-ac31-f6a8668904e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a44b6c-8da1-4256-b788-daef5ff911f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing\n"
     ]
    }
   ],
   "source": [
    "print('Imputing')\n",
    "\n",
    "num_cells = len(features) * len(month_range) * int(num_features)\n",
    "ln_ft = len(features); ln_na = len(features.dropna())\n",
    "features.fillna(features.groupby(['year', 'district'], as_index=False).transform('mean'), inplace=True)\n",
    "\n",
    "ln_ft = len(features); ln_na = len(features.dropna())\n",
    "features.fillna(features.groupby(['district'], as_index=False).transform('mean'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9da2254-6b2b-4730-86bc-2e5f819842ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[features.year == 2016].district.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c318805-7b87-4575-9c93-f1c01c64cde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>year</th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>...</th>\n",
       "      <th>999_5</th>\n",
       "      <th>999_6</th>\n",
       "      <th>999_7</th>\n",
       "      <th>999_8</th>\n",
       "      <th>999_9</th>\n",
       "      <th>999_10</th>\n",
       "      <th>999_11</th>\n",
       "      <th>999_12</th>\n",
       "      <th>crop_perc</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.04991</td>\n",
       "      <td>-15.09977</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.893386e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.358994</td>\n",
       "      <td>4.089959</td>\n",
       "      <td>4.271688</td>\n",
       "      <td>4.246182</td>\n",
       "      <td>4.490125</td>\n",
       "      <td>5.122961</td>\n",
       "      <td>4.164947</td>\n",
       "      <td>3.906469</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>Kalabo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.04991</td>\n",
       "      <td>-15.09977</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.893386e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.364898</td>\n",
       "      <td>3.231562</td>\n",
       "      <td>3.249797</td>\n",
       "      <td>3.097034</td>\n",
       "      <td>3.413488</td>\n",
       "      <td>5.010098</td>\n",
       "      <td>4.399866</td>\n",
       "      <td>4.079709</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>Kalabo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.04991</td>\n",
       "      <td>-15.09977</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.912843</td>\n",
       "      <td>3.176933</td>\n",
       "      <td>3.221959</td>\n",
       "      <td>3.212218</td>\n",
       "      <td>3.395274</td>\n",
       "      <td>3.536010</td>\n",
       "      <td>4.040872</td>\n",
       "      <td>3.866383</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>Kalabo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.04991</td>\n",
       "      <td>-15.09977</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.398332</td>\n",
       "      <td>4.801321</td>\n",
       "      <td>4.528609</td>\n",
       "      <td>4.880805</td>\n",
       "      <td>4.875570</td>\n",
       "      <td>3.211890</td>\n",
       "      <td>3.884175</td>\n",
       "      <td>4.118165</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>Kalabo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.04991</td>\n",
       "      <td>-15.09977</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.304991</td>\n",
       "      <td>3.381151</td>\n",
       "      <td>3.405476</td>\n",
       "      <td>3.506648</td>\n",
       "      <td>3.967765</td>\n",
       "      <td>5.478981</td>\n",
       "      <td>4.227735</td>\n",
       "      <td>3.813649</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>Kalabo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45012</th>\n",
       "      <td>33.63583</td>\n",
       "      <td>-10.56260</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.696334</td>\n",
       "      <td>2.691303</td>\n",
       "      <td>2.941995</td>\n",
       "      <td>3.205833</td>\n",
       "      <td>3.413213</td>\n",
       "      <td>3.438436</td>\n",
       "      <td>3.784972</td>\n",
       "      <td>3.546447</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>Isoka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45013</th>\n",
       "      <td>33.63583</td>\n",
       "      <td>-10.56260</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.588395</td>\n",
       "      <td>2.720627</td>\n",
       "      <td>3.015472</td>\n",
       "      <td>3.048735</td>\n",
       "      <td>3.852941</td>\n",
       "      <td>3.595639</td>\n",
       "      <td>3.977738</td>\n",
       "      <td>3.187459</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>Isoka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45014</th>\n",
       "      <td>33.63583</td>\n",
       "      <td>-10.56260</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.852466</td>\n",
       "      <td>3.071886</td>\n",
       "      <td>3.032688</td>\n",
       "      <td>3.325195</td>\n",
       "      <td>3.146947</td>\n",
       "      <td>3.649997</td>\n",
       "      <td>4.993696</td>\n",
       "      <td>3.639261</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>Isoka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45015</th>\n",
       "      <td>33.63583</td>\n",
       "      <td>-10.56260</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.524389</td>\n",
       "      <td>2.627626</td>\n",
       "      <td>3.038066</td>\n",
       "      <td>3.401843</td>\n",
       "      <td>3.490526</td>\n",
       "      <td>3.658384</td>\n",
       "      <td>3.551093</td>\n",
       "      <td>3.706571</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>Isoka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45016</th>\n",
       "      <td>33.63583</td>\n",
       "      <td>-10.56260</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.510948e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.363354</td>\n",
       "      <td>2.875322</td>\n",
       "      <td>2.936592</td>\n",
       "      <td>3.187982</td>\n",
       "      <td>3.367498</td>\n",
       "      <td>4.048011</td>\n",
       "      <td>3.929231</td>\n",
       "      <td>3.688949</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>Isoka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45017 rows × 12005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lon       lat  year       0_1  0_2           0_3           0_4  \\\n",
       "0      22.04991 -15.09977  2016  0.000001  0.0  5.893386e-07  0.000000e+00   \n",
       "1      22.04991 -15.09977  2017  0.000001  0.0  5.893386e-07  0.000000e+00   \n",
       "2      22.04991 -15.09977  2018  0.000000  0.0  0.000000e+00  0.000000e+00   \n",
       "3      22.04991 -15.09977  2019  0.000000  0.0  0.000000e+00  0.000000e+00   \n",
       "4      22.04991 -15.09977  2020  0.000000  0.0  0.000000e+00  0.000000e+00   \n",
       "...         ...       ...   ...       ...  ...           ...           ...   \n",
       "45012  33.63583 -10.56260  2018  0.000000  0.0  0.000000e+00  0.000000e+00   \n",
       "45013  33.63583 -10.56260  2019  0.000000  0.0  0.000000e+00  0.000000e+00   \n",
       "45014  33.63583 -10.56260  2020  0.000000  0.0  0.000000e+00  0.000000e+00   \n",
       "45015  33.63583 -10.56260  2021  0.000000  0.0  0.000000e+00  0.000000e+00   \n",
       "45016  33.63583 -10.56260  2022  0.000000  0.0  0.000000e+00  3.510948e-07   \n",
       "\n",
       "       0_5  0_6  0_7  ...     999_5     999_6     999_7     999_8     999_9  \\\n",
       "0      0.0  0.0  0.0  ...  4.358994  4.089959  4.271688  4.246182  4.490125   \n",
       "1      0.0  0.0  0.0  ...  3.364898  3.231562  3.249797  3.097034  3.413488   \n",
       "2      0.0  0.0  0.0  ...  2.912843  3.176933  3.221959  3.212218  3.395274   \n",
       "3      0.0  0.0  0.0  ...  4.398332  4.801321  4.528609  4.880805  4.875570   \n",
       "4      0.0  0.0  0.0  ...  3.304991  3.381151  3.405476  3.506648  3.967765   \n",
       "...    ...  ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "45012  0.0  0.0  0.0  ...  2.696334  2.691303  2.941995  3.205833  3.413213   \n",
       "45013  0.0  0.0  0.0  ...  2.588395  2.720627  3.015472  3.048735  3.852941   \n",
       "45014  0.0  0.0  0.0  ...  2.852466  3.071886  3.032688  3.325195  3.146947   \n",
       "45015  0.0  0.0  0.0  ...  2.524389  2.627626  3.038066  3.401843  3.490526   \n",
       "45016  0.0  0.0  0.0  ...  2.363354  2.875322  2.936592  3.187982  3.367498   \n",
       "\n",
       "         999_10    999_11    999_12  crop_perc  district  \n",
       "0      5.122961  4.164947  3.906469   0.000152    Kalabo  \n",
       "1      5.010098  4.399866  4.079709   0.000152    Kalabo  \n",
       "2      3.536010  4.040872  3.866383   0.000152    Kalabo  \n",
       "3      3.211890  3.884175  4.118165   0.000152    Kalabo  \n",
       "4      5.478981  4.227735  3.813649   0.000152    Kalabo  \n",
       "...         ...       ...       ...        ...       ...  \n",
       "45012  3.438436  3.784972  3.546447   0.001067     Isoka  \n",
       "45013  3.595639  3.977738  3.187459   0.001067     Isoka  \n",
       "45014  3.649997  4.993696  3.639261   0.001067     Isoka  \n",
       "45015  3.658384  3.551093  3.706571   0.001067     Isoka  \n",
       "45016  4.048011  3.929231  3.688949   0.001067     Isoka  \n",
       "\n",
       "[45017 rows x 12005 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3b7f0b4-c603-44b0-abea-79f8c12164bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_ft = len(features); ln_na = len(features.dropna())\n",
    "features = features.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84b696dc-7c42-43e9-8210-a488e5a3066d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[features.year == 2016].district.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55a061-da4e-4b8d-81ca-22189342717a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c48216d3-dbcc-41ee-be1e-20c88b0c0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_features(params):\n",
    "    file         = params[0]\n",
    "    limit_months = params[1]\n",
    "    crop_mask    = params[2]\n",
    "    # weighted_avg = params[3]\n",
    "    f            = file.split(sep=\"_\")\n",
    "    satellite    = f[0]\n",
    "    points       = int(f[3].replace(\"k-points\", \"\"))\n",
    "    num_features = int(f[4].replace(\"-features\", \"\"))\n",
    " \n",
    "    path = str(here(\"data\", \"random_features\", satellite, file))\n",
    "    files = glob.glob(pathname=path)\n",
    "    \n",
    "    print('Opening')\n",
    "    \n",
    "    features = get_merged_files(files)\n",
    "\n",
    "    year_end = max(features.year)\n",
    "    \n",
    "    if satellite == \"landsat-c2-l2\":\n",
    "        year_start = 2008\n",
    "    elif satellite == \"landsat-8-c2-l2\":\n",
    "        year_start = 2013 \n",
    "    else:\n",
    "        year_start = 2015 \n",
    "        \n",
    "    month_range = range(4, 10) if limit_months else range(1, 13)\n",
    "\n",
    "    if (satellite == \"landsat-8-c2-l2\") & (limit_months):\n",
    "        month_start = 4\n",
    "    else:\n",
    "        month_start = 10\n",
    "\n",
    "    keep = np.where(\n",
    "        ((features.year == year_start) & (features.month >= month_start)) | (features.year > year_start), True, False)\n",
    "\n",
    "    features = features[keep]\n",
    "\n",
    "    features['year'] = np.where(\n",
    "        features['month'].isin([10, 11, 12]),\n",
    "        features['year'] + 1, \n",
    "        features['year']\n",
    "    )\n",
    "    features = features[features.year <= year_end]\n",
    "\n",
    "    features.lon, features.lat = round(features.lon, 5), round(features.lat, 5)\n",
    "\n",
    "    features = features[features.month.isin(month_range)]\n",
    "\n",
    "    features = features.set_index(['lon','lat', \"year\", 'month']).unstack()\n",
    "    features.columns = features.columns.map(lambda x: '{}_{}'.format(*x))\n",
    "\n",
    "    features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    features.reset_index(inplace = True)\n",
    "\n",
    "    if points == 4:\n",
    "        weights = weights_4.copy()\n",
    "    elif points == 15:\n",
    "        weights = weights_15.copy()\n",
    "    elif points == 20:\n",
    "        weights = weights_20.copy()\n",
    "\n",
    "    features = features.join(weights.set_index(['lon', 'lat']), on = ['lon', 'lat'])\n",
    "\n",
    "    if crop_mask:\n",
    "        features = features[features.crop_perc > 0]\n",
    "    else:\n",
    "        pass   \n",
    "\n",
    "    features = geopandas.GeoDataFrame(\n",
    "        features, \n",
    "        geometry = geopandas.points_from_xy(x = features.lon, y = features.lat), \n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "\n",
    "    features = (\n",
    "        features\n",
    "        .sjoin(country_shp, how = 'left', predicate = 'within')\n",
    "        .drop(['geometry'], axis = 1)\n",
    "        .rename(columns = {\"index_right\": \"district\"})\n",
    "        .dropna(subset=['district'])\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "\n",
    "    print('Imputing')\n",
    "    \n",
    "    num_cells = len(features) * len(month_range) * int(num_features)\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features.fillna(features.groupby(['year', 'district'], as_index=False).transform('mean'), inplace=True)\n",
    "\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features.fillna(features.groupby(['district'], as_index=False).transform('mean'), inplace=True)\n",
    "\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features = features.dropna(axis=0)\n",
    "\n",
    "    min_yr = min(features.year); max_yr = max(features.year)\n",
    "    min_mn = min(month_range);   max_mn = max(month_range)\n",
    "\n",
    "    f = f'{file[:-1]}yr-{min_yr}-{max_yr}_mn-{min_mn}-{max_mn}_lm-{limit_months}'+\\\n",
    "        f'_cm-{crop_mask}_full.feather'\n",
    "    full_file = here('data', 'random_features', 'full_files', f)\n",
    "\n",
    "    print('Saving')\n",
    "    \n",
    "    features.reset_index(drop=True).to_feather(full_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e778a47-781d-4f2b-818e-47669bf7d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening\n",
      "Imputing\n",
      "Saving\n",
      "CPU times: user 11min 34s, sys: 4min 14s, total: 15min 48s\n",
      "Wall time: 13min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "impute_features(paramlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59cc081-46d1-41b3-933e-ec76ec9f4884",
   "metadata": {},
   "source": [
    "## Load the \"best\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef564ee6-e657-4d4d-9850-12c519fb1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode = True\n",
    "weighted_avg = True\n",
    "file_suffix = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-points_1000-features_yr-2013-2021_mn-4-9_lm-True_cm-True'\n",
    "model_fn_suffix = f'{file_suffix}_wa-{weighted_avg}_he-{hot_encode}'\n",
    "\n",
    "k_model_fn = f'k-fold-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "       \n",
    "with open(here('models', k_model_fn), 'rb') as f:\n",
    "    best_kfold_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734d1c6-c736-4760-aee5-032e5a6fa9a5",
   "metadata": {},
   "source": [
    "## Make high resolution predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7348ed-1c77-460a-a0fd-9cdf0da50e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_f = f'{file_suffix}_full.feather'\n",
    "high_res_fn = here('data', 'random_features', 'full_files', high_res_f)\n",
    "high_res_features = pd.read_feather(high_res_fn)\n",
    "\n",
    "drop_cols = ['year', 'lon', 'lat', 'crop_perc', 'district']\n",
    "\n",
    "if weighted_avg:\n",
    "    high_res_features = high_res_features.set_index(drop_cols)\n",
    "    high_res_features.rename(columns={x:y for x,y in zip(high_res_features.columns,range(0,len(high_res_features.columns)))}, inplace=True)\n",
    "    high_res_features = high_res_features.reset_index()\n",
    "    high_res_features.columns = high_res_features.columns.astype(str)\n",
    "\n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    high_res_features = pd.get_dummies(high_res_features, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "high_res_predictions = high_res_features.copy()[drop_cols]\n",
    "\n",
    "high_res_x_all = high_res_features.drop(drop_cols, axis = 1) \n",
    "high_res_predictions['prediction'] = np.maximum(best_kfold_model.predict(high_res_x_all), 0)\n",
    "\n",
    "high_res_f_pred = f'high-res-pred_k-fold-cv_{model_fn_suffix}.feather'\n",
    "high_res_fn_pred = here('data', 'results', high_res_f_pred)\n",
    "high_res_predictions.to_feather(str(high_res_fn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e3330-804a-4a5c-8069-4ebd429dbca4",
   "metadata": {},
   "source": [
    "## Make summary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "520f7dd1-b830-455c-8573-b1c66c6a9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode = True\n",
    "weighted_avg = True\n",
    "file_suffix = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-points_1000-features_yr-2013-2021_mn-4-9_lm-True_cm-True'\n",
    "model_fn_suffix = f'{file_suffix}_wa-{weighted_avg}_he-{hot_encode}'\n",
    "\n",
    "k_model_fn = f'k-fold-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "       \n",
    "with open(here('models', k_model_fn), 'rb') as f:\n",
    "    best_kfold_model = pickle.load(f)\n",
    "\n",
    "summary_f = f'{file_suffix}_wa-{weighted_avg}_summary.feather'\n",
    "summary_fn = here('data', 'random_features', 'summary', summary_f)\n",
    "summary_features = pd.read_feather(summary_fn)\n",
    "\n",
    "drop_cols = ['district', 'year', 'yield_mt']\n",
    "summary_predictions = summary_features.copy().loc[:, tuple(drop_cols)]\n",
    "\n",
    "if hot_encode:\n",
    "    drop_cols.remove(\"district\")\n",
    "    summary_features = pd.get_dummies(summary_features, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "summary_x_all = summary_features.drop(drop_cols, axis = 1) \n",
    "summary_y_all = np.log10(summary_features.yield_mt.to_numpy() + 1)\n",
    "summary_predictions['log_yield'] = summary_y_all\n",
    "summary_predictions['prediction'] = np.maximum(best_kfold_model.predict(summary_x_all), 0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    summary_x_all, summary_y_all, test_size = 0.2, random_state = 0)\n",
    "\n",
    "kfold = KFold()\n",
    "x_train['kfold_cv_predictions'] = np.maximum(cross_val_predict(best_kfold_model, X = x_train, y = y_train, cv=kfold), 0)\n",
    "x_train['split'], x_test['split']= 'train', 'test'\n",
    "train_test = pd.concat([x_train, x_test])[['split', 'kfold_cv_predictions']]\n",
    "summary_predictions = summary_predictions.join(train_test)\n",
    "\n",
    "summary_f_pred = f'summary-pred_k-fold-cv_{model_fn_suffix}.csv'\n",
    "summary_fn_pred = here('data', 'results', summary_f_pred)\n",
    "summary_predictions.to_csv(summary_fn_pred, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce381e-30c0-43bc-bc73-70af84200f87",
   "metadata": {},
   "source": [
    "## Make high resolution predictions with two sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd5f43-d0a1-4fe2-9158-6ea4dffb4795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_suffix_1 = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-points_1000-features_yr-2013-2021_mn-4-9_lm-True_cm-False'\n",
    "file_suffix_2 = 'sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_1000-features_yr-2016-2022_mn-1-12_lm-False_cm-True'\n",
    "model_fn_suffix = f'best-k-fold-2-sensor-params_he-{True}'\n",
    "\n",
    "k_model_fn = f'k-fold-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "       \n",
    "with open(here('models', k_model_fn), 'rb') as f:\n",
    "    best_kfold_model = pickle.load(f)\n",
    "    \n",
    "high_res_f_1 = f'{file_suffix_1}_full.feather'\n",
    "high_res_fn_1 = here('data', 'random_features', 'full_files', high_res_f_1)\n",
    "high_res_features_1 = pd.read_feather(high_res_fn_1)\n",
    "\n",
    "high_res_f_2 = f'{file_suffix_2}_full.feather'\n",
    "high_res_fn_2 = here('data', 'random_features', 'full_files', high_res_f_2)\n",
    "high_res_features_2 = pd.read_feather(high_res_fn_2)\n",
    "\n",
    "index_cols = ['district', 'year', 'crop_perc', 'lon', 'lat']\n",
    "    \n",
    "high_res_features_1 = high_res_features_1.set_index(index_cols).add_prefix(\"f1_\")\n",
    "high_res_features_2 = high_res_features_2.set_index(index_cols).add_prefix(\"f2_\")\n",
    "\n",
    "high_res_features = high_res_features_1.join(high_res_features_2).reset_index()\n",
    "high_res_features = high_res_features[~high_res_features.isna().any(axis = 1)]\n",
    "\n",
    "drop_cols = ['year', 'lon', 'lat', 'crop_perc', 'district']\n",
    "\n",
    "if weighted_avg:\n",
    "    high_res_features = high_res_features.set_index(drop_cols)\n",
    "    high_res_features.rename(columns={x:y for x,y in zip(high_res_features.columns,range(0,len(high_res_features.columns)))}, inplace=True)\n",
    "    high_res_features = high_res_features.reset_index()\n",
    "    high_res_features.columns = high_res_features.columns.astype(str)\n",
    "\n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    high_res_features = pd.get_dummies(high_res_features, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "high_res_predictions = high_res_features.copy()[drop_cols]\n",
    "\n",
    "high_res_x_all = high_res_features.drop(drop_cols, axis = 1) \n",
    "high_res_predictions['prediction'] = best_kfold_model.predict(high_res_x_all)\n",
    "high_res_predictions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "high_res_f_pred = f'high-res-pred_k-fold-cv_{model_fn_suffix}.feather'\n",
    "high_res_fn_pred = here('data', 'results', high_res_f_pred)\n",
    "high_res_predictions.to_feather(str(high_res_fn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064b94b-43fe-4f41-89b6-f3f3a03e5b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mosaiks-env] *",
   "language": "python",
   "name": "conda-env-mosaiks-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
