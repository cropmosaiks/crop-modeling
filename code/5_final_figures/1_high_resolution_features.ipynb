{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc81613-5df0-41b8-8922-a241b1ca875d",
   "metadata": {},
   "source": [
    "# Modeling Crop Yield\n",
    "## Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f807a9-4078-43eb-8005-651307577218",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import warnings\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from pyhere import here\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyarrow\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import p_tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneGroupOut, cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr,  pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a10e81-3447-491b-8999-19d4df8296b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_shp = geopandas.read_file(here('data', 'geo_boundaries', 'gadm36_ZMB_2.shp'))\n",
    "country_shp = country_shp.set_index('district')\n",
    "\n",
    "crop_df = pd.read_csv(here('data', 'crop_yield', 'cfs_maize_districts_zambia_2009_2022.csv'))\n",
    "crop_df = crop_df.set_index(['district', 'year'])[['yield_mt']]\n",
    "                             \n",
    "weights_4_fn = 'ZMB_cropland_percentage_4k-points.feather'\n",
    "weights_15_fn = 'ZMB_cropland_percentage_15k-points.feather'\n",
    "weights_20_fn = 'ZMB_cropland_percentage_20k-points.feather'\n",
    "  \n",
    "weights_4 = pd.read_feather(here(\"data\", \"land_cover\", weights_4_fn))\n",
    "weights_15 = pd.read_feather(here(\"data\", \"land_cover\", weights_15_fn))\n",
    "weights_20 = pd.read_feather(here(\"data\", \"land_cover\", weights_20_fn))\n",
    "                           \n",
    "weights_4.lon, weights_4.lat = round(weights_4.lon, 5), round(weights_4.lat, 5)\n",
    "weights_15.lon, weights_15.lat = round(weights_15.lon, 5), round(weights_15.lat, 5)\n",
    "weights_20.lon, weights_20.lat = round(weights_20.lon, 5), round(weights_20.lat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d0f439-fb04-4333-a537-110e78b0b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_files(flist, **kwargs):\n",
    "    return pd.concat([pd.read_feather(f, **kwargs) for f in flist], axis=0).reset_index(drop=True)\n",
    "\n",
    "def merge_tuple(x, bases = (tuple, list)):\n",
    "    for e in x:\n",
    "        if type(e) in bases:\n",
    "            for e in merge_tuple(e, bases):\n",
    "                yield e\n",
    "        else:\n",
    "            yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1b58e9-7140-4677-9255-2545e4f94c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satellite</th>\n",
       "      <th>bands</th>\n",
       "      <th>country_code</th>\n",
       "      <th>points</th>\n",
       "      <th>num_features</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_4k-points_1000-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>landsat-8-c2-l2</td>\n",
       "      <td>1-2-3-4-5-6-7</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_15k-points_1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>landsat-c2-l2</td>\n",
       "      <td>r-g-b-nir-swir16-swir22</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1024</td>\n",
       "      <td>landsat-c2-l2_bands-r-g-b-nir-swir16-swir22_ZM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>landsat-8-c2-l2</td>\n",
       "      <td>1-2-3-4-5-6-7</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         satellite                    bands country_code  points num_features  \\\n",
       "0   sentinel-2-l2a                    2-3-4          ZMB       4         1000   \n",
       "1  landsat-8-c2-l2            1-2-3-4-5-6-7          ZMB      15         1000   \n",
       "2   sentinel-2-l2a                  2-3-4-8          ZMB      15         1000   \n",
       "3   sentinel-2-l2a                    2-3-4          ZMB      15         1000   \n",
       "4    landsat-c2-l2  r-g-b-nir-swir16-swir22          ZMB      20         1024   \n",
       "5  landsat-8-c2-l2            1-2-3-4-5-6-7          ZMB      20         1000   \n",
       "6   sentinel-2-l2a                    2-3-4          ZMB      20         1000   \n",
       "\n",
       "                                             pattern  \n",
       "0  sentinel-2-l2a_bands-2-3-4_ZMB_4k-points_1000-...  \n",
       "1  landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-po...  \n",
       "2  sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...  \n",
       "3  sentinel-2-l2a_bands-2-3-4_ZMB_15k-points_1000...  \n",
       "4  landsat-c2-l2_bands-r-g-b-nir-swir16-swir22_ZM...  \n",
       "5  landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-po...  \n",
       "6  sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_groups = pd.DataFrame()\n",
    "satellites = [\"sentinel-2-l2a\",\"landsat-8-c2-l2\",\"landsat-c2-l2\"]\n",
    "for satellite in satellites:\n",
    "    \n",
    "    directory = here(\"data\", \"random_features\", satellite)\n",
    "    files = os.listdir(directory)\n",
    "    files = [f for f in files if f not in ('.gitkeep', '.ipynb_checkpoints')]\n",
    "    files.sort()\n",
    "    \n",
    "    for file in files:\n",
    "        f = file.split(sep=\"_\")\n",
    "        d = {\n",
    "            'satellite'    : f[0],\n",
    "            'bands'        : f[1].replace(\"bands-\", \"\"),\n",
    "            'country_code' : f[2],\n",
    "            'points'       : int(f[3].replace(\"k-points\", \"\")),\n",
    "            'num_features' : f[4].replace(\"-features\", \"\"),\n",
    "            'pattern'      : f[0]+'_'+f[1]+'_'+f[2]+'_'+f[3]+'_'+f[4]+'_*'\n",
    "        }\n",
    "        df = pd.DataFrame(data=d, index=[0])\n",
    "        file_groups = pd.concat([file_groups, df])\n",
    "        \n",
    "file_groups = file_groups.sort_values(by=['points'], ascending=True)\n",
    "file_groups = file_groups.drop_duplicates().reset_index(drop=True)\n",
    "file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4707c3f-ef20-4214-a794-db5a7ea3191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satellite</th>\n",
       "      <th>bands</th>\n",
       "      <th>country_code</th>\n",
       "      <th>points</th>\n",
       "      <th>num_features</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentinel-2-l2a</td>\n",
       "      <td>2-3-4-8</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        satellite    bands country_code  points num_features  \\\n",
       "2  sentinel-2-l2a  2-3-4-8          ZMB      15         1000   \n",
       "\n",
       "                                             pattern  \n",
       "2  sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_10...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_groups = file_groups[file_groups.satellite == \"sentinel-2-l2a\"]\n",
    "file_groups = file_groups[file_groups.points == 15]\n",
    "file_groups = file_groups[file_groups.bands == '2-3-4-8']\n",
    "file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34510e26-c2a5-445c-b198-993a8024b025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_1000-features_*', False, True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = 'limit_months crop_mask'.split()\n",
    "paramlist = list(itertools.product([False,True], repeat = len(names)))\n",
    "paramlist = list(itertools.product(file_groups.pattern.to_list(), paramlist))\n",
    "for i in range(len(paramlist)):\n",
    "    paramlist[i] = tuple(merge_tuple(paramlist[i]))\n",
    "paramlist = [t for t in paramlist if (t[1] == False) & (t[2] == True)][0]\n",
    "paramlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "896b8e36-311e-4295-8440-eb87a3b066a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000-features_*',\n",
       " False,\n",
       " True,\n",
       " False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-points_1000-features_*' #'  yr-2013-2021_mn-4-9_lm-True_cm-False_wa-False_summary.feather'  \n",
    "# paramlist = (f1, True, False, False)\n",
    "\n",
    "# f1 = 'sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_1000-features_*' #'yr-2016-2022_mn-1-12_lm-False_cm-True_wa-False_summary.feather'         \n",
    "# paramlist = (f1, False, True, False)\n",
    "\n",
    "# f1 = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-points_1000-features_*' #'yr-2014-2021_mn-1-12_lm-False_cm-False_wa-True_summary.feather'\n",
    "# paramlist = (f1, False, False, True)\n",
    "\n",
    "# f1 = 'sentinel-2-l2a_bands-2-3-4_ZMB_15k-points_1000-features_*' #'yr-2016-2022_mn-4-9_lm-True_cm-False_wa-False_summary.feather'\n",
    "# paramlist = (f1, True, False, False)\n",
    "\n",
    "# f1 = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-points_1000-features_*' #'yr-2014-2021_mn-1-12_lm-False_cm-True_wa-True_summary.feather'\n",
    "# paramlist = (f1, False, True, True)\n",
    "\n",
    "f1 = 'sentinel-2-l2a_bands-2-3-4_ZMB_20k-points_1000-features_*' #'yr-2016-2022_mn-1-12_lm-False_cm-True_wa-False_summary.feather'\n",
    "paramlist = (f1, False, True, False)\n",
    "\n",
    "paramlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c48216d3-dbcc-41ee-be1e-20c88b0c0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_features(params):\n",
    "    file         = params[0]\n",
    "    limit_months = params[1]\n",
    "    crop_mask    = params[2]\n",
    "    # weighted_avg = params[3]\n",
    "    f            = file.split(sep=\"_\")\n",
    "    satellite    = f[0]\n",
    "    points       = int(f[3].replace(\"k-points\", \"\"))\n",
    "    num_features = int(f[4].replace(\"-features\", \"\"))\n",
    " \n",
    "    path = str(here(\"data\", \"random_features\", satellite, file))\n",
    "    files = glob.glob(pathname=path)\n",
    "    \n",
    "    print('Opening')\n",
    "    \n",
    "    features = get_merged_files(files)\n",
    "\n",
    "    year_end = max(features.year)\n",
    "    \n",
    "    if satellite == \"landsat-c2-l2\":\n",
    "        year_start = 2008\n",
    "    elif satellite == \"landsat-8-c2-l2\":\n",
    "        year_start = 2013 \n",
    "    else:\n",
    "        year_start = 2015 \n",
    "        \n",
    "    month_range = range(4, 10) if limit_months else range(1, 13)\n",
    "\n",
    "    if (satellite == \"landsat-8-c2-l2\") & (limit_months):\n",
    "        month_start = 4\n",
    "    else:\n",
    "        month_start = 10\n",
    "\n",
    "    keep = np.where(\n",
    "        ((features.year == year_start) & (features.month >= month_start)) | (features.year > year_start), True, False)\n",
    "\n",
    "    features = features[keep]\n",
    "\n",
    "    features['year'] = np.where(\n",
    "        features['month'].isin([10, 11, 12]),\n",
    "        features['year'] + 1, \n",
    "        features['year']\n",
    "    )\n",
    "    features = features[features.year <= year_end]\n",
    "\n",
    "    features.lon, features.lat = round(features.lon, 5), round(features.lat, 5)\n",
    "\n",
    "    features = features[features.month.isin(month_range)]\n",
    "\n",
    "    features = features.set_index(['lon','lat', \"year\", 'month']).unstack()\n",
    "    features.columns = features.columns.map(lambda x: '{}_{}'.format(*x))\n",
    "\n",
    "    features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    features.reset_index(inplace = True)\n",
    "\n",
    "    if points == 4:\n",
    "        weights = weights_4.copy()\n",
    "    elif points == 15:\n",
    "        weights = weights_15.copy()\n",
    "    elif points == 20:\n",
    "        weights = weights_20.copy()\n",
    "\n",
    "    features = features.join(weights.set_index(['lon', 'lat']), on = ['lon', 'lat'])\n",
    "\n",
    "    if crop_mask:\n",
    "        features = features[features.crop_perc > 0]\n",
    "    else:\n",
    "        pass   \n",
    "\n",
    "    features = geopandas.GeoDataFrame(\n",
    "        features, \n",
    "        geometry = geopandas.points_from_xy(x = features.lon, y = features.lat), \n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "\n",
    "    features = (\n",
    "        features\n",
    "        .sjoin(country_shp, how = 'left', predicate = 'within')\n",
    "        .drop(['geometry'], axis = 1)\n",
    "        .rename(columns = {\"index_right\": \"district\"})\n",
    "        .dropna(subset=['district'])\n",
    "        .reset_index(drop = True)\n",
    "    )\n",
    "\n",
    "    print('Imputing')\n",
    "    \n",
    "    num_cells = len(features) * len(month_range) * int(num_features)\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features.fillna(features.groupby(['year', 'district'], as_index=False).transform('mean'), inplace=True)\n",
    "\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features.fillna(features.groupby(['district'], as_index=False).transform('mean'), inplace=True)\n",
    "\n",
    "    ln_ft = len(features); ln_na = len(features.dropna())\n",
    "    features = features.dropna(axis=0)\n",
    "\n",
    "    min_yr = min(features.year); max_yr = max(features.year)\n",
    "    min_mn = min(month_range);   max_mn = max(month_range)\n",
    "\n",
    "    f = f'{file[:-1]}yr-{min_yr}-{max_yr}_mn-{min_mn}-{max_mn}_lm-{limit_months}'+\\\n",
    "        f'_cm-{crop_mask}_full.feather'\n",
    "    full_file = here('data', 'random_features', 'full_files', f)\n",
    "\n",
    "    print('Saving')\n",
    "    \n",
    "    features.reset_index(drop=True).to_feather(full_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e778a47-781d-4f2b-818e-47669bf7d4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening\n",
      "Imputing\n",
      "Saving\n",
      "CPU times: user 11min 34s, sys: 4min 14s, total: 15min 48s\n",
      "Wall time: 13min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "impute_features(paramlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59cc081-46d1-41b3-933e-ec76ec9f4884",
   "metadata": {},
   "source": [
    "## Load the \"best\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef564ee6-e657-4d4d-9850-12c519fb1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode = True\n",
    "weighted_avg = True\n",
    "file_suffix = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-points_1000-features_yr-2013-2021_mn-4-9_lm-True_cm-True'\n",
    "model_fn_suffix = f'{file_suffix}_wa-{weighted_avg}_he-{hot_encode}'\n",
    "\n",
    "k_model_fn = f'k-fold-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "       \n",
    "with open(here('models', k_model_fn), 'rb') as f:\n",
    "    best_kfold_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734d1c6-c736-4760-aee5-032e5a6fa9a5",
   "metadata": {},
   "source": [
    "## Make high resolution predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7348ed-1c77-460a-a0fd-9cdf0da50e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res_f = f'{file_suffix}_full.feather'\n",
    "high_res_fn = here('data', 'random_features', 'full_files', high_res_f)\n",
    "high_res_features = pd.read_feather(high_res_fn)\n",
    "\n",
    "drop_cols = ['year', 'lon', 'lat', 'crop_perc', 'district']\n",
    "\n",
    "if weighted_avg:\n",
    "    high_res_features = high_res_features.set_index(drop_cols)\n",
    "    high_res_features.rename(columns={x:y for x,y in zip(high_res_features.columns,range(0,len(high_res_features.columns)))}, inplace=True)\n",
    "    high_res_features = high_res_features.reset_index()\n",
    "    high_res_features.columns = high_res_features.columns.astype(str)\n",
    "\n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    high_res_features = pd.get_dummies(high_res_features, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "high_res_predictions = high_res_features.copy()[drop_cols]\n",
    "\n",
    "high_res_x_all = high_res_features.drop(drop_cols, axis = 1) \n",
    "high_res_predictions['prediction'] = np.maximum(best_kfold_model.predict(high_res_x_all), 0)\n",
    "\n",
    "high_res_f_pred = f'high-res-pred_k-fold-cv_{model_fn_suffix}.feather'\n",
    "high_res_fn_pred = here('data', 'results', high_res_f_pred)\n",
    "high_res_predictions.to_feather(str(high_res_fn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e3330-804a-4a5c-8069-4ebd429dbca4",
   "metadata": {},
   "source": [
    "## Make summary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "520f7dd1-b830-455c-8573-b1c66c6a9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encode = True\n",
    "weighted_avg = True\n",
    "file_suffix = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_20k-points_1000-features_yr-2013-2021_mn-4-9_lm-True_cm-True'\n",
    "model_fn_suffix = f'{file_suffix}_wa-{weighted_avg}_he-{hot_encode}'\n",
    "\n",
    "k_model_fn = f'k-fold-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "       \n",
    "with open(here('models', k_model_fn), 'rb') as f:\n",
    "    best_kfold_model = pickle.load(f)\n",
    "\n",
    "summary_f = f'{file_suffix}_wa-{weighted_avg}_summary.feather'\n",
    "summary_fn = here('data', 'random_features', 'summary', summary_f)\n",
    "summary_features = pd.read_feather(summary_fn)\n",
    "\n",
    "drop_cols = ['district', 'year', 'yield_mt']\n",
    "summary_predictions = summary_features.copy().loc[:, tuple(drop_cols)]\n",
    "\n",
    "if hot_encode:\n",
    "    drop_cols.remove(\"district\")\n",
    "    summary_features = pd.get_dummies(summary_features, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "summary_x_all = summary_features.drop(drop_cols, axis = 1) \n",
    "summary_y_all = np.log10(summary_features.yield_mt.to_numpy() + 1)\n",
    "summary_predictions['log_yield'] = summary_y_all\n",
    "summary_predictions['prediction'] = np.maximum(best_kfold_model.predict(summary_x_all), 0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    summary_x_all, summary_y_all, test_size = 0.2, random_state = 0)\n",
    "\n",
    "kfold = KFold()\n",
    "x_train['kfold_cv_predictions'] = np.maximum(cross_val_predict(best_kfold_model, X = x_train, y = y_train, cv=kfold), 0)\n",
    "x_train['split'], x_test['split']= 'train', 'test'\n",
    "train_test = pd.concat([x_train, x_test])[['split', 'kfold_cv_predictions']]\n",
    "summary_predictions = summary_predictions.join(train_test)\n",
    "\n",
    "summary_f_pred = f'summary-pred_k-fold-cv_{model_fn_suffix}.csv'\n",
    "summary_fn_pred = here('data', 'results', summary_f_pred)\n",
    "summary_predictions.to_csv(summary_fn_pred, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce381e-30c0-43bc-bc73-70af84200f87",
   "metadata": {},
   "source": [
    "## Make high resolution predictions with two sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd5f43-d0a1-4fe2-9158-6ea4dffb4795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_suffix_1 = 'landsat-8-c2-l2_bands-1-2-3-4-5-6-7_ZMB_15k-points_1000-features_yr-2013-2021_mn-4-9_lm-True_cm-False'\n",
    "file_suffix_2 = 'sentinel-2-l2a_bands-2-3-4-8_ZMB_15k-points_1000-features_yr-2016-2022_mn-1-12_lm-False_cm-True'\n",
    "model_fn_suffix = f'best-k-fold-2-sensor-params_he-{True}'\n",
    "\n",
    "k_model_fn = f'k-fold-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "logo_model_fn = f'logo-cv_rr-model_{model_fn_suffix}.pkl'\n",
    "       \n",
    "with open(here('models', k_model_fn), 'rb') as f:\n",
    "    best_kfold_model = pickle.load(f)\n",
    "    \n",
    "high_res_f_1 = f'{file_suffix_1}_full.feather'\n",
    "high_res_fn_1 = here('data', 'random_features', 'full_files', high_res_f_1)\n",
    "high_res_features_1 = pd.read_feather(high_res_fn_1)\n",
    "\n",
    "high_res_f_2 = f'{file_suffix_2}_full.feather'\n",
    "high_res_fn_2 = here('data', 'random_features', 'full_files', high_res_f_2)\n",
    "high_res_features_2 = pd.read_feather(high_res_fn_2)\n",
    "\n",
    "index_cols = ['district', 'year', 'crop_perc', 'lon', 'lat']\n",
    "    \n",
    "high_res_features_1 = high_res_features_1.set_index(index_cols).add_prefix(\"f1_\")\n",
    "high_res_features_2 = high_res_features_2.set_index(index_cols).add_prefix(\"f2_\")\n",
    "\n",
    "high_res_features = high_res_features_1.join(high_res_features_2).reset_index()\n",
    "high_res_features = high_res_features[~high_res_features.isna().any(axis = 1)]\n",
    "\n",
    "drop_cols = ['year', 'lon', 'lat', 'crop_perc', 'district']\n",
    "\n",
    "if weighted_avg:\n",
    "    high_res_features = high_res_features.set_index(drop_cols)\n",
    "    high_res_features.rename(columns={x:y for x,y in zip(high_res_features.columns,range(0,len(high_res_features.columns)))}, inplace=True)\n",
    "    high_res_features = high_res_features.reset_index()\n",
    "    high_res_features.columns = high_res_features.columns.astype(str)\n",
    "\n",
    "if hot_encode:\n",
    "    drop_cols.remove('district')\n",
    "    high_res_features = pd.get_dummies(high_res_features, columns=[\"district\"], drop_first=False)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "high_res_predictions = high_res_features.copy()[drop_cols]\n",
    "\n",
    "high_res_x_all = high_res_features.drop(drop_cols, axis = 1) \n",
    "high_res_predictions['prediction'] = best_kfold_model.predict(high_res_x_all)\n",
    "high_res_predictions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "high_res_f_pred = f'high-res-pred_k-fold-cv_{model_fn_suffix}.feather'\n",
    "high_res_fn_pred = here('data', 'results', high_res_f_pred)\n",
    "high_res_predictions.to_feather(str(high_res_fn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064b94b-43fe-4f41-89b6-f3f3a03e5b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mosaiks-env] *",
   "language": "python",
   "name": "conda-env-mosaiks-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
