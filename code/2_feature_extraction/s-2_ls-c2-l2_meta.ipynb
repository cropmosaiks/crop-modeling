{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440e592b-c09d-4e75-91fc-00e5d36d391d",
   "metadata": {},
   "source": [
    "## MOSAIKS meta data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522ab90b-af76-477d-a930-4d63c6847028",
   "metadata": {
    "gather": {
     "logged": 1650114371790
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/geopandas/dask-geopandas\n",
    "!pip install -q pyhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281d0543-f6b0-4b68-a4ba-a99c547b00c8",
   "metadata": {
    "gather": {
     "logged": 1651174535306
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import calendar\n",
    "import re\n",
    "\n",
    "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
    "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
    "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
    "    GDAL_SWATH_SIZE=\"200000000\",\n",
    "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
    ")\n",
    "os.environ.update(RASTERIO_BEST_PRACTICES)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhere import here\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "import rasterio\n",
    "import rasterio.warp\n",
    "import rasterio.mask\n",
    "import shapely.geometry\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "from dask.distributed import Client\n",
    "\n",
    "from pystac import Item\n",
    "import stackstac\n",
    "import pyproj\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning, module=\"torch\")\n",
    "warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "\n",
    "\n",
    "# Disabling the benchmarking feature with torch.backends.cudnn.benchmark = False \n",
    "# causes cuDNN to deterministically select an algorithm, possibly at the cost of reduced performance.\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefa598-0653-4fd4-b7ce-14fb7c4e59e2",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28b414c-1d02-491a-9518-1b777898950d",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1651174535433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "num_features = 1024\n",
    "country_code = 'ZMB'\n",
    "use_file = True\n",
    "# use_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce354d45-8f23-4630-ae55-95738e4a443d",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1651174535433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "satellite = \"landsat-c2-l2\"\n",
    "bands = [\"red\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb7126f-4aaf-4615-82da-efc06a2140bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if satellite == \"landsat-c2-l2\":\n",
    "    resolution = 30\n",
    "    min_image_edge = 6\n",
    "else:\n",
    "    resolution = 10\n",
    "    min_image_edge = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9b0ec-c334-4751-91c4-91dabff6a44a",
   "metadata": {},
   "source": [
    "## Create grid and sample points to featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09c0e05-9ba6-407e-9260-5f9f00decc18",
   "metadata": {
    "gather": {
     "logged": 1651174535812
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19598, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_file:\n",
    "    gdf = pd.read_feather(here('data', 'land_cover', 'ZMB_cropland_percentage_20k-points.feather'))\n",
    "    gdf = (\n",
    "        geopandas\n",
    "        .GeoDataFrame(\n",
    "            gdf, \n",
    "            geometry = geopandas.points_from_xy(x = gdf.lon, y = gdf.lat), \n",
    "            crs='EPSG:4326')\n",
    "    )\n",
    "else:\n",
    "    cell_size = 0.01  # Roughly 1 km\n",
    "    ### get country shape\n",
    "    country_file_name = f\"data/geo_boundaries/africa_adm0.geojson\"\n",
    "    africa = geopandas.read_file(country_file_name)\n",
    "    country = africa[africa.adm0_a3 == country_code]\n",
    "    #### This would be simpler, but throws an error down the line if used \n",
    "    # world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "    # country = world.query(f'iso_a3 == \"{country_code}\"')\n",
    "    ### Create grid of points\n",
    "    cell_size = .01  # Very roughly 1 km\n",
    "    xmin, ymin, xmax, ymax = country.total_bounds\n",
    "    xs = list(np.arange(xmin, xmax + cell_size, cell_size))\n",
    "    ys = list(np.arange(ymin, ymax + cell_size, cell_size))\n",
    "    def make_cell(x, y, cell_size):\n",
    "        ring = [\n",
    "            (x, y),\n",
    "            (x + cell_size, y),\n",
    "            (x + cell_size, y + cell_size),\n",
    "            (x, y + cell_size)\n",
    "        ]\n",
    "        cell = shapely.geometry.Polygon(ring).centroid\n",
    "        return cell\n",
    "    center_points = []\n",
    "    for x in xs:\n",
    "        for y in ys:\n",
    "            cell = make_cell(x, y, cell_size)\n",
    "            center_points.append(cell)\n",
    "    ### Put grid into a GeDataFrame for cropping to country shape\n",
    "    gdf = geopandas.GeoDataFrame({'geometry': center_points}, crs = 'EPSG:4326')\n",
    "    gdf['lon'], gdf['lat'] = gdf.geometry.x, gdf.geometry.y\n",
    "    ### Subset to country \n",
    "    ### This buffer ensures that no points are take at the border \n",
    "    ### which would lead to duplication with neighboring countries\n",
    "    gdf = gdf[gdf.within(country.unary_union.buffer(-0.005))]\n",
    "    gdf = gdf[['lon', 'lat', 'geometry']].reset_index(drop = True)\n",
    "    gdf = gdf.sample(frac = 0.1, random_state=42, ignore_index=False)\n",
    "    points = gdf[[\"lon\", \"lat\"]].to_numpy()\n",
    "pt_len = gdf.shape[0]\n",
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebfd0c2e-78fe-45a9-99a4-13112f0da841",
   "metadata": {
    "gather": {
     "logged": 1651174537641
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NPARTITIONS = 250\n",
    "\n",
    "ddf = dask_geopandas.from_geopandas(gdf, npartitions=1)\n",
    "hd = ddf.hilbert_distance().compute()\n",
    "gdf[\"hd\"] = hd\n",
    "gdf = gdf.sort_values(\"hd\")\n",
    "\n",
    "dgdf = dask_geopandas.from_geopandas(gdf, npartitions=NPARTITIONS, sort=False)\n",
    "\n",
    "del ddf, hd, gdf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b07b3638-e152-4858-972a-5bef5486ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 0.005\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, points, items, buffer=buffer_size):\n",
    "        self.points = points\n",
    "        self.items = items\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        lon, lat = self.points[idx]\n",
    "        fn = self.items[idx]\n",
    "\n",
    "        if fn is None:\n",
    "            return None\n",
    "        else:\n",
    "            stack = stackstac.stack(fn, assets=bands, resolution=resolution)\n",
    "            x_min, y_min = pyproj.Proj(stack.crs)(lon-self.buffer, lat-self.buffer)\n",
    "            x_max, y_max = pyproj.Proj(stack.crs)(lon+self.buffer, lat+self.buffer)\n",
    "            aoi = stack.loc[..., y_max:y_min, x_min:x_max]\n",
    "            data = aoi.data.squeeze()\n",
    "            na_percentage = np.isnan(data).sum() / (data.shape[0] * data.shape[1])\n",
    "            return na_percentage\n",
    "        \n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, points, items, buffer=buffer_size):\n",
    "#         self.points = points\n",
    "#         self.items = items\n",
    "#         self.buffer = buffer\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.points.shape[0]\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "\n",
    "#         lon, lat = self.points[idx]\n",
    "#         fn = self.items[idx]\n",
    "\n",
    "#         if fn is None:\n",
    "#             return None\n",
    "#         else:\n",
    "#             stack = stackstac.stack(\n",
    "#                 fn,\n",
    "#                 assets=bands,\n",
    "#                 resolution=resolution,\n",
    "#             )\n",
    "#             x_min, y_min = pyproj.Proj(stack.crs)(lon-self.buffer, lat-self.buffer)\n",
    "#             x_max, y_max = pyproj.Proj(stack.crs)(lon+self.buffer, lat+self.buffer)\n",
    "#             aoi = stack.loc[..., y_max:y_min, x_min:x_max]\n",
    "#             data = aoi.compute(\n",
    "#                 scheduler=\"single-threaded\"\n",
    "#                 )\n",
    "#             out_image = data.data.squeeze()\n",
    "#             out_image = torch.from_numpy(out_image).float()\n",
    "#             return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94fe0280-66ed-4491-9bec-d69e08f67840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:  \n",
      "    Satellite: landsat-c2-l2  \n",
      "    Pixel resolution: 30  \n",
      "    Grid resolution: 0.01 degree squared (WGS84) \n",
      "    Cloud limit: 20%  \n",
      "    Bands: ['red'] \n",
      "    Number of points: 19598 \n",
      "    Number of features: 1024 features \n",
      "    Year range: 2019 to 2022 \n",
      "\n",
      "Matching images to points for: 1-2019\n",
      "Found acceptable images for 4123/19598 points in 19.72 seconds\n",
      "Collecting metadata: 01-2019\n",
      "0/4123 -- 0.00% -- 15.94 seconds\n",
      "1000/4123 -- 24.25% -- 1956.87 seconds\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error reading Window(col_off=5120, row_off=4096, width=1024, height=1024) from 'https://landsateuwest.blob.core.windows.net/landsat-c2/level-2/standard/etm/2019/173/070/LE07_L2SP_173070_20190127_20200827_02_T1/LE07_L2SP_173070_20190127_20200827_02_T1_SR_B3.TIF?st=2022-10-03T19%3A23%3A20Z&se=2022-10-04T20%3A08%3A20Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-04T13%3A27%3A51Z&ske=2022-10-11T13%3A27%3A51Z&sks=b&skv=2021-06-08&sig=356AAYAR6VGp2QgpRtpXnisZWNfE4Wn6NPuiYq3wQ0c%3D': RasterioIOError('Read or write failed. IReadBlock failed at X offset 10, Y offset 32: IReadBlock failed at X offset 19, Y offset 15: TIFFReadEncodedTile() failed.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_io.pyx:936\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase._read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:174\u001b[0m, in \u001b[0;36mrasterio._io.io_multi_band\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:191\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_int\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_AppDefinedError\u001b[0m: IReadBlock failed at X offset 10, Y offset 32: IReadBlock failed at X offset 19, Y offset 15: TIFFReadEncodedTile() failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/stackstac/rio_reader.py:387\u001b[0m, in \u001b[0;36mAutoParallelRioReader.read\u001b[0;34m(self, window, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmasked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ^ NOTE: we always do a masked array, so we can safely apply scales and offsets\u001b[39;49;00m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# without potentially altering pixels that should have been the ``fill_value``\u001b[39;49;00m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/stackstac/rio_reader.py:227\u001b[0m, in \u001b[0;36mThreadLocalRioDataset.read\u001b[0;34m(self, window, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env\u001b[38;5;241m.\u001b[39mread:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mrasterio/_warp.pyx:1235\u001b[0m, in \u001b[0;36mrasterio._warp.WarpedVRTReaderBase.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:612\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase.read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_io.pyx:939\u001b[0m, in \u001b[0;36mrasterio._io.DatasetReaderBase._read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: Read or write failed. IReadBlock failed at X offset 10, Y offset 32: IReadBlock failed at X offset 19, Y offset 15: TIFFReadEncodedTile() failed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:183\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/array/core.py:1696\u001b[0m, in \u001b[0;36mArray.__array__\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1696\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m   1698\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/base.py:315\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    598\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 600\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "    \u001b[0;31m[... skipping similar frames: _execute_task at line 119 (2 times), <genexpr> at line 119 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[0;32m--> 990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:149\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, out, cache)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[1;32m    148\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[0;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/stackstac/to_dask.py:185\u001b[0m, in \u001b[0;36mfetch_raster_window\u001b[0;34m(reader_table, slices, dtype, fill_value)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Only read if the window we're fetching actually overlaps with the asset\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m windows\u001b[38;5;241m.\u001b[39mintersect(current_window, asset_window):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# NOTE: when there are multiple assets, we _could_ parallelize these reads with our own threadpool.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# However, that would probably increase memory usage, since the internal, thread-local GDAL datasets\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# would end up copied to even more threads.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# TODO when the Reader won't be rescaling, support passing `output` to avoid the copy?\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_empty:\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;66;03m# Turn `output` from a broadcast-trick array to a real array, so it's writeable\u001b[39;00m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    190\u001b[0m             np\u001b[38;5;241m.\u001b[39misnan(data)\n\u001b[1;32m    191\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(fill_value)\n\u001b[1;32m    192\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mequal(data, fill_value)\n\u001b[1;32m    193\u001b[0m         )\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;66;03m# Unless the data we just read is all empty anyway\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mosaiks-env/lib/python3.8/site-packages/stackstac/rio_reader.py:400\u001b[0m, in \u001b[0;36mAutoParallelRioReader.read\u001b[0;34m(self, window, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nodata_for_window(window, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale:\n\u001b[1;32m    403\u001b[0m     scale, offset \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mscale_offset\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error reading Window(col_off=5120, row_off=4096, width=1024, height=1024) from 'https://landsateuwest.blob.core.windows.net/landsat-c2/level-2/standard/etm/2019/173/070/LE07_L2SP_173070_20190127_20200827_02_T1/LE07_L2SP_173070_20190127_20200827_02_T1_SR_B3.TIF?st=2022-10-03T19%3A23%3A20Z&se=2022-10-04T20%3A08%3A20Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-04T13%3A27%3A51Z&ske=2022-10-11T13%3A27%3A51Z&sks=b&skv=2021-06-08&sig=356AAYAR6VGp2QgpRtpXnisZWNfE4Wn6NPuiYq3wQ0c%3D': RasterioIOError('Read or write failed. IReadBlock failed at X offset 10, Y offset 32: IReadBlock failed at X offset 19, Y offset 15: TIFFReadEncodedTile() failed.')"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_month = 1\n",
    "year_start = 2019\n",
    "year_end = 2022\n",
    "\n",
    "cloud_limit = 20\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "workers = os.cpu_count() -10\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "Parameters:  \n",
    "    Satellite: {satellite}  \n",
    "    Pixel resolution: {resolution}  \n",
    "    Grid resolution: {buffer_size * 2} degree squared (WGS84) \n",
    "    Cloud limit: {cloud_limit}%  \n",
    "    Bands: {bands} \n",
    "    Number of points: {pt_len} \n",
    "    Number of features: {num_features} features \n",
    "    Year range: {year_start} to {year_end} \n",
    "\"\"\"\n",
    ")\n",
    "for yr in range(year_start, year_end+1):\n",
    "    \n",
    "    # data = pd.DataFrame()\n",
    "    df = []\n",
    "\n",
    "    if (yr == year_start):\n",
    "        month_range = range(start_month, 13)\n",
    "    else:\n",
    "        month_range = range(1, 13) \n",
    "\n",
    "    for mn in month_range:\n",
    "\n",
    "        if mn < 10:\n",
    "            month = \"0\"+str(mn)\n",
    "        else:\n",
    "            month = mn\n",
    "\n",
    "        def query(points):\n",
    "            \"\"\"\n",
    "            Find a STAC item for points in the `points` DataFrame\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            points : geopandas.GeoDataFrame\n",
    "                A GeoDataFrame\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            geopandas.GeoDataFrame\n",
    "                A new geopandas.GeoDataFrame with a `stac_item` column containing the STAC\n",
    "                item that covers each point.\n",
    "            \"\"\"\n",
    "            intersects = shapely.geometry.mapping(points.unary_union.convex_hull)\n",
    "\n",
    "            catalog = pystac_client.Client.open(\n",
    "                \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "            )\n",
    "            # Define search date range for query\n",
    "            ending_day = calendar.monthrange(yr, int(mn))[1]\n",
    "            search_start = f\"{yr}-{month}-1\" \n",
    "            search_end = f\"{yr}-{month}-{ending_day}\" \n",
    "\n",
    "            # The time frame in which we search for non-cloudy imagery\n",
    "            search = catalog.search(\n",
    "                collections=[satellite],  \n",
    "                intersects=intersects,\n",
    "                datetime=[search_start, search_end],\n",
    "                query={\"eo:cloud_cover\": {\"lt\": cloud_limit}},\n",
    "                limit=500,\n",
    "            )\n",
    "            ic = search.get_all_items_as_dict()\n",
    "            features = ic[\"features\"]\n",
    "            features_d = {item[\"id\"]: item for item in features}\n",
    "            data = {\n",
    "                \"eo:cloud_cover\": [],\n",
    "                \"geometry\": [],\n",
    "            }\n",
    "            index = []\n",
    "            for item in features:\n",
    "                data[\"eo:cloud_cover\"].append(item[\"properties\"][\"eo:cloud_cover\"])\n",
    "                data[\"geometry\"].append(shapely.geometry.shape(item[\"geometry\"]))\n",
    "                index.append(item[\"id\"])\n",
    "            items = geopandas.GeoDataFrame(data, index=index, geometry=\"geometry\").sort_values(\n",
    "                \"eo:cloud_cover\"\n",
    "            )\n",
    "            point_list = points.geometry.tolist()\n",
    "            point_items = []\n",
    "            for point in point_list:\n",
    "                covered_by = items[items.covers(point)]\n",
    "                if len(covered_by):\n",
    "                    point_items.append(features_d[covered_by.index[0]])\n",
    "                else:\n",
    "                    # There weren't any scenes matching our conditions for this point (too cloudy)\n",
    "                    point_items.append(None)\n",
    "            return points.assign(stac_item=point_items)\n",
    "\n",
    "        tic = time.time()\n",
    "        print(\"Matching images to points for: \", mn, \"-\", yr, sep = \"\")\n",
    "\n",
    "        with Client(n_workers=16) as client:\n",
    "            meta = dgdf._meta.assign(stac_item=[])\n",
    "            df2 = dgdf.map_partitions(query, meta=meta).compute()\n",
    "            \n",
    "        df3 = df2.dropna(subset=[\"stac_item\"]).reset_index(drop = True)\n",
    "\n",
    "        matching_items = []\n",
    "        for item in df3.stac_item.tolist():\n",
    "            signed_item = pc.sign(Item.from_dict(item))\n",
    "            matching_items.append(signed_item)\n",
    "\n",
    "        points = df3[[\"lon\", \"lat\"]].to_numpy()\n",
    "\n",
    "        print(\"Found acceptable images for \", \n",
    "              points.shape[0], \"/\", pt_len,\n",
    "              \" points in \", \n",
    "              f\"{time.time()-tic:0.2f} seconds\", \n",
    "              sep = \"\")\n",
    "\n",
    "        \n",
    "#         print(\"Collecting metadata: \", month, \"-\", yr, sep = \"\") \n",
    "#         na_perc = np.zeros((points.shape[0], 1), dtype=float)\n",
    "#         tic = time.time()\n",
    "#         for i in range(0, len(points)):\n",
    "#             lon, lat = points[i]\n",
    "#             fn = matching_items[i]\n",
    "#             stack = stackstac.stack(fn, assets=bands,  resolution=resolution)\n",
    "#             x_min, y_min = pyproj.Proj(stack.crs)(lon-buffer_size, lat-buffer_size)\n",
    "#             x_max, y_max = pyproj.Proj(stack.crs)(lon+buffer_size, lat+buffer_size)\n",
    "#             aoi = stack.loc[..., y_max:y_min, x_min:x_max]\n",
    "#             out_image = aoi.data.squeeze()\n",
    "#             out_image = torch.from_numpy(out_image.compute()).float()\n",
    "#             na_perc[i] = ((out_image.isnan()).sum() / out_image.numel()).item()\n",
    "#             if i % 1000 == 0:\n",
    "#                 print(\n",
    "#                     f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "#                     + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "#                 )\n",
    "#                 tic = time.time()\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "#         print(\"Collecting metadata: \", month, \"-\", yr, sep = \"\")   \n",
    "#         dataset = CustomDataset(points, matching_items)    \n",
    "#         na_perc = np.zeros((points.shape[0], 1), dtype=float)\n",
    "#         tic = time.time()\n",
    "#         i = 0\n",
    "#         for image in dataset:\n",
    "#             na_perc[i] = ((image.isnan()).sum() / image.numel()).item()\n",
    "#             if i % 1000 == 0:\n",
    "#                 print(\n",
    "#                     f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "#                     + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "#                 )\n",
    "#                 tic = time.time()\n",
    "#             i += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        dataset = CustomDataset(points, matching_items)\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=workers,\n",
    "            collate_fn=lambda x: x,\n",
    "        )\n",
    "\n",
    "        print(\"Collecting metadata: \", month, \"-\", yr, sep = \"\")\n",
    "\n",
    "        na_perc = np.zeros((points.shape[0], 1), dtype=float)\n",
    "        tic = time.time()\n",
    "        i = 0\n",
    "        for images in dataloader:\n",
    "            for image in images:\n",
    "                \n",
    "                na_perc[i] = image\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "                        + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "                    )\n",
    "                    tic = time.time()\n",
    "                i += 1\n",
    "\n",
    "        df3['stac_id'] = df3['stac_item'].apply(pd.Series)['id']\n",
    "        df3['platform'] = df3['stac_item'].apply(pd.Series)['properties'].apply(pd.Series)['platform']\n",
    "        df3['cloud_cover'] = df3['stac_item'].apply(pd.Series)['properties'].apply(pd.Series)['eo:cloud_cover']\n",
    "        df3[['na_percent', 'year', \"month\"]] = na_perc, yr, mn\n",
    "        df3.drop(['geometry', 'hd', 'stac_item'], axis = 1, inplace = True)\n",
    "        df3 = pd.DataFrame(df3)\n",
    "        \n",
    "        fn = f'{satellite}_{country_code}_{pt_len/1000:.0f}k-points_meta_{yr}_{mn}.csv'\n",
    "        file_name = here('data', 'feature_meta_data', fn)\n",
    "        print(\"Saving file as:\", file_name, \"\\n\")\n",
    "        df3.to_csv(file_name, index=False)\n",
    "        \n",
    "        # df.append(df3)\n",
    "        \n",
    "#     data = pd.concat(df).reset_index(drop = True)\n",
    "    \n",
    "#     fn = f'{satellite}_{country_code}_{pt_len/1000:.0f}k-points_meta.csv'\n",
    "#     file_name = here('data', 'feature_meta_data', satellite, fn)\n",
    "#     print(\"Saving file as:\", file_name)\n",
    "#     data.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e03fd0-8ddd-41f5-a9e1-4505c841ca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1409"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
