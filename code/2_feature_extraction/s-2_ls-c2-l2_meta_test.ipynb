{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440e592b-c09d-4e75-91fc-00e5d36d391d",
   "metadata": {},
   "source": [
    "## MOSAIKS feature extraction\n",
    "\n",
    "This tutorial demonstrates the **MOSAIKS** method for extracting _feature vectors_ from satellite imagery patches for use in downstream modeling tasks. It will show:\n",
    "- How to extract 1km$^2$ patches of Sentinel 2 or Landsat multispectral imagery for a list of latitude, longitude points\n",
    "- How to extract summary features from each of these imagery patches\n",
    "- How to use the summary features in a linear model of the population density at each point\n",
    "\n",
    "### Background\n",
    "\n",
    "Consider the case where you have a dataset of latitude and longitude points assosciated with some dependent variable (for example: population density, weather, housing prices, biodiversity) and, potentially, other independent variables. You would like to model the dependent variable as a function of the independent variables, but instead of including latitude and longitude directly in this model, you would like to include some high dimensional representation of what the Earth looks like at that point (that hopefully explains some of the variance in the dependent variable!). From the computer vision literature, there are various [representation learning techniques](https://en.wikipedia.org/wiki/Feature_learning) that can be used to do this, i.e. extract _features vectors_ from imagery. This notebook gives an implementation of the technique described in [Rolf et al. 2021](https://www.nature.com/articles/s41467-021-24638-z), \"A generalizable and accessible approach to machine learning with global satellite imagery\" called Multi-task Observation using Satellite Imagery & Kitchen Sinks (**MOSAIKS**). For more information about **MOSAIKS** see the [project's webpage](http://www.globalpolicy.science/mosaiks).\n",
    "\n",
    "### Environment setup\n",
    "This notebook works with or without an API key, but you will be given more permissive access to the data with an API key.\n",
    "- If you're running this on the [Planetary Computer Hub](http://planetarycomputer.microsoft.com/compute), make sure to choose the **GPU - PyTorch** profile when presented with the form to choose your environment.\n",
    "- The Planetary Computer Hub is pre-configured to use your API key.\n",
    "- To use your API key locally, set the environment variable `PC_SDK_SUBSCRIPTION_KEY` or use `pc.settings.set_subscription_key(<YOUR API Key>)`.\n",
    "    \n",
    "**Notes**:\n",
    "- This example uses either\n",
    "    - [sentinel-2-l2a data](https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a)\n",
    "    - [landsat-c2-l2 data](https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2)\n",
    "- The techniques used here apply equally well to other remote-sensing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522ab90b-af76-477d-a930-4d63c6847028",
   "metadata": {
    "gather": {
     "logged": 1650114371790
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q git+https://github.com/geopandas/dask-geopandas\n",
    "!pip install -q pyhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281d0543-f6b0-4b68-a4ba-a99c547b00c8",
   "metadata": {
    "gather": {
     "logged": 1651174535306
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import calendar\n",
    "import re\n",
    "\n",
    "RASTERIO_BEST_PRACTICES = dict(  # See https://github.com/pangeo-data/cog-best-practices\n",
    "    CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    GDAL_DISABLE_READDIR_ON_OPEN=\"EMPTY_DIR\",\n",
    "    AWS_NO_SIGN_REQUEST=\"YES\",\n",
    "    GDAL_MAX_RAW_BLOCK_CACHE_SIZE=\"200000000\",\n",
    "    GDAL_SWATH_SIZE=\"200000000\",\n",
    "    VSI_CURL_CACHE_SIZE=\"200000000\",\n",
    ")\n",
    "os.environ.update(RASTERIO_BEST_PRACTICES)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhere import here\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy import ndimage as nd\n",
    "\n",
    "import rasterio\n",
    "import rasterio.warp\n",
    "import rasterio.mask\n",
    "import shapely.geometry\n",
    "import geopandas\n",
    "import dask_geopandas\n",
    "from dask.distributed import Client\n",
    "\n",
    "from pystac import Item\n",
    "import stackstac\n",
    "import pyproj\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning, module=\"torch\")\n",
    "warnings.filterwarnings(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "\n",
    "\n",
    "# Disabling the benchmarking feature with torch.backends.cudnn.benchmark = False \n",
    "# causes cuDNN to deterministically select an algorithm, possibly at the cost of reduced performance.\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefa598-0653-4fd4-b7ce-14fb7c4e59e2",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28b414c-1d02-491a-9518-1b777898950d",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1651174535433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "num_features = 1024\n",
    "country_code = 'ZMB'\n",
    "use_file = True\n",
    "# use_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce354d45-8f23-4630-ae55-95738e4a443d",
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1651174535433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "satellite = \"landsat-c2-l2\"\n",
    "# bands = [\"qa_pixel\"]\n",
    "# bands = ['cloud_qa']\n",
    "bands = ['red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb7126f-4aaf-4615-82da-efc06a2140bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if satellite == \"landsat-c2-l2\":\n",
    "    resolution = 30\n",
    "    min_image_edge = 6\n",
    "else:\n",
    "    resolution = 10\n",
    "    min_image_edge = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9b0ec-c334-4751-91c4-91dabff6a44a",
   "metadata": {},
   "source": [
    "## Create grid and sample points to featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09c0e05-9ba6-407e-9260-5f9f00decc18",
   "metadata": {
    "gather": {
     "logged": 1651174535812
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19598, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_file:\n",
    "    gdf = pd.read_feather(here('data', 'grid', 'ZMB_crop_weights_20k-points.feather'))\n",
    "    gdf = (\n",
    "        geopandas\n",
    "        .GeoDataFrame(\n",
    "            gdf, \n",
    "            geometry = geopandas.points_from_xy(x = gdf.lon, y = gdf.lat), \n",
    "            crs='EPSG:4326')\n",
    "    )\n",
    "else:\n",
    "    cell_size = 0.01  # Roughly 1 km\n",
    "    ### get country shape\n",
    "    country_file_name = f\"data/geo_boundaries/africa_adm0.geojson\"\n",
    "    africa = geopandas.read_file(country_file_name)\n",
    "    country = africa[africa.adm0_a3 == country_code]\n",
    "    #### This would be simpler, but throws an error down the line if used \n",
    "    # world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "    # country = world.query(f'iso_a3 == \"{country_code}\"')\n",
    "    ### Create grid of points\n",
    "    cell_size = .01  # Very roughly 1 km\n",
    "    xmin, ymin, xmax, ymax = country.total_bounds\n",
    "    xs = list(np.arange(xmin, xmax + cell_size, cell_size))\n",
    "    ys = list(np.arange(ymin, ymax + cell_size, cell_size))\n",
    "    def make_cell(x, y, cell_size):\n",
    "        ring = [\n",
    "            (x, y),\n",
    "            (x + cell_size, y),\n",
    "            (x + cell_size, y + cell_size),\n",
    "            (x, y + cell_size)\n",
    "        ]\n",
    "        cell = shapely.geometry.Polygon(ring).centroid\n",
    "        return cell\n",
    "    center_points = []\n",
    "    for x in xs:\n",
    "        for y in ys:\n",
    "            cell = make_cell(x, y, cell_size)\n",
    "            center_points.append(cell)\n",
    "    ### Put grid into a GeDataFrame for cropping to country shape\n",
    "    gdf = geopandas.GeoDataFrame({'geometry': center_points}, crs = 'EPSG:4326')\n",
    "    gdf['lon'], gdf['lat'] = gdf.geometry.x, gdf.geometry.y\n",
    "    ### Subset to country \n",
    "    ### This buffer ensures that no points are take at the border \n",
    "    ### which would lead to duplication with neighboring countries\n",
    "    gdf = gdf[gdf.within(country.unary_union.buffer(-0.005))]\n",
    "    gdf = gdf[['lon', 'lat', 'geometry']].reset_index(drop = True)\n",
    "    gdf = gdf.sample(frac = 0.1, random_state=42, ignore_index=False)\n",
    "    points = gdf[[\"lon\", \"lat\"]].to_numpy()\n",
    "pt_len = gdf.shape[0]\n",
    "gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebfd0c2e-78fe-45a9-99a4-13112f0da841",
   "metadata": {
    "gather": {
     "logged": 1651174537641
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NPARTITIONS = 250\n",
    "\n",
    "ddf = dask_geopandas.from_geopandas(gdf, npartitions=1)\n",
    "hd = ddf.hilbert_distance().compute()\n",
    "gdf[\"hd\"] = hd\n",
    "gdf = gdf.sort_values(\"hd\")\n",
    "\n",
    "dgdf = dask_geopandas.from_geopandas(gdf, npartitions=NPARTITIONS, sort=False)\n",
    "\n",
    "del ddf\n",
    "del hd\n",
    "del gdf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578c8582-db2c-417d-8512-063ed38c05d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Using:  \n",
      "        Satellite: landsat-c2-l2  \n",
      "        Pixel Resolution: 30  \n",
      "        Grid Resolution: 0.01 degree squared (WGS84) \n",
      "        Cloud Limit: less than 20%  \n",
      "        Bands: ['red'] \n",
      "        Points: 19598 \n",
      "        Number Features: 1024 features \n",
      "        Year Range: 2022 to 2022 \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "start_month = 7\n",
    "\n",
    "year_start = 2022\n",
    "year_end = 2022\n",
    "\n",
    "buffer_size = 0.005\n",
    "cloud_limit = 20\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "workers = os.cpu_count() \n",
    "\n",
    "print(\n",
    "   f\"\"\"\n",
    "    Using:  \n",
    "        Satellite: {satellite}  \n",
    "        Pixel Resolution: {resolution}  \n",
    "        Grid Resolution: {buffer_size * 2} degree squared (WGS84) \n",
    "        Cloud Limit: less than {cloud_limit}%  \n",
    "        Bands: {bands} \n",
    "        Points: {pt_len} \n",
    "        Number Features: {num_features} features \n",
    "        Year Range: {year_start} to {year_end} \n",
    "    \"\"\"\n",
    ")\n",
    "# for yr in range(year_start, year_end+1):\n",
    "    \n",
    "yr = 2013\n",
    "\n",
    "features = pd.DataFrame()\n",
    "ft = []\n",
    "\n",
    "if (yr == year_start):\n",
    "    month_range = range(start_month, 13)\n",
    "else:\n",
    "    month_range = range(1, 13) \n",
    "        \n",
    "    # for mn in month_range:\n",
    "        \n",
    "mn = 1\n",
    "\n",
    "if mn < 10:\n",
    "    month = \"0\"+str(mn)\n",
    "else:\n",
    "    month = mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ed4f36-0656-4a65-966d-12c035c6b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(points):\n",
    "    \"\"\"\n",
    "    Find a STAC item for points in the `points` DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : geopandas.GeoDataFrame\n",
    "        A GeoDataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoDataFrame\n",
    "        A new geopandas.GeoDataFrame with a `stac_item` column containing the STAC\n",
    "        item that covers each point.\n",
    "    \"\"\"\n",
    "    intersects = shapely.geometry.mapping(points.unary_union.convex_hull)\n",
    "\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "    )\n",
    "    # Define search date range for query\n",
    "    ending_day = calendar.monthrange(yr, int(mn))[1]\n",
    "    search_start = f\"{yr}-{month}-1\" \n",
    "    search_end = f\"{yr}-{month}-{ending_day}\" \n",
    "\n",
    "    # The time frame in which we search for non-cloudy imagery\n",
    "    search = catalog.search(\n",
    "        collections=[satellite],  \n",
    "        intersects=intersects,\n",
    "        datetime=[search_start, search_end],\n",
    "        query={\"eo:cloud_cover\": {\"lt\": cloud_limit}},\n",
    "        limit=500,\n",
    "    )\n",
    "    ic = search.get_all_items_as_dict()\n",
    "    features = ic[\"features\"]\n",
    "    features_d = {item[\"id\"]: item for item in features}\n",
    "    data = {\n",
    "        \"eo:cloud_cover\": [],\n",
    "        \"geometry\": [],\n",
    "    }\n",
    "    index = []\n",
    "    for item in features:\n",
    "        data[\"eo:cloud_cover\"].append(item[\"properties\"][\"eo:cloud_cover\"])\n",
    "        data[\"geometry\"].append(shapely.geometry.shape(item[\"geometry\"]))\n",
    "        index.append(item[\"id\"])\n",
    "    items = geopandas.GeoDataFrame(data, index=index, geometry=\"geometry\").sort_values(\n",
    "        \"eo:cloud_cover\"\n",
    "    )\n",
    "    point_list = points.geometry.tolist()\n",
    "    point_items = []\n",
    "    # cloud_cover = []\n",
    "    for point in point_list:\n",
    "        covered_by = items[items.covers(point)]\n",
    "        if len(covered_by):\n",
    "            point_items.append(features_d[covered_by.index[0]])\n",
    "            # cloud_cover.append(features_d[covered_by.index[0]].get('properties').get('eo:cloud_cover'))\n",
    "        else:\n",
    "            # There weren't any scenes matching our conditions for this point (too cloudy)\n",
    "            point_items.append(None)\n",
    "            # cloud_cover.append(None)\n",
    "    return points.assign(stac_item=point_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43826d71-7189-4d24-8ec0-527e53857c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching images to points for: 1-2013\n",
      "Found acceptable images for 1857/19598 points in 30.32 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "print(\"Matching images to points for: \", mn, \"-\", yr, sep = \"\")\n",
    "\n",
    "with Client(n_workers=16) as client:\n",
    "    meta = dgdf._meta.assign(stac_item=[])\n",
    "    df2 = dgdf.map_partitions(query, meta=meta).compute()\n",
    "    \n",
    "df3 = df2.dropna(subset=[\"stac_item\"]).reset_index(drop = True)\n",
    "\n",
    "matching_items = []\n",
    "for item in df3.stac_item.tolist():\n",
    "    signed_item = pc.sign(Item.from_dict(item))\n",
    "    matching_items.append(signed_item)\n",
    "\n",
    "points = df3[[\"lon\", \"lat\"]].to_numpy()\n",
    "\n",
    "print(\"Found acceptable images for \", \n",
    "      points.shape[0], \"/\", pt_len,\n",
    "      \" points in \", \n",
    "      f\"{time.time()-tic:0.2f} seconds\", \n",
    "      sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26656992-2046-49ef-bb93-a3f48d04b5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f206ec-0458-49aa-bec8-6cb1cca12446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4be93c-dfe0-462b-a592-217de22244ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7354a0a-ba76-4fd9-8aa5-84b7ad98369d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afc69f-5af5-41a3-a04e-0c3d903105a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131a4cb2-c0b3-4a4e-b30b-6f428b0a3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6425373-a07c-491a-ae38-4a03a0f72bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1857 -- 0.00% -- 0.44 seconds\n",
      "500/1857 -- 26.93% -- 59.68 seconds\n",
      "1000/1857 -- 53.85% -- 56.57 seconds\n",
      "1500/1857 -- 80.78% -- 60.49 seconds\n",
      "CPU times: user 1min 20s, sys: 10.6 s, total: 1min 30s\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "na_perc = np.zeros((points.shape[0], 1), dtype=float)\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    \n",
    "    lon, lat = points[i]\n",
    "    fn = matching_items[i]\n",
    "\n",
    "    stack = stackstac.stack(fn, assets=bands, resolution=resolution)\n",
    "    x_min, y_min = pyproj.Proj(stack.crs)(lon-buffer_size, lat-buffer_size)\n",
    "    x_max, y_max = pyproj.Proj(stack.crs)(lon+buffer_size, lat+buffer_size)\n",
    "    aoi = stack.loc[..., y_max:y_min, x_min:x_max]\n",
    "    \n",
    "    data = aoi.data.squeeze()\n",
    "    na_perc[i] = (np.isnan(data).sum() / (data.shape[0] * data.shape[1]))#.compute()\n",
    "    \n",
    "    \n",
    "#     out_image = aoi.data.squeeze()\n",
    "#     out_image = torch.from_numpy(out_image.compute()).float()\n",
    "#     out_image = out_image.to(device)\n",
    "#     na_perc[i] = ((out_image.isnan()).sum() / out_image.numel()).item()\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(\n",
    "            f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "            + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "        )\n",
    "        tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece7d7a5-088b-40be-b445-6e1c30442396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38455598],\n",
       "       [0.30632716],\n",
       "       [0.38348765],\n",
       "       ...,\n",
       "       [0.47822823],\n",
       "       [0.36261261],\n",
       "       [0.41666667]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da4a0f-3b82-4c50-976d-cce5e42f0a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f9eeb-9dce-48af-94a9-4548e69a7d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60c457-f70d-43bd-a91f-21a90bc44e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd4662-6900-4ea4-96e6-0f34ebdb2922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581d00d-04a3-4f92-8109-b1cf39242916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01678ab-de35-4dbc-b062-378f69d03dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58f541e-e819-4314-9762-2f2d70b1b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, points, items, buffer=buffer_size):\n",
    "        self.points = points\n",
    "        self.items = items\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        lon, lat = self.points[idx]\n",
    "        fn = self.items[idx]\n",
    "\n",
    "        if fn is None:\n",
    "            return None\n",
    "        else:\n",
    "            stack = stackstac.stack(fn, assets=bands, resolution=resolution)\n",
    "            x_min, y_min = pyproj.Proj(stack.crs)(lon-self.buffer, lat-self.buffer)\n",
    "            x_max, y_max = pyproj.Proj(stack.crs)(lon+self.buffer, lat+self.buffer)\n",
    "            aoi = stack.loc[..., y_max:y_min, x_min:x_max]\n",
    "            data = aoi.data.squeeze()\n",
    "            na_percentage = np.isnan(data).sum() / (data.shape[0] * data.shape[1])\n",
    "            return na_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba65d752-ed53-4b5c-b480-82ab1d256268",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(points, matching_items)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    num_workers=workers * 2,\n",
    "    collate_fn=lambda x: x,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8099be6-9b9a-4fa8-9306-98cc38d607ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting metadata: 01-2013\n",
      "0/1857 -- 0.00% -- 1.01 seconds\n",
      "500/1857 -- 26.93% -- 50.76 seconds\n",
      "1000/1857 -- 53.85% -- 44.70 seconds\n",
      "1500/1857 -- 80.78% -- 50.56 seconds\n",
      "CPU times: user 1min 2s, sys: 9.51 s, total: 1min 11s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Collecting metadata: \", month, \"-\", yr, sep = \"\")\n",
    "\n",
    "na_perc = np.zeros((points.shape[0], 1), dtype=float)\n",
    "tic = time.time()\n",
    "i = 0\n",
    "for images in dataloader:\n",
    "    for image in images:\n",
    "        na_perc[i] = image\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            print(\n",
    "                f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "                + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "            )\n",
    "            tic = time.time()\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e0a6302-371f-4c75-820f-17cf79528ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38455598],\n",
       "       [0.30632716],\n",
       "       [0.38348765],\n",
       "       ...,\n",
       "       [0.47822823],\n",
       "       [0.36261261],\n",
       "       [0.41666667]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b52399e-22e2-4c29-b999-3a36d8a083d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd97df2-97c0-4056-a005-b2774911d9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d7d48-9b08-408f-a516-202091cf5d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621cc7f-1453-413e-9deb-4fb373d1b838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de8acf-3554-4838-96f5-8a442e0ff7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad84b0-2e3a-4369-ab85-d4b9343f2ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42388b-e7cc-4289-be87-bef3b16d37aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7cc805-050c-4f2f-9c28-3509f7befa09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810da9d9-4519-4d38-99be-9ff5860b7d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e48553-2bd2-4d16-b979-7d716f2c017c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec79b8-d9e7-4275-aa81-666a8f1ecdca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b88f119f-7590-4e5a-ae35-86a8986e0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, points, items, buffer=buffer_size):\n",
    "        self.points = points\n",
    "        self.items = items\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        lon, lat = self.points[idx]\n",
    "        fn = self.items[idx]\n",
    "\n",
    "        if fn is None:\n",
    "            return None\n",
    "        else:\n",
    "            stack = stackstac.stack(\n",
    "                fn,\n",
    "                assets=['qa_pixel'],\n",
    "                resolution=resolution,\n",
    "            )\n",
    "            x_min, y_min = pyproj.Proj(stack.crs)(lon-self.buffer, lat-self.buffer)\n",
    "            x_max, y_max = pyproj.Proj(stack.crs)(lon+self.buffer, lat+self.buffer)\n",
    "            aoi = stack.loc[..., y_max:y_min, x_min:x_max]\n",
    "            data = aoi.compute(\n",
    "                scheduler=\"single-threaded\"\n",
    "                )\n",
    "            out_image = data.data.squeeze()\n",
    "            out_image = torch.from_numpy(out_image).float()\n",
    "            return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6d3278c-a12d-4600-9f7b-1c60f8fa8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(points, matching_items, buffer = .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ad0c4-081f-4c7d-a16c-efbe8aa57b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af4007-0a4b-4abb-8c53-97fb33f29f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img['band']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59580afe-123c-4ecf-bb7e-ce0803e5760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img['raster:bands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b029a0-5ffe-4f95-91b6-17925881366f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d249be-36de-44c7-8b39-ffb6bc928ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa599f7-a410-4079-9819-455f4d928398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219e6e3-989b-4cf5-a20f-3692de1d7e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39016b31-013b-41ee-990a-c38c2fb1efee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa32b21-9d4a-4282-8695-8cd99c8f0e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c62ff-569f-4a7a-9288-d9a13e67f960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046eabc-fc19-4eca-8718-e8a4f4697ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "import pystac_client\n",
    "import pyproj\n",
    "import planetary_computer as pc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "lat, lon =  -5, 20\n",
    "\n",
    "catalog = pystac_client.Client.open('https://planetarycomputer.microsoft.com/api/stac/v1')\n",
    "\n",
    "search = catalog.search(\n",
    "    collections=['landsat-c2-l2'],\n",
    "    intersects=dict(type=\"Point\", coordinates=[lon, lat]),\n",
    "    datetime=\"2020-12-01/2021-01-01\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 25}}\n",
    ")\n",
    "\n",
    "items = pc.sign(search)\n",
    "\n",
    "stack = stackstac.stack(items, assets=[\"qa_pixel\"])\n",
    "\n",
    "x_utm, y_utm = pyproj.Proj(stack.crs)(lon, lat)\n",
    "\n",
    "buffer = 2000  # meters\n",
    "\n",
    "aoi = stack.loc[..., y_utm+buffer:y_utm-buffer, x_utm-buffer:x_utm+buffer]\n",
    "\n",
    "image = aoi.data.squeeze().compute()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(image, interpolation='none')\n",
    "values = np.unique(image.ravel())\n",
    "colors = [im.cmap(im.norm(value)) for value in values]\n",
    "patches = [mpatches.Patch(color=colors[i], label=f\"{values[i]}\") for i in range(len(values))]\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beca0bb-ba9e-4fb6-812f-2082a6767ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack['raster:bands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf92311-ff97-4621-876e-57e87f44db71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127def10-18f5-4cd9-a399-571824b9a46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea610cb3-6ee9-49ea-bff0-abb75cc1ebaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29996d-41ca-4bb6-b673-03031c8617ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e430ea-b6d2-41ab-999b-58621d652430",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(points, matching_items, buffer = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3bed3-f71f-470d-9546-133b406e8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.patches as mpatches\n",
    "img = dataset[0]\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(img, interpolation='none')\n",
    "\n",
    "# get the unique values from data\n",
    "# i.e. a sorted list of all values in data\n",
    "values = np.unique(img.ravel())\n",
    "\n",
    "# get the colors of the values, according to the \n",
    "# colormap used by imshow\n",
    "colors = [ im.cmap(im.norm(value)) for value in values]\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [ mpatches.Patch(color=colors[i], label=f\"{values[i]}\") for i in range(len(values)) ]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3269e-5c96-4c6f-bae5-952c0f17f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb57ff6-2cb0-4950-a057-48f9678887e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_perc = ((img.isnan()).sum() / img.numel()).item()\n",
    "na_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c59e3fb9-fb0b-47c0-81aa-19b1128d5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=workers,\n",
    "    collate_fn=lambda x: x,\n",
    "    pin_memory=False,\n",
    "    persistent_workers=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1c49880-7b4a-4231-8b72-144cf9d98ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting metadata: 05-2022\n",
      "0/19598 -- 0.00% -- 0.45 seconds\n",
      "500/19598 -- 2.55% -- 20.19 seconds\n",
      "1000/19598 -- 5.10% -- 21.35 seconds\n",
      "1500/19598 -- 7.65% -- 146.39 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Collecting metadata: \", month, \"-\", yr, sep = \"\")\n",
    "\n",
    "x_all = np.zeros((points.shape[0], 1), dtype=float)\n",
    "tic = time.time()\n",
    "i = 0\n",
    "for images in dataloader:\n",
    "    for image in images:\n",
    "        if i % 500 == 0:\n",
    "            print(\n",
    "                f\"{i}/{points.shape[0]} -- {i / points.shape[0] * 100:0.2f}%\"\n",
    "                + f\" -- {time.time()-tic:0.2f} seconds\"\n",
    "            )\n",
    "            tic = time.time()\n",
    "            \n",
    "        x_all[i] = ((image.isnan()).sum() / image.numel()).item()\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb47e168-fe93-431e-828a-7bede95ae501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd7f5d50-fc1c-46ee-893d-d2cdf1e83030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9add0c4d-37b3-4d91-b1e2-1b2d7f1e82ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de5a986b-a362-48ab-bc35-2b70d1b1152a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77fcd6d3-6d1f-4e5e-be00-7ec570552488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a128e16-e125-4cc6-af9f-375e72a1d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna(subset=[\"stac_item\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0203c540-ce8f-4378-9ac8-a8c2ae0cc271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'gsd': 30, 'created': '2022-06-02T09:16:38.13...\n",
       "1        {'gsd': 30, 'created': '2022-06-02T09:16:38.13...\n",
       "2        {'gsd': 30, 'created': '2022-06-02T09:16:38.13...\n",
       "3        {'gsd': 30, 'created': '2022-06-02T09:16:38.13...\n",
       "4        {'gsd': 30, 'created': '2022-09-14T06:16:10.62...\n",
       "                               ...                        \n",
       "19593    {'gsd': 30, 'created': '2022-09-14T06:15:23.87...\n",
       "19594    {'gsd': 30, 'created': '2022-09-14T06:15:23.87...\n",
       "19595    {'gsd': 30, 'created': '2022-09-14T06:15:23.87...\n",
       "19596    {'gsd': 30, 'created': '2022-09-14T06:15:23.87...\n",
       "19597    {'gsd': 30, 'created': '2022-09-14T06:15:23.87...\n",
       "Name: properties, Length: 19598, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['stac_item'].apply(pd.Series)['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dba4da95-6a07-43c4-b3eb-8c24bb5e8261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_perc</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>stac_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>na_percent</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201666</td>\n",
       "      <td>22.144878</td>\n",
       "      <td>-16.384232</td>\n",
       "      <td>LC09_L2SP_175072_20220525_02_T1</td>\n",
       "      <td>landsat-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279001</td>\n",
       "      <td>22.124878</td>\n",
       "      <td>-16.384232</td>\n",
       "      <td>LC09_L2SP_175072_20220525_02_T1</td>\n",
       "      <td>landsat-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311719</td>\n",
       "      <td>22.134878</td>\n",
       "      <td>-16.384232</td>\n",
       "      <td>LC09_L2SP_175072_20220525_02_T1</td>\n",
       "      <td>landsat-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.419393</td>\n",
       "      <td>22.134878</td>\n",
       "      <td>-16.394232</td>\n",
       "      <td>LC09_L2SP_175072_20220525_02_T1</td>\n",
       "      <td>landsat-9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305175</td>\n",
       "      <td>22.104878</td>\n",
       "      <td>-16.324232</td>\n",
       "      <td>LE07_L2SP_176071_20220525_02_T1</td>\n",
       "      <td>landsat-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19593</th>\n",
       "      <td>0.505651</td>\n",
       "      <td>27.844878</td>\n",
       "      <td>-16.784232</td>\n",
       "      <td>LE07_L2SP_172072_20220522_02_T1</td>\n",
       "      <td>landsat-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19594</th>\n",
       "      <td>0.475907</td>\n",
       "      <td>27.854878</td>\n",
       "      <td>-16.784232</td>\n",
       "      <td>LE07_L2SP_172072_20220522_02_T1</td>\n",
       "      <td>landsat-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19595</th>\n",
       "      <td>0.437835</td>\n",
       "      <td>27.864878</td>\n",
       "      <td>-16.784232</td>\n",
       "      <td>LE07_L2SP_172072_20220522_02_T1</td>\n",
       "      <td>landsat-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19596</th>\n",
       "      <td>0.466984</td>\n",
       "      <td>27.864878</td>\n",
       "      <td>-16.794232</td>\n",
       "      <td>LE07_L2SP_172072_20220522_02_T1</td>\n",
       "      <td>landsat-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19597</th>\n",
       "      <td>0.334920</td>\n",
       "      <td>27.824878</td>\n",
       "      <td>-16.824232</td>\n",
       "      <td>LE07_L2SP_172072_20220522_02_T1</td>\n",
       "      <td>landsat-7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19598 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       crop_perc        lon        lat                          stac_id  \\\n",
       "0       0.201666  22.144878 -16.384232  LC09_L2SP_175072_20220525_02_T1   \n",
       "1       0.279001  22.124878 -16.384232  LC09_L2SP_175072_20220525_02_T1   \n",
       "2       0.311719  22.134878 -16.384232  LC09_L2SP_175072_20220525_02_T1   \n",
       "3       0.419393  22.134878 -16.394232  LC09_L2SP_175072_20220525_02_T1   \n",
       "4       0.305175  22.104878 -16.324232  LE07_L2SP_176071_20220525_02_T1   \n",
       "...          ...        ...        ...                              ...   \n",
       "19593   0.505651  27.844878 -16.784232  LE07_L2SP_172072_20220522_02_T1   \n",
       "19594   0.475907  27.854878 -16.784232  LE07_L2SP_172072_20220522_02_T1   \n",
       "19595   0.437835  27.864878 -16.784232  LE07_L2SP_172072_20220522_02_T1   \n",
       "19596   0.466984  27.864878 -16.794232  LE07_L2SP_172072_20220522_02_T1   \n",
       "19597   0.334920  27.824878 -16.824232  LE07_L2SP_172072_20220522_02_T1   \n",
       "\n",
       "        platform  cloud_cover  na_percent  year  month  \n",
       "0      landsat-9          0.0         0.0  2022      5  \n",
       "1      landsat-9          0.0         0.0  2022      5  \n",
       "2      landsat-9          0.0         0.0  2022      5  \n",
       "3      landsat-9          0.0         0.0  2022      5  \n",
       "4      landsat-7          0.0         0.0  2022      5  \n",
       "...          ...          ...         ...   ...    ...  \n",
       "19593  landsat-7          0.0         0.0  2022      5  \n",
       "19594  landsat-7          0.0         0.0  2022      5  \n",
       "19595  landsat-7          0.0         0.0  2022      5  \n",
       "19596  landsat-7          0.0         0.0  2022      5  \n",
       "19597  landsat-7          0.0         0.0  2022      5  \n",
       "\n",
       "[19598 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['stac_id'] = df3['stac_item'].apply(pd.Series)['id']\n",
    "df3['platform'] = df3['stac_item'].apply(pd.Series)['properties'].apply(pd.Series)['platform']\n",
    "df3['cloud_cover'] = df3['stac_item'].apply(pd.Series)['properties'].apply(pd.Series)['eo:cloud_cover']\n",
    "df3.drop(['geometry', 'hd', 'stac_item'], axis = 1, inplace = True)\n",
    "df3[['na_percent', 'year', \"month\"]] = x_all, yr, mn\n",
    "df3 = pd.DataFrame(df3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ce507-5616-4e75-ac25-efe8ebd023d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'{satellite}_{country_code}_{pt_len/1000:.0f}k-points_meta_{yr}_{mn}.csv'\n",
    "file_name = here('data', 'random_features', satellite, fn)\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1724588-edce-41f8-9d2d-df844ee846c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
